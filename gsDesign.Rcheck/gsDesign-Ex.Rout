
R version 4.5.0 (2025-04-11) -- "How About a Twenty-Six"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: aarch64-apple-darwin20

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "gsDesign"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('gsDesign')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("as_gt")
> ### * as_gt
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as_gt
> ### Title: Convert a summary table object to a gt object
> ### Aliases: as_gt as_gt.gsBinomialExactTable
> 
> ### ** Examples
> 
> safety_design <- binomialSPRT(
+   p0 = .04, p1 = .1, alpha = .04, beta = .2, minn = 4, maxn = 75
+ )
> safety_power <- gsBinomialExact(
+   k = length(safety_design$n.I),
+   theta = seq(.02, .16, .02),
+   n.I = safety_design$n.I,
+   a = safety_design$lower$bound,
+   b = safety_design$upper$bound
+ )
> safety_power |>
+   as_table() |>
+   as_gt(
+     theta_label = gt::html("Underlying<br>AE rate"),
+     prob_decimals = 3,
+     bound_label = c("low rate", "high rate")
+   )
<div id="ydgabwknrs" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
  <style>#ydgabwknrs table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#ydgabwknrs thead, #ydgabwknrs tbody, #ydgabwknrs tfoot, #ydgabwknrs tr, #ydgabwknrs td, #ydgabwknrs th {
  border-style: none;
}

#ydgabwknrs p {
  margin: 0;
  padding: 0;
}

#ydgabwknrs .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ydgabwknrs .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#ydgabwknrs .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ydgabwknrs .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ydgabwknrs .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ydgabwknrs .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ydgabwknrs .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ydgabwknrs .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ydgabwknrs .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ydgabwknrs .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ydgabwknrs .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ydgabwknrs .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ydgabwknrs .gt_spanner_row {
  border-bottom-style: hidden;
}

#ydgabwknrs .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#ydgabwknrs .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ydgabwknrs .gt_from_md > :first-child {
  margin-top: 0;
}

#ydgabwknrs .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ydgabwknrs .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ydgabwknrs .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#ydgabwknrs .gt_row_group_first td {
  border-top-width: 2px;
}

#ydgabwknrs .gt_row_group_first th {
  border-top-width: 2px;
}

#ydgabwknrs .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#ydgabwknrs .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#ydgabwknrs .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ydgabwknrs .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ydgabwknrs .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#ydgabwknrs .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ydgabwknrs .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ydgabwknrs .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ydgabwknrs .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ydgabwknrs .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_left {
  text-align: left;
}

#ydgabwknrs .gt_center {
  text-align: center;
}

#ydgabwknrs .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ydgabwknrs .gt_font_normal {
  font-weight: normal;
}

#ydgabwknrs .gt_font_bold {
  font-weight: bold;
}

#ydgabwknrs .gt_font_italic {
  font-style: italic;
}

#ydgabwknrs .gt_super {
  font-size: 65%;
}

#ydgabwknrs .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#ydgabwknrs .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#ydgabwknrs .gt_indent_1 {
  text-indent: 5px;
}

#ydgabwknrs .gt_indent_2 {
  text-indent: 10px;
}

#ydgabwknrs .gt_indent_3 {
  text-indent: 15px;
}

#ydgabwknrs .gt_indent_4 {
  text-indent: 20px;
}

#ydgabwknrs .gt_indent_5 {
  text-indent: 25px;
}

#ydgabwknrs .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#ydgabwknrs div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
  <table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="4" class="gt_heading gt_title gt_font_normal" style>Operating Characteristics for the Truncated SPRT Design</td>
    </tr>
    <tr class="gt_heading">
      <td colspan="4" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style>Assumes trial evaluated sequentially after each response</td>
    </tr>
    <tr class="gt_col_headings gt_spanner_row">
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="2" colspan="1" scope="col" id="theta">Underlying<br>AE rate</th>
      <th class="gt_center gt_columns_top_border gt_column_spanner_outer" rowspan="1" colspan="2" scope="colgroup" id="Probability of crossing">
        <div class="gt_column_spanner">Probability of crossing</div>
      </th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="2" colspan="1" scope="col" id="en">Average<br>sample size</th>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Lower">low rate</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Upper">high rate</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="theta" class="gt_row gt_right">2%</td>
<td headers="Lower" class="gt_row gt_right">0.964</td>
<td headers="Upper" class="gt_row gt_right">0.001</td>
<td headers="en" class="gt_row gt_right">34.8</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">4%</td>
<td headers="Lower" class="gt_row gt_right">0.769</td>
<td headers="Upper" class="gt_row gt_right">0.019</td>
<td headers="en" class="gt_row gt_right">46.4</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">6%</td>
<td headers="Lower" class="gt_row gt_right">0.506</td>
<td headers="Upper" class="gt_row gt_right">0.108</td>
<td headers="en" class="gt_row gt_right">54.3</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">8%</td>
<td headers="Lower" class="gt_row gt_right">0.291</td>
<td headers="Upper" class="gt_row gt_right">0.290</td>
<td headers="en" class="gt_row gt_right">56.1</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">10%</td>
<td headers="Lower" class="gt_row gt_right">0.155</td>
<td headers="Upper" class="gt_row gt_right">0.516</td>
<td headers="en" class="gt_row gt_right">52.8</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">12%</td>
<td headers="Lower" class="gt_row gt_right">0.079</td>
<td headers="Upper" class="gt_row gt_right">0.714</td>
<td headers="en" class="gt_row gt_right">46.8</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">14%</td>
<td headers="Lower" class="gt_row gt_right">0.039</td>
<td headers="Upper" class="gt_row gt_right">0.851</td>
<td headers="en" class="gt_row gt_right">40.2</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">16%</td>
<td headers="Lower" class="gt_row gt_right">0.020</td>
<td headers="Upper" class="gt_row gt_right">0.930</td>
<td headers="en" class="gt_row gt_right">34.2</td></tr>
  </tbody>
  
</table>
</div>
> 
> 
> 
> cleanEx()
> nameEx("as_rtf")
> ### * as_rtf
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as_rtf
> ### Title: Save a summary table object as an RTF file
> ### Aliases: as_rtf as_rtf.gsBinomialExactTable as_rtf.gsBoundSummary
> 
> ### ** Examples
> 
> # as_rtf for gsBinomialExact
> zz <- gsBinomialExact(
+   k = 3, theta = seq(0.1, 0.9, 0.1), n.I = c(12, 24, 36),
+   a = c(-1, 0, 11), b = c(5, 9, 12)
+ )
> zz |>
+   as_table() |>
+   as_rtf(
+     file = tempfile(fileext = ".rtf"),
+     title = "Power/Type I Error and Expected Sample Size for a Group Sequential Design"
+   )
> 
> safety_design <- binomialSPRT(
+   p0 = .04, p1 = .1, alpha = .04, beta = .2, minn = 4, maxn = 75
+ )
> safety_power <- gsBinomialExact(
+   k = length(safety_design$n.I),
+   theta = seq(.02, .16, .02),
+   n.I = safety_design$n.I,
+   a = safety_design$lower$bound,
+   b = safety_design$upper$bound
+ )
> safety_power |>
+   as_table() |>
+   as_rtf(
+     file = tempfile(fileext = ".rtf"),
+     theta_label = "Underlying\nAE Rate",
+     prob_decimals = 3,
+     bound_label = c("Low Rate", "High Rate")
+   )
> # as_rtf for gsBoundSummary
> xgs <- gsSurv(lambdaC = .2, hr = .5, eta = .1, T = 2, minfup = 1.5)
> gsBoundSummary(xgs, timename = "Year", tdigits = 1) |> as_rtf(file = tempfile(fileext = ".rtf"))
> 
> ss <- nSurvival(
+   lambda1 = .2, lambda2 = .1, eta = .1, Ts = 2, Tr = .5,
+   sided = 1, alpha = .025, ratio = 2
+ )
> xs <- gsDesign(nFixSurv = ss$n, n.fix = ss$nEvents, delta1 = log(ss$lambda2 / ss$lambda1))
> gsBoundSummary(xs, logdelta = TRUE, ratio = ss$ratio) |> as_rtf(file = tempfile(fileext = ".rtf"))
> 
> xs <- gsDesign(nFixSurv = ss$n, n.fix = ss$nEvents, delta1 = log(ss$lambda2 / ss$lambda1))
> gsBoundSummary(xs, logdelta = TRUE, ratio = ss$ratio) |>
+   as_rtf(file = tempfile(fileext = ".rtf"),
+   footnote_specify = "Z",
+   footnote_text = "Z-Score")
> 
> 
> 
> cleanEx()
> nameEx("as_table")
> ### * as_table
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: as_table
> ### Title: Create a summary table
> ### Aliases: as_table as_table.gsBinomialExact
> 
> ### ** Examples
> 
> b <- binomialSPRT(p0 = .1, p1 = .35, alpha = .08, beta = .2, minn = 10, maxn = 25)
> b_power <- gsBinomialExact(
+   k = length(b$n.I), theta = seq(.1, .45, .05), n.I = b$n.I,
+   a = b$lower$bound, b = b$upper$bound
+ )
> b_power |>
+   as_table() |>
+   as_gt()
<div id="ydgabwknrs" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
  <style>#ydgabwknrs table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#ydgabwknrs thead, #ydgabwknrs tbody, #ydgabwknrs tfoot, #ydgabwknrs tr, #ydgabwknrs td, #ydgabwknrs th {
  border-style: none;
}

#ydgabwknrs p {
  margin: 0;
  padding: 0;
}

#ydgabwknrs .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ydgabwknrs .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#ydgabwknrs .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ydgabwknrs .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ydgabwknrs .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ydgabwknrs .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ydgabwknrs .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ydgabwknrs .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ydgabwknrs .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ydgabwknrs .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ydgabwknrs .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ydgabwknrs .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ydgabwknrs .gt_spanner_row {
  border-bottom-style: hidden;
}

#ydgabwknrs .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#ydgabwknrs .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ydgabwknrs .gt_from_md > :first-child {
  margin-top: 0;
}

#ydgabwknrs .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ydgabwknrs .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ydgabwknrs .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#ydgabwknrs .gt_row_group_first td {
  border-top-width: 2px;
}

#ydgabwknrs .gt_row_group_first th {
  border-top-width: 2px;
}

#ydgabwknrs .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#ydgabwknrs .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#ydgabwknrs .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ydgabwknrs .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ydgabwknrs .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#ydgabwknrs .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ydgabwknrs .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ydgabwknrs .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ydgabwknrs .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ydgabwknrs .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ydgabwknrs .gt_left {
  text-align: left;
}

#ydgabwknrs .gt_center {
  text-align: center;
}

#ydgabwknrs .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ydgabwknrs .gt_font_normal {
  font-weight: normal;
}

#ydgabwknrs .gt_font_bold {
  font-weight: bold;
}

#ydgabwknrs .gt_font_italic {
  font-style: italic;
}

#ydgabwknrs .gt_super {
  font-size: 65%;
}

#ydgabwknrs .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#ydgabwknrs .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#ydgabwknrs .gt_indent_1 {
  text-indent: 5px;
}

#ydgabwknrs .gt_indent_2 {
  text-indent: 10px;
}

#ydgabwknrs .gt_indent_3 {
  text-indent: 15px;
}

#ydgabwknrs .gt_indent_4 {
  text-indent: 20px;
}

#ydgabwknrs .gt_indent_5 {
  text-indent: 25px;
}

#ydgabwknrs .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#ydgabwknrs div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>
  <table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    <tr class="gt_heading">
      <td colspan="4" class="gt_heading gt_title gt_font_normal" style>Operating Characteristics for the Truncated SPRT Design</td>
    </tr>
    <tr class="gt_heading">
      <td colspan="4" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style>Assumes trial evaluated sequentially after each response</td>
    </tr>
    <tr class="gt_col_headings gt_spanner_row">
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="2" colspan="1" scope="col" id="theta">Underlying<br>response rate</th>
      <th class="gt_center gt_columns_top_border gt_column_spanner_outer" rowspan="1" colspan="2" scope="colgroup" id="Probability of crossing">
        <div class="gt_column_spanner">Probability of crossing</div>
      </th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="2" colspan="1" scope="col" id="en">Average<br>sample size</th>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Lower">Futility bound</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Upper">Efficacy bound</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="theta" class="gt_row gt_right">10%</td>
<td headers="Lower" class="gt_row gt_right">0.94</td>
<td headers="Upper" class="gt_row gt_right">0.04</td>
<td headers="en" class="gt_row gt_right">12.1</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">15%</td>
<td headers="Lower" class="gt_row gt_right">0.78</td>
<td headers="Upper" class="gt_row gt_right">0.15</td>
<td headers="en" class="gt_row gt_right">13.6</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">20%</td>
<td headers="Lower" class="gt_row gt_right">0.57</td>
<td headers="Upper" class="gt_row gt_right">0.32</td>
<td headers="en" class="gt_row gt_right">14.3</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">25%</td>
<td headers="Lower" class="gt_row gt_right">0.37</td>
<td headers="Upper" class="gt_row gt_right">0.53</td>
<td headers="en" class="gt_row gt_right">14.2</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">30%</td>
<td headers="Lower" class="gt_row gt_right">0.22</td>
<td headers="Upper" class="gt_row gt_right">0.71</td>
<td headers="en" class="gt_row gt_right">13.4</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">35%</td>
<td headers="Lower" class="gt_row gt_right">0.12</td>
<td headers="Upper" class="gt_row gt_right">0.84</td>
<td headers="en" class="gt_row gt_right">12.5</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">40%</td>
<td headers="Lower" class="gt_row gt_right">0.06</td>
<td headers="Upper" class="gt_row gt_right">0.92</td>
<td headers="en" class="gt_row gt_right">11.6</td></tr>
    <tr><td headers="theta" class="gt_row gt_right">45%</td>
<td headers="Lower" class="gt_row gt_right">0.03</td>
<td headers="Upper" class="gt_row gt_right">0.97</td>
<td headers="en" class="gt_row gt_right">11.0</td></tr>
  </tbody>
  
</table>
</div>
> 
> 
> 
> cleanEx()
> nameEx("binomialPowerTable")
> ### * binomialPowerTable
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: binomialPowerTable
> ### Title: Power Table for Binomial Tests
> ### Aliases: binomialPowerTable
> 
> ### ** Examples
> 
> # Create a power table with analytical power calculation
> power_table <- binomialPowerTable(
+   pC = c(0.8, 0.9),
+   delta = seq(-0.05, 0.05, 0.025),
+   n = 70
+ )
> 
> # Create a power table with simulation
> power_table_sim <- binomialPowerTable(
+   pC = c(0.8, 0.9),
+   delta = seq(-0.05, 0.05, 0.025),
+   n = 70,
+   simulation = TRUE,
+   nsim = 10000
+ )
> 
> 
> 
> cleanEx()
> nameEx("checkScalar")
> ### * checkScalar
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: checkLengths
> ### Title: Utility functions to verify variable properties
> ### Aliases: checkLengths checkRange checkScalar isInteger checkVector
> ### Keywords: programming
> 
> ### ** Examples
> 
> 
> # check whether input is an integer
> isInteger(1)
[1] TRUE
> isInteger(1:5)
[1] TRUE
> try(isInteger("abc")) # expect error
[1] FALSE
> 
> # check whether input is an integer scalar
> checkScalar(3, "integer")
> 
> # check whether input is an integer scalar that resides
> # on the interval on [3, 6]. Then test for interval (3, 6].
> checkScalar(3, "integer", c(3, 6))
> try(checkScalar(3, "integer", c(3, 6), c(FALSE, TRUE))) # expect error
Error in checkRange(x, ..., varname = deparse(substitute(x))) : 
  3 not on interval (3, 6]
> 
> # check whether the input is an atomic vector of class numeric,
> # of length 3, and whose value all reside on the interval [1, 10)
> x <- c(3, pi, exp(1))
> checkVector(x, "numeric", c(1, 10), c(TRUE, FALSE), length = 3)
> 
> # do the same but change the expected length; expect error
> try(checkVector(x, "numeric", c(1, 10), c(TRUE, FALSE), length = 2))
Error in checkVector(x, "numeric", c(1, 10), c(TRUE, FALSE), length = 2) : 
  object 'varstr' not found
> 
> # create faux function to check input variable
> foo <- function(moo) checkVector(moo, "character")
> foo(letters)
> try(foo(1:5)) # expect error with function and argument name in message
Error in checkVector(moo, "character") : 
  In function foo : variable moo  must be vector of class  character
> 
> # check for equal lengths of various inputs
> checkLengths(1:2, 2:3, 3:4)
> try(checkLengths(1, 2, 3, 4:5)) # expect error
Error in checkLengths(1, 2, 3, 4:5) : 
  In function doTryCatch :lengths of inputs are not all equal
> 
> # check for equal length inputs but ignore single element vectors
> checkLengths(1, 2, 3, 4:5, 7:8, allowSingle = TRUE)
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("eEvents")
> ### * eEvents
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: eEvents
> ### Title: Expected number of events for a time-to-event study
> ### Aliases: eEvents print.eEvents
> ### Keywords: design
> 
> ### ** Examples
> 
> # 3 enrollment periods, 3 piecewise exponential failure rates
> str(eEvents(
+   lambda = c(.05, .02, .01), eta = .01, gamma = c(5, 10, 20),
+   R = c(2, 1, 2), S = c(1, 1), T = 20
+ ))
List of 11
 $ lambda: num [1:3, 1] 0.05 0.02 0.01
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:3] "0-1" "1-2" "2-20"
  .. ..$ : chr "Stratum 1"
 $ eta   : num [1:3, 1] 0.01 0.01 0.01
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:3] "0-1" "1-2" "2-20"
  .. ..$ : chr "Stratum 1"
 $ gamma : num [1:3, 1] 5 10 20
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:3] "0-2" "2-3" "3-5"
  .. ..$ : chr "Stratum 1"
 $ R     : num [1:3] 2 1 2
 $ S     : num [1:2] 1 1
 $ T     : num 20
 $ Tfinal: num 20
 $ minfup: num 0
 $ d     : num 11
 $ n     : num 60
 $ digits: num 4
 - attr(*, "class")= chr "eEvents"
> 
> # Control group for example from Bernstein and Lagakos (1978)
> lamC <- c(1, .8, .5)
> n <- eEvents(
+   lambda = matrix(c(lamC, lamC * 2 / 3), ncol = 6), eta = 0,
+   gamma = matrix(.5, ncol = 6), R = 2, T = 4
+ )
> 
> 
> 
> cleanEx()
> nameEx("gsBinomialExact")
> ### * gsBinomialExact
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gsBinomialExact
> ### Title: One-Sample Binomial Routines
> ### Aliases: gsBinomialExact print.gsBinomialExact binomialSPRT
> ###   plot.gsBinomialExact plot.binomialSPRT nBinomial1Sample
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> 
> zz <- gsBinomialExact(
+   k = 3, theta = seq(0.1, 0.9, 0.1), n.I = c(12, 24, 36),
+   a = c(-1, 0, 11), b = c(5, 9, 12)
+ )
> 
> # let's see what class this is
> class(zz)
[1] "gsBinomialExact" "gsProbability"  
> 
> # because of "gsProbability" class above, following is equivalent to
> # \code{print.gsProbability(zz)}
> zz
              Bounds
  Analysis   N   a   b
         1  12  -1   5
         2  24   0   9
         3  36  11  12

Boundary crossing probabilities and expected sample size assume
any cross stops the trial

Upper boundary
          Analysis
  Theta      1      2      3  Total E{N}
    0.1 0.0043 0.0002 0.0001 0.0045 34.9
    0.2 0.0726 0.0155 0.0168 0.1048 34.0
    0.3 0.2763 0.0993 0.1164 0.4921 28.2
    0.4 0.5618 0.1782 0.1362 0.8762 20.4
    0.5 0.8062 0.1372 0.0463 0.9896 15.0
    0.6 0.9427 0.0519 0.0052 0.9998 12.8
    0.7 0.9905 0.0093 0.0002 1.0000 12.1
    0.8 0.9994 0.0006 0.0000 1.0000 12.0
    0.9 1.0000 0.0000 0.0000 1.0000 12.0

Lower boundary
          Analysis
  Theta 1      2      3  Total
    0.1 0 0.0798 0.9157 0.9955
    0.2 0 0.0047 0.8905 0.8952
    0.3 0 0.0002 0.5077 0.5079
    0.4 0 0.0000 0.1238 0.1238
    0.5 0 0.0000 0.0104 0.0104
    0.6 0 0.0000 0.0002 0.0002
    0.7 0 0.0000 0.0000 0.0000
    0.8 0 0.0000 0.0000 0.0000
    0.9 0 0.0000 0.0000 0.0000
> 
> # also plot (see also plots below for \code{binomialSPRT})
> # add lines using geom_line()
> plot(zz) + 
+ ggplot2::geom_line()
> 
> # now for SPRT examples
> x <- binomialSPRT(p0 = .05, p1 = .25, alpha = .1, beta = .2)
> # boundary plot
> plot(x)
> # power plot
> plot(x, plottype = 2)
> # Response (event) rate at boundary
> plot(x, plottype = 3)
> # Expected sample size at boundary crossing or end of trial
> plot(x, plottype = 6)
> 
> # sample size for single arm exact binomial
> 
> # plot of table of power by sample size
> # note that outtype need not be specified if beta is NULL
> nb1 <- nBinomial1Sample(p0 = 0.05, p1=0.2,alpha = 0.025, beta=NULL, n = 25:40)
> nb1
     p0  p1 alpha      beta  n b      alphaR     Power
1  0.05 0.2 0.025 0.4206743 25 5 0.007164948 0.5793257
2  0.05 0.2 0.025 0.3833381 26 5 0.008511231 0.6166619
3  0.05 0.2 0.025 0.3480384 27 5 0.010022739 0.6519616
4  0.05 0.2 0.025 0.3148874 28 5 0.011708399 0.6851126
5  0.05 0.2 0.025 0.2839465 29 5 0.013576673 0.7160535
6  0.05 0.2 0.025 0.2552333 30 5 0.015635510 0.7447667
7  0.05 0.2 0.025 0.2287288 31 5 0.017892313 0.7712712
8  0.05 0.2 0.025 0.2043839 32 5 0.020353899 0.7956161
9  0.05 0.2 0.025 0.1821257 33 5 0.023026479 0.8178743
10 0.05 0.2 0.025 0.2996488 34 6 0.006269405 0.7003512
11 0.05 0.2 0.025 0.2720917 35 6 0.007251716 0.7279083
12 0.05 0.2 0.025 0.2463717 36 6 0.008340444 0.7536283
13 0.05 0.2 0.025 0.2224770 37 6 0.009541557 0.7775230
14 0.05 0.2 0.025 0.2003744 38 6 0.010860905 0.7996256
15 0.05 0.2 0.025 0.1800132 39 6 0.012304191 0.8199868
16 0.05 0.2 0.025 0.1613288 40 6 0.013876949 0.8386712
> library(scales)
> ggplot2::ggplot(nb1, ggplot2::aes(x = n, y = Power)) + 
+ ggplot2::geom_line() + 
+ ggplot2::geom_point() + 
+ ggplot2::scale_y_continuous(labels = percent)
> 
> # simple call with same parameters to get minimum sample size yielding desired power
> nBinomial1Sample(p0 = 0.05, p1 = 0.2, alpha = 0.025, beta = .2, n = 25:40)
[1] 33
> 
> # change to 'conservative' if you want all larger sample
> # sizes to also provide adequate power
> nBinomial1Sample(p0 = 0.05, p1 = 0.2, alpha = 0.025, beta = .2, n = 25:40, conservative = TRUE)
[1] 39
> 
> # print out more information for the selected derived sample size
> nBinomial1Sample(p0 = 0.05, p1 = 0.2, alpha = 0.025, beta = .2, n = 25:40, conservative = TRUE,
+  outtype = 2)
    p0  p1 alpha beta  n b     alphaR     Power
1 0.05 0.2 0.025  0.2 39 6 0.01230419 0.8199868
> # Reproduce realized Type I error alphaR
> stats::pbinom(q = 5, size = 39, prob = .05, lower.tail = FALSE)
[1] 0.01230419
> # Reproduce realized power
> stats::pbinom(q = 5, size = 39, prob = 0.2, lower.tail = FALSE)
[1] 0.8199868
> # Reproduce critical value for positive finding
> stats::qbinom(p = 1 - .025, size = 39, prob = .05) + 1
[1] 6
> # Compute p-value for 7 successes
> stats::pbinom(q = 6, size = 39, prob = .05, lower.tail = FALSE)
[1] 0.002922829
> # what happens if input sample sizes not sufficient?
> ## Not run: 
> ##D  
> ##D   nBinomial1Sample(p0 = 0.05, p1 = 0.2, alpha = 0.025, beta = .2, n = 25:30)
> ## End(Not run)
> 
> 
> 
> cleanEx()

detaching ‘package:scales’, ‘package:ggplot2’

> nameEx("gsBound")
> ### * gsBound
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gsBound
> ### Title: Boundary derivation - low level
> ### Aliases: gsBound gsBound1
> ### Keywords: design
> 
> ### ** Examples
> 
> 
> # set boundaries so that probability is .01 of first crossing
> # each upper boundary and .02 of crossing each lower boundary
> # under the null hypothesis
> x <- gsBound(
+   I = c(1, 2, 3) / 3, trueneg = rep(.02, 3),
+   falsepos = rep(.01, 3)
+ )
> x
$k
[1] 3

$theta
[1] 0

$I
[1] 0.3333333 0.6666667 1.0000000

$a
[1] -2.053749 -1.914183 -1.789206

$b
[1] 2.326348 2.219299 2.120127

$rates
$rates$falsepos
[1] 0.01 0.01 0.01

$rates$trueneg
[1] 0.02 0.02 0.02


$tol
[1] 1e-06

$r
[1] 18

$error
[1] 0

> 
> #  use gsBound1 to set up boundary for a 1-sided test
> x <- gsBound1(
+   theta = 0, I = c(1, 2, 3) / 3, a = rep(-20, 3),
+   probhi = c(.001, .009, .015)
+ )
> x$b
[1] 3.090232 2.344824 2.039501
> 
> # check boundary crossing probabilities with gsProbability
> y <- gsProbability(k = 3, theta = 0, n.I = x$I, a = x$a, b = x$b)$upper$prob
> 
> #  Note that gsBound1 only computes upper bound
> #  To get a lower bound under a parameter value theta:
> #      use minus the upper bound as a lower bound
> #      replace theta with -theta
> #      set probhi as desired lower boundary crossing probabilities
> #  Here we let set lower boundary crossing at 0.05 at each analysis
> #  assuming theta=2.2
> y <- gsBound1(
+   theta = -2.2, I = c(1, 2, 3) / 3, a = -x$b,
+   probhi = rep(.05, 3)
+ )
> y$b
[1]  0.3746830 -0.3594403 -0.9470061
> 
> #  Now use gsProbability to look at design
> #  Note that lower boundary crossing probabilities are as
> #  specified for theta=2.2, but for theta=0 the upper boundary
> #  crossing probabilities are smaller than originally specified
> #  above after first interim analysis
> gsProbability(k = length(x$b), theta = c(0, 2.2), n.I = x$I, b = x$b, a = -y$b)
               Lower bounds   Upper bounds
  Analysis N    Z   Nominal p  Z   Nominal p
         1  1 -0.37    0.3539 3.09    0.0010
         2  1  0.36    0.6404 2.34    0.0095
         3  1  0.95    0.8282 2.04    0.0207

Boundary crossing probabilities and expected sample size assume
any cross stops the trial

Upper boundary
          Analysis
  Theta      1      2      3  Total E{N}
    0.0 0.0010 0.0090 0.0146 0.0246  0.7
    2.2 0.0344 0.2601 0.2783 0.5728  0.8

Lower boundary
          Analysis
  Theta      1      2     3  Total
    0.0 0.3539 0.3153 0.184 0.8532
    2.2 0.0500 0.0500 0.050 0.1500
> 
> 
> 
> cleanEx()
> nameEx("gsBoundCP")
> ### * gsBoundCP
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gsBoundCP
> ### Title: Conditional Power at Interim Boundaries
> ### Aliases: gsBoundCP
> ### Keywords: design
> 
> ### ** Examples
> 
> 
> # set up a group sequential design
> x <- gsDesign(k = 5)
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.220 -0.90    0.1836 0.0077 3.25    0.0006  0.0006
         2  0.441 -0.04    0.4853 0.0115 2.99    0.0014  0.0013
         3  0.661  0.69    0.7563 0.0171 2.69    0.0036  0.0028
         4  0.881  1.36    0.9131 0.0256 2.37    0.0088  0.0063
         5  1.101  2.03    0.9786 0.0381 2.03    0.0214  0.0140
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Hwang-Shih-DeCani spending function with gamma = -2.
++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4      5  Total   E{N}
  0.0000 0.0006 0.0013 0.0028 0.0062 0.0117 0.0226 0.5726
  3.2415 0.0417 0.1679 0.2806 0.2654 0.1444 0.9000 0.7440

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4      5  Total
  0.0000 0.1836 0.3201 0.2700 0.1477 0.0559 0.9774
  3.2415 0.0077 0.0115 0.0171 0.0256 0.0381 0.1000
> 
> # compute conditional power based on interim treatment effects
> gsBoundCP(x)
             CPlo      CPhi
[1,] 2.294534e-06 1.0000001
[2,] 2.238566e-03 0.9998352
[3,] 2.669114e-02 0.9922459
[4,] 1.296705e-01 0.9200502
> 
> # compute conditional power based on original x$delta
> gsBoundCP(x, theta = x$delta)
          CPlo      CPhi
[1,] 0.4936972 0.9940265
[2,] 0.3676577 0.9954019
[3,] 0.3331896 0.9912361
[4,] 0.3871332 0.9590607
> 
> 
> 
> cleanEx()
> nameEx("gsBoundSummary")
> ### * gsBoundSummary
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.gsDesign
> ### Title: Bound Summary and Z-transformations
> ### Aliases: summary.gsDesign print.gsDesign gsBoundSummary xprint
> ###   print.gsBoundSummary gsBValue gsDelta gsRR gsHR gsCPz
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # survival endpoint using gsSurv
> # generally preferred over nSurv since time computations are shown
> xgs <- gsSurv(lambdaC = .2, hr = .5, eta = .1, T = 2, minfup = 1.5)
> gsBoundSummary(xgs, timename = "Year", tdigits = 1)
Method: LachinFoulkes 
   Analysis              Value Efficacy Futility
  IA 1: 33%                  Z   3.0107  -0.2388
     N: 460        p (1-sided)   0.0013   0.5944
 Events: 33       ~HR at bound   0.3457   1.0879
  Year: 0.8   P(Cross) if HR=1   0.0013   0.4056
            P(Cross) if HR=0.5   0.1412   0.0148
  IA 2: 67%                  Z   2.5465   0.9410
     N: 460        p (1-sided)   0.0054   0.1733
 Events: 65       ~HR at bound   0.5298   0.7907
  Year: 1.3   P(Cross) if HR=1   0.0062   0.8347
            P(Cross) if HR=0.5   0.5815   0.0437
      Final                  Z   1.9992   1.9992
     N: 460        p (1-sided)   0.0228   0.0228
 Events: 97       ~HR at bound   0.6655   0.6655
    Year: 2   P(Cross) if HR=1   0.0233   0.9767
            P(Cross) if HR=0.5   0.9000   0.1000
> summary(xgs)
[1] "Asymmetric two-sided group sequential design with non-binding futility bound, 3 analyses, time-to-event outcome with sample size 460 and 97 events required, 90 percent power, 2.5 percent (1-sided) Type I error to detect a hazard ratio of 0.5. Enrollment and total study durations are assumed to be 0.5 and 2 months, respectively. Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4. Futility bounds derived using a Hwang-Shih-DeCani spending function with gamma = -2."
> 
> # survival endpoint using nSurvival
> # NOTE: generally recommend gsSurv above for this!
> ss <- nSurvival(
+   lambda1 = .2, lambda2 = .1, eta = .1, Ts = 2, Tr = .5,
+   sided = 1, alpha = .025, ratio = 2
+ )
> xs <- gsDesign(nFixSurv = ss$n, n.fix = ss$nEvents, delta1 = log(ss$lambda2 / ss$lambda1))
> gsBoundSummary(xs, logdelta = TRUE, ratio = ss$ratio)
  Analysis              Value Efficacy Futility
 IA 1: 33%                  Z   3.0107  -0.2387
     N: 34        p (1-sided)   0.0013   0.5943
                 ~HR at bound   0.3306   1.0917
             P(Cross) if HR=1   0.0013   0.4057
           P(Cross) if HR=0.5   0.1412   0.0148
 IA 2: 67%                  Z   2.5465   0.9411
     N: 67        p (1-sided)   0.0054   0.1733
                 ~HR at bound   0.5158   0.7830
             P(Cross) if HR=1   0.0062   0.8347
           P(Cross) if HR=0.5   0.5815   0.0437
     Final                  Z   1.9992   1.9992
    N: 100        p (1-sided)   0.0228   0.0228
                 ~HR at bound   0.6542   0.6542
             P(Cross) if HR=1   0.0233   0.9767
           P(Cross) if HR=0.5   0.9000   0.1000
> # generate some of the above summary statistics for the upper bound
> z <- xs$upper$bound
> # B-values
> gsBValue(z = z, i = 1:3, x = xs)
[1] 1.738251 2.079233 1.999226
> # hazard ratio
> gsHR(z = z, i = 1:3, x = xs)
[1] 0.3521851 0.5357126 0.6702573
> # conditional power at observed treatment effect
> gsCPz(z = z[1:2], i = 1:2, x = xs)
[1] 0.9999676 0.9737643
> # conditional power at H1 treatment effect
> gsCPz(z = z[1:2], i = 1:2, x = xs, theta = xs$delta)
[1] 0.9937804 0.9809768
> 
> # information-based design
> xinfo <- gsDesign(delta = .3, delta1 = .3)
> gsBoundSummary(xinfo, Nname = "Information")
            Analysis                 Value Efficacy Futility
           IA 1: 33%                     Z   3.0107  -0.2387
  Information: 41.64           p (1-sided)   0.0013   0.5943
                           ~delta at bound   0.4666  -0.0370
                       P(Cross) if delta=0   0.0013   0.4057
                     P(Cross) if delta=0.3   0.1412   0.0148
           IA 2: 67%                     Z   2.5465   0.9411
  Information: 83.27           p (1-sided)   0.0054   0.1733
                           ~delta at bound   0.2791   0.1031
                       P(Cross) if delta=0   0.0062   0.8347
                     P(Cross) if delta=0.3   0.5815   0.0437
               Final                     Z   1.9992   1.9992
 Information: 124.91           p (1-sided)   0.0228   0.0228
                           ~delta at bound   0.1789   0.1789
                       P(Cross) if delta=0   0.0233   0.9767
                     P(Cross) if delta=0.3   0.9000   0.1000
> 
> # show all available boundary descriptions
> gsBoundSummary(xinfo, Nname = "Information", exclude = NULL)
            Analysis                 Value Efficacy Futility
           IA 1: 33%                     Z   3.0107  -0.2387
  Information: 41.64           p (1-sided)   0.0013   0.5943
                           ~delta at bound   0.4666  -0.0370
                                  Spending   0.0013   0.0148
                                   B-value   1.7383  -0.1378
                                        CP   1.0000   0.0012
                                     CP H1   0.9938   0.4689
                                        PP   0.9897   0.0373
                       P(Cross) if delta=0   0.0013   0.4057
                     P(Cross) if delta=0.3   0.1412   0.0148
           IA 2: 67%                     Z   2.5465   0.9411
  Information: 83.27           p (1-sided)   0.0054   0.1733
                           ~delta at bound   0.2791   0.1031
                                  Spending   0.0049   0.0289
                                   B-value   2.0792   0.7684
                                        CP   0.9738   0.0713
                                     CP H1   0.9810   0.4223
                                        PP   0.9427   0.1157
                       P(Cross) if delta=0   0.0062   0.8347
                     P(Cross) if delta=0.3   0.5815   0.0437
               Final                     Z   1.9992   1.9992
 Information: 124.91           p (1-sided)   0.0228   0.0228
                           ~delta at bound   0.1789   0.1789
                                  Spending   0.0188   0.0563
                                   B-value   1.9992   1.9992
                       P(Cross) if delta=0   0.0233   0.9767
                     P(Cross) if delta=0.3   0.9000   0.1000
> 
> # add intermediate parameter value
> xinfo <- gsProbability(d = xinfo, theta = c(0, .15, .3))
> class(xinfo) # note this is still as gsDesign class object
[1] "gsDesign"
> gsBoundSummary(xinfo, Nname = "Information")
            Analysis                  Value Efficacy Futility
           IA 1: 33%                      Z   3.0107  -0.2387
  Information: 41.64            p (1-sided)   0.0013   0.5943
                            ~delta at bound   0.4666  -0.0370
                        P(Cross) if delta=0   0.0013   0.4057
                     P(Cross) if delta=0.15   0.0205   0.1138
                      P(Cross) if delta=0.3   0.1412   0.0148
           IA 2: 67%                      Z   2.5465   0.9411
  Information: 83.27            p (1-sided)   0.0054   0.1733
                            ~delta at bound   0.2791   0.1031
                        P(Cross) if delta=0   0.0062   0.8347
                     P(Cross) if delta=0.15   0.1243   0.3523
                      P(Cross) if delta=0.3   0.5815   0.0437
               Final                      Z   1.9992   1.9992
 Information: 124.91            p (1-sided)   0.0228   0.0228
                            ~delta at bound   0.1789   0.1789
                        P(Cross) if delta=0   0.0233   0.9767
                     P(Cross) if delta=0.15   0.3636   0.6364
                      P(Cross) if delta=0.3   0.9000   0.1000
> 
> # now look at a binomial endpoint; specify H0 treatment difference as p1-p2=.05
> # now treatment effect at bound (say, thetahat) is transformed to
> # xp$delta0 + xp$delta1*(thetahat-xp$delta0)/xp$delta
> np <- nBinomial(p1 = .15, p2 = .10)
> xp <- gsDesign(n.fix = np, endpoint = "Binomial", delta1 = .05)
> summary(xp)
[1] "Asymmetric two-sided group sequential design with non-binding futility bound, 3 analyses, sample size 1963, 90 percent power, 2.5 percent (1-sided) Type I error. Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4. Futility bounds derived using a Hwang-Shih-DeCani spending function with gamma = -2."
> gsBoundSummary(xp, deltaname = "p[C]-p[E]")
  Analysis                      Value Efficacy Futility
 IA 1: 33%                          Z   3.0107  -0.2387
    N: 655                p (1-sided)   0.0013   0.5943
                  ~p[C]-p[E] at bound   0.0778  -0.0062
              P(Cross) if p[C]-p[E]=0   0.0013   0.4057
           P(Cross) if p[C]-p[E]=0.05   0.1412   0.0148
 IA 2: 67%                          Z   2.5465   0.9411
   N: 1309                p (1-sided)   0.0054   0.1733
                  ~p[C]-p[E] at bound   0.0465   0.0172
              P(Cross) if p[C]-p[E]=0   0.0062   0.8347
           P(Cross) if p[C]-p[E]=0.05   0.5815   0.0437
     Final                          Z   1.9992   1.9992
   N: 1963                p (1-sided)   0.0228   0.0228
                  ~p[C]-p[E] at bound   0.0298   0.0298
              P(Cross) if p[C]-p[E]=0   0.0233   0.9767
           P(Cross) if p[C]-p[E]=0.05   0.9000   0.1000
> # estimate treatment effect at lower bound
> # by setting delta0=0 (default) and delta1 above in gsDesign
> # treatment effect at bounds is scaled to these differences
> # in this case, this is the difference in event rates
> gsDelta(z = xp$lower$bound, i = 1:3, xp)
[1] -0.006166098  0.017187789  0.029813687
> 
> # binomial endpoint with risk ratio estimates
> n.fix <- nBinomial(p1 = .3, p2 = .15, scale = "RR")
> xrr <- gsDesign(k = 2, n.fix = n.fix, delta1 = log(.15 / .3), endpoint = "Binomial")
> gsBoundSummary(xrr, deltaname = "RR", logdelta = TRUE)
  Analysis              Value Efficacy Futility
 IA 1: 50%                  Z   2.7500   0.4122
    N: 168        p (1-sided)   0.0030   0.3401
                 ~RR at bound   0.4429   0.8851
             P(Cross) if RR=1   0.0030   0.6599
           P(Cross) if RR=0.5   0.3412   0.0269
     Final                  Z   1.9811   1.9811
    N: 336        p (1-sided)   0.0238   0.0238
                 ~RR at bound   0.6605   0.6605
             P(Cross) if RR=1   0.0239   0.9761
           P(Cross) if RR=0.5   0.9000   0.1000
> gsRR(z = xp$lower$bound, i = 1:3, xrr)
[1] 1.0732500 0.8211496        NA
> plot(xrr, plottype = "RR")
> 
> # delta is odds-ratio: sample size slightly smaller than for relative risk or risk difference
> n.fix <- nBinomial(p1 = .3, p2 = .15, scale = "OR")
> xOR <- gsDesign(k = 2, n.fix = n.fix, delta1 = log(.15 / .3 / .85 * .7), endpoint = "Binomial")
> gsBoundSummary(xOR, deltaname = "OR", logdelta = TRUE)
  Analysis               Value Efficacy Futility
 IA 1: 50%                   Z   2.7500   0.4122
    N: 166         p (1-sided)   0.0030   0.3401
                  ~OR at bound   0.3526   0.8553
              P(Cross) if OR=1   0.0030   0.6599
           P(Cross) if OR=0.41   0.3412   0.0269
     Final                   Z   1.9811   1.9811
    N: 332         p (1-sided)   0.0238   0.0238
                  ~OR at bound   0.5880   0.5880
              P(Cross) if OR=1   0.0239   0.9761
           P(Cross) if OR=0.41   0.9000   0.1000
> 
> # for nice LaTeX table output, use xprint
> xprint(xtable::xtable(gsBoundSummary(xOR, deltaname = "OR", logdelta = TRUE),
+   caption = "Table caption."
+ ))
% latex table generated in R 4.5.0 by xtable 1.8-8 package
% Wed Feb 25 16:26:31 2026
\begin{table}[ht]
\centering
\begin{tabular}{llrr}
  \hline
Analysis & Value & Efficacy & Futility \\ 
  \hline
IA 1: 50\% & Z & 2.75 & 0.41 \\ 
  N: 166 & p (1-sided) & 0.00 & 0.34 \\ 
   & \~{}OR at bound & 0.35 & 0.86 \\ 
   & P(Cross) if OR=1 & 0.00 & 0.66 \\ 
   & P(Cross) if OR=0.41 & 0.34 & 0.03 \\ 
   \hline
Final & Z & 1.98 & 1.98 \\ 
  N: 332 & p (1-sided) & 0.02 & 0.02 \\ 
   & \~{}OR at bound & 0.59 & 0.59 \\ 
   & P(Cross) if OR=1 & 0.02 & 0.98 \\ 
   & P(Cross) if OR=0.41 & 0.90 & 0.10 \\ 
   \hline
\end{tabular}
\caption{Table caption.} 
\end{table}
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("gsCP")
> ### * gsCP
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gsCP
> ### Title: Conditional and Predictive Power, Overall and Conditional
> ###   Probability of Success
> ### Aliases: gsCP gsPP gsPI gsPosterior gsPOS gsCPOS
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # set up a group sequential design
> x <- gsDesign(k = 5)
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.220 -0.90    0.1836 0.0077 3.25    0.0006  0.0006
         2  0.441 -0.04    0.4853 0.0115 2.99    0.0014  0.0013
         3  0.661  0.69    0.7563 0.0171 2.69    0.0036  0.0028
         4  0.881  1.36    0.9131 0.0256 2.37    0.0088  0.0063
         5  1.101  2.03    0.9786 0.0381 2.03    0.0214  0.0140
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Hwang-Shih-DeCani spending function with gamma = -2.
++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4      5  Total   E{N}
  0.0000 0.0006 0.0013 0.0028 0.0062 0.0117 0.0226 0.5726
  3.2415 0.0417 0.1679 0.2806 0.2654 0.1444 0.9000 0.7440

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4      5  Total
  0.0000 0.1836 0.3201 0.2700 0.1477 0.0559 0.9774
  3.2415 0.0077 0.0115 0.0171 0.0256 0.0381 0.1000
> 
> # set up a prior distribution for the treatment effect
> # that is normal with mean .75*x$delta and standard deviation x$delta/2
> mu0 <- .75 * x$delta
> sigma0 <- x$delta / 2
> prior <- normalGrid(mu = mu0, sigma = sigma0)
> 
> # compute POS for the design given the above prior distribution for theta
> gsPOS(x = x, theta = prior$z, wgts = prior$wgts)
[1] 0.5954771
> 
> # assume POS should only count cases in prior where theta >= x$delta/2
> gsPOS(x = x, theta = prior$z, wgts = prior$wgts * (prior$z >= x$delta / 2))
[1] 0.5554313
> 
> # assuming a z-value at lower bound at analysis 2, what are conditional
> # boundary crossing probabilities for future analyses
> # assuming theta values from x as well as a value based on the interim
> # observed z
> CP <- gsCP(x, i = 2, zi = x$lower$bound[2])
> CP
              Lower bounds   Upper bounds
  Analysis N   Z   Nominal p  Z   Nominal p
         1  1 1.25    0.8952 4.71    0.0000
         2  1 1.96    0.9750 3.39    0.0003
         3  1 2.64    0.9959 2.64    0.0041

Boundary crossing probabilities and expected sample size assume
any cross stops the trial

Upper boundary
          Analysis
    Theta     1      2      3  Total E{N}
  -0.0554 0e+00 0.0003 0.0019 0.0022  0.2
   0.0000 0e+00 0.0003 0.0022 0.0026  0.2
   3.2415 7e-04 0.1038 0.2631 0.3677  0.4

Lower boundary
          Analysis
    Theta      1      2      3  Total
  -0.0554 0.8999 0.0841 0.0138 0.9978
   0.0000 0.8952 0.0872 0.0150 0.9974
   3.2415 0.3950 0.1368 0.1006 0.6323
> 
> # summing values for crossing future upper bounds gives overall
> # conditional power for each theta value
> CP$theta
[1] -0.05536767  0.00000000  3.24151555
> t(CP$upper$prob) %*% c(1, 1, 1)
            [,1]
[1,] 0.002238566
[2,] 0.002561570
[3,] 0.367657692
> 
> # compute predictive probability based on above assumptions
> gsPP(x, i = 2, zi = x$lower$bound[2], theta = prior$z, wgts = prior$wgts)
[1] 0.06730167
> 
> # if it is known that boundary not crossed at interim 2, use
> # gsCPOS to compute conditional POS based on this
> gsCPOS(x = x, i = 2, theta = prior$z, wgts = prior$wgts)
[1] 0.6114033
> 
> # 2-stage example to compare results to direct computation
> x <- gsDesign(k = 2)
> z1 <- 0.5
> n1 <- x$n.I[1]
> n2 <- x$n.I[2] - x$n.I[1]
> thetahat <- z1 / sqrt(n1)
> theta <- c(thetahat, 0, x$delta)
> 
> # conditional power direct computation - comparison w gsCP
> pnorm((n2 * theta + z1 * sqrt(n1) - x$upper$bound[2] * sqrt(n1 + n2)) / sqrt(n2))
[1] 0.03579292 0.01067483 0.51555676
> 
> gsCP(x = x, zi = z1, i = 1)$upper$prob
           [,1]       [,2]      [,3]
[1,] 0.03579292 0.01067483 0.5155568
> 
> # predictive power direct computation - comparison w gsPP
> # use same prior as above
> mu0 <- .75 * x$delta * sqrt(x$n.I[2])
> sigma2 <- (.5 * x$delta)^2 * x$n.I[2]
> prior <- normalGrid(mu = .75 * x$delta, sigma = x$delta / 2)
> gsPP(x = x, zi = z1, i = 1, theta = prior$z, wgts = prior$wgts)
[1] 0.1556447
> t <- .5
> z1 <- .5
> b <- z1 * sqrt(t)
> # direct from Proschan, Lan and Wittes eqn 3.10
> # adjusted drift at n.I[2]
> pnorm(((b - x$upper$bound[2]) * (1 + t * sigma2) +
+   (1 - t) * (mu0 + b * sigma2)) /
+   sqrt((1 - t) * (1 + sigma2) * (1 + t * sigma2)))
[1] 0.1556447
> 
> # plot prior then posterior distribution for unblinded analysis with i=1, zi=1
> xp <- gsPosterior(x = x, i = 1, zi = 1, prior = prior)
> plot(x = xp$z, y = xp$density, type = "l", col = 2, xlab = expression(theta), ylab = "Density")
> points(x = x$z, y = x$density, col = 1)
> 
> # add posterior plot assuming only knowlede that interim bound has
> # not been crossed at interim 1
> xpb <- gsPosterior(x = x, i = 1, zi = 1, prior = prior)
> lines(x = xpb$z, y = xpb$density, col = 4)
> 
> # prediction interval based in interim 1 results
> # start with point estimate, followed by 90% prediction interval
> gsPI(x = x, i = 1, zi = z1, j = 2, theta = prior$z, wgts = prior$wgts, level = 0)
[1] 1.081745
> gsPI(x = x, i = 1, zi = z1, j = 2, theta = prior$z, wgts = prior$wgts, level = .9)
[1] -0.3793133  2.5428090
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("gsDensity")
> ### * gsDensity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gsDensity
> ### Title: Group sequential design interim density function
> ### Aliases: gsDensity
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # set up a group sequential design
> x <- gsDesign()
> 
> # set theta values where density is to be evaluated
> theta <- x$theta[2] * c(0, .5, 1, 1.5)
> 
> # set zi values from -1 to 7 where density is to be evaluated
> zi <- seq(-3, 7, .05)
> 
> # compute subdensity values at analysis 2
> y <- gsDensity(x, theta = theta, i = 2, zi = zi)
> 
> # plot sub-density function for each theta value
> plot(y$zi, y$density[, 3],
+   type = "l", xlab = "Z",
+   ylab = "Interim 2 density", lty = 3, lwd = 2
+ )
> lines(y$zi, y$density[, 2], lty = 2, lwd = 2)
> lines(y$zi, y$density[, 1], lwd = 2)
> lines(y$zi, y$density[, 4], lty = 4, lwd = 2)
> title("Sub-density functions at interim analysis 2")
> legend(
+   x = c(3.85, 7.2), y = c(.27, .385), lty = 1:5, lwd = 2, cex = 1.5,
+   legend = c(
+     expression(paste(theta, "=0.0")),
+     expression(paste(theta, "=0.5", delta)),
+     expression(paste(theta, "=1.0", delta)),
+     expression(paste(theta, "=1.5", delta))
+   )
+ )
> 
> # add vertical lines with lower and upper bounds at analysis 2
> # to demonstrate how likely it is to continue, stop for futility
> # or stop for efficacy at analysis 2 by treatment effect
> lines(rep(x$upper$bound[2], 2), c(0, .4), col = 2)
> lines(rep(x$lower$bound[2], 2), c(0, .4), lty = 2, col = 2)
> 
> # Replicate part of figures 8.1 and 8.2 of Jennison and Turnbull text book
> # O'Brien-Fleming design with four analyses
> 
> x <- gsDesign(k = 4, test.type = 2, sfu = "OF", alpha = .1, beta = .2)
> 
> z <- seq(-4.2, 4.2, .05)
> d <- gsDensity(x = x, theta = x$theta, i = 4, zi = z)
> 
> plot(z, d$density[, 1], type = "l", lwd = 2, ylab = expression(paste(p[4], "(z,", theta, ")")))
> lines(z, d$density[, 2], lty = 2, lwd = 2)
> u <- x$upper$bound[4]
> text(expression(paste(theta, "=", delta)), x = 2.2, y = .2, cex = 1.5)
> text(expression(paste(theta, "=0")), x = .55, y = .4, cex = 1.5)
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("gsDesign")
> ### * gsDesign
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gsDesign
> ### Title: Design Derivation
> ### Aliases: gsDesign xtable.gsDesign
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> #  symmetric, 2-sided design with O'Brien-Fleming-like boundaries
> #  lower bound is non-binding (ignored in Type I error computation)
> #  sample size is computed based on a fixed design requiring n=800
> x <- gsDesign(k = 5, test.type = 2, n.fix = 800)
> 
> # note that "x" below is equivalent to print(x) and print.gsDesign(x)
> x
Symmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Spending computations assume trial stops
if a bound is crossed.

              
  Analysis  N   Z   Nominal p  Spend
         1 164 3.25    0.0006 0.0006
         2 328 2.99    0.0014 0.0013
         3 492 2.69    0.0036 0.0028
         4 656 2.37    0.0088 0.0063
         5 819 2.03    0.0214 0.0140
     Total                    0.0250 

++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4      5 Total  E{N}
  0.0000 0.0006 0.0013 0.0028 0.0063 0.0140 0.025 812.8
  0.1146 0.0370 0.1512 0.2647 0.2699 0.1771 0.900 589.3

Lower boundary (futility or Type II Error)
          Analysis
   Theta     1      2      3      4     5 Total
  0.0000 6e-04 0.0013 0.0028 0.0063 0.014 0.025
  0.1146 0e+00 0.0000 0.0000 0.0000 0.000 0.000
> plot(x)
> plot(x, plottype = 2)
> 
> # Assuming after trial was designed actual analyses occurred after
> # 300, 600, and 860 patients, reset bounds
> y <- gsDesign(
+   k = 3, test.type = 2, n.fix = 800, n.I = c(300, 600, 860),
+   maxn.IPlan = x$n.I[x$k]
+ )
> y
Symmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Spending computations assume trial stops
if a bound is crossed.

              
  Analysis  N   Z   Nominal p  Spend
         1 300 2.96    0.0016 0.0016
         2 600 2.44    0.0074 0.0067
         3 860 2.01    0.0220 0.0167
     Total                    0.0250 

++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3  Total  E{N}
  0.0000 0.0016 0.0067 0.0167 0.0250 854.8
  0.1146 0.1655 0.4833 0.2654 0.9142 641.6

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3 Total
  0.0000 0.0016 0.0067 0.0167 0.025
  0.1146 0.0000 0.0000 0.0000 0.000
> 
> #  asymmetric design with user-specified spending that is non-binding
> #  sample size is computed relative to a fixed design with n=1000
> sfup <- c(.033333, .063367, .1)
> sflp <- c(.25, .5, .75)
> timing <- c(.1, .4, .7)
> x <- gsDesign(
+   k = 4, timing = timing, sfu = sfPoints, sfupar = sfup, sfl = sfPoints,
+   sflpar = sflp, n.fix = 1000
+ )
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

                  ----Lower bounds----  ----Upper bounds-----
  Analysis   N    Z   Nominal p Spend+  Z   Nominal p Spend++
         1  123 -0.83    0.2041  0.025 3.14    0.0008  0.0008
         2  489  0.39    0.6513  0.025 3.16    0.0008  0.0008
         3  855  1.26    0.8966  0.025 3.06    0.0011  0.0009
         4 1222  1.98    0.9761  0.025 1.98    0.0239  0.0225
     Total                      0.1000                 0.0250 
+ lower bound beta spending (under H1):
 User-specified spending function with Points = 0.25, Points = 0.5, Points = 0.75, Points = 1.
++ alpha spending:
 User-specified spending function with Points = 0.03333, Points = 0.06337, Points = 0.1, Points = 1.

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4  Total  E{N}
  0.0000 0.0008 0.0007 0.0009 0.0177 0.0202 564.0
  0.1025 0.0222 0.1716 0.2969 0.4094 0.9000 907.4

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4  Total
  0.0000 0.2041 0.4703 0.2361 0.0693 0.9798
  0.1025 0.0250 0.0250 0.0250 0.0250 0.1000
> plot(x)
> plot(x, plottype = 2)
> 
> # same design, but with relative sample sizes
> gsDesign(
+   k = 4, timing = timing, sfu = sfPoints, sfupar = sfup, sfl = sfPoints,
+   sflpar = sflp
+ )
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.122 -0.83    0.2041  0.025 3.14    0.0008  0.0008
         2  0.488  0.39    0.6513  0.025 3.16    0.0008  0.0008
         3  0.855  1.26    0.8966  0.025 3.06    0.0011  0.0009
         4  1.221  1.98    0.9761  0.025 1.98    0.0239  0.0225
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 User-specified spending function with Points = 0.25, Points = 0.5, Points = 0.75, Points = 1.
++ alpha spending:
 User-specified spending function with Points = 0.03333, Points = 0.06337, Points = 0.1, Points = 1.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4  Total   E{N}
  0.0000 0.0008 0.0007 0.0009 0.0177 0.0202 0.5640
  3.2415 0.0222 0.1716 0.2969 0.4094 0.9000 0.9074

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4  Total
  0.0000 0.2041 0.4703 0.2361 0.0693 0.9798
  3.2415 0.0250 0.0250 0.0250 0.0250 0.1000
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("gsProbability")
> ### * gsProbability
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gsProbability
> ### Title: Boundary Crossing Probabilities
> ### Aliases: gsProbability print.gsProbability
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # making a gsDesign object first may be easiest...
> x <- gsDesign()
> 
> # take a look at it
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.357 -0.24    0.4057 0.0148 3.01    0.0013  0.0013
         2  0.713  0.94    0.8267 0.0289 2.55    0.0054  0.0049
         3  1.070  2.00    0.9772 0.0563 2.00    0.0228  0.0188
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Hwang-Shih-DeCani spending function with gamma = -2.
++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3  Total   E{N}
  0.0000 0.0013 0.0049 0.0171 0.0233 0.6249
  3.2415 0.1412 0.4403 0.3185 0.9000 0.7913

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3  Total
  0.0000 0.4057 0.4290 0.1420 0.9767
  3.2415 0.0148 0.0289 0.0563 0.1000
> 
> # default plot for gsDesign object shows boundaries
> plot(x)
> 
> # \code{plottype=2} shows boundary crossing probabilities
> plot(x, plottype = 2)
> 
> # now add boundary crossing probabilities and
> # expected sample size for more theta values
> y <- gsProbability(d = x, theta = x$delta * seq(0, 2, .25))
> class(y)
[1] "gsDesign"
> 
> # note that "y" below is equivalent to \code{print(y)} and
> # \code{print.gsProbability(y)}
> y
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.357 -0.24    0.4057 0.0148 3.01    0.0013  0.0013
         2  0.713  0.94    0.8267 0.0289 2.55    0.0054  0.0049
         3  1.070  2.00    0.9772 0.0563 2.00    0.0228  0.0188
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Hwang-Shih-DeCani spending function with gamma = -2.
++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3  Total   E{N}
  0.0000 0.0013 0.0049 0.0171 0.0233 0.6249
  0.8104 0.0058 0.0279 0.0872 0.1209 0.7523
  1.6208 0.0205 0.1038 0.2393 0.3636 0.8520
  2.4311 0.0595 0.2579 0.3636 0.6810 0.8668
  3.2415 0.1412 0.4403 0.3185 0.9000 0.7913
  4.0519 0.2773 0.5353 0.1684 0.9810 0.6765
  4.8623 0.4574 0.4844 0.0559 0.9976 0.5701
  5.6727 0.6469 0.3410 0.0119 0.9998 0.4868
  6.4830 0.8053 0.1930 0.0016 1.0000 0.4266

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3  Total
  0.0000 0.4057 0.4290 0.1420 0.9767
  0.8104 0.2349 0.3812 0.2630 0.8791
  1.6208 0.1138 0.2385 0.2841 0.6364
  2.4311 0.0455 0.1017 0.1718 0.3190
  3.2415 0.0148 0.0289 0.0563 0.1000
  4.0519 0.0039 0.0054 0.0097 0.0190
  4.8623 0.0008 0.0006 0.0009 0.0024
  5.6727 0.0001 0.0001 0.0000 0.0002
  6.4830 0.0000 0.0000 0.0000 0.0000
> 
> # the plot does not change from before since this is a
> # gsDesign object; note that theta/delta is on x axis
> plot(y, plottype = 2)
> 
> # now let's see what happens with a gsProbability object
> z <- gsProbability(
+   k = 3, a = x$lower$bound, b = x$upper$bound,
+   n.I = x$n.I, theta = x$delta * seq(0, 2, .25)
+ )
> 
> # with the above form,  the results is a gsProbability object
> class(z)
[1] "gsProbability"
> z
              Lower bounds   Upper bounds
  Analysis N    Z   Nominal p  Z   Nominal p
         1  1 -0.24    0.4057 3.01    0.0013
         2  1  0.94    0.8267 2.55    0.0054
         3  2  2.00    0.9772 2.00    0.0228

Boundary crossing probabilities and expected sample size assume
any cross stops the trial

Upper boundary
          Analysis
   Theta      1      2      3  Total E{N}
  0.0000 0.0013 0.0049 0.0171 0.0233  0.6
  0.8104 0.0058 0.0279 0.0872 0.1209  0.8
  1.6208 0.0205 0.1038 0.2393 0.3636  0.9
  2.4311 0.0595 0.2579 0.3636 0.6810  0.9
  3.2415 0.1412 0.4403 0.3185 0.9000  0.8
  4.0519 0.2773 0.5353 0.1684 0.9810  0.7
  4.8623 0.4574 0.4844 0.0559 0.9976  0.6
  5.6727 0.6469 0.3410 0.0119 0.9998  0.5
  6.4830 0.8053 0.1930 0.0016 1.0000  0.4

Lower boundary
          Analysis
   Theta      1      2      3  Total
  0.0000 0.4057 0.4290 0.1420 0.9767
  0.8104 0.2349 0.3812 0.2630 0.8791
  1.6208 0.1138 0.2385 0.2841 0.6364
  2.4311 0.0455 0.1017 0.1718 0.3190
  3.2415 0.0148 0.0289 0.0563 0.1000
  4.0519 0.0039 0.0054 0.0097 0.0190
  4.8623 0.0008 0.0006 0.0009 0.0024
  5.6727 0.0001 0.0001 0.0000 0.0002
  6.4830 0.0000 0.0000 0.0000 0.0000
> 
> # default plottype is now 2
> # this is the same range for theta, but plot now has theta on x axis
> plot(z)
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("gsSurvCalendar")
> ### * gsSurvCalendar
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gsSurvCalendar
> ### Title: Group sequential design with calendar-based timing of analyses
> ### Aliases: gsSurvCalendar
> 
> ### ** Examples
> 
> # First example: while timing is calendar-based, spending is event-based
> x <- gsSurvCalendar() |> toInteger()
> gsBoundSummary(x)
    Analysis              Value Efficacy Futility
   IA 1: 29%                  Z   3.0856  -0.4349
      N: 130        p (1-sided)   0.0010   0.6682
  Events: 50       ~HR at bound   0.4178   1.1309
   Month: 12   P(Cross) if HR=1   0.0010   0.3318
             P(Cross) if HR=0.6   0.1018   0.0122
   IA 2: 79%                  Z   2.3279   1.3991
      N: 194        p (1-sided)   0.0100   0.0809
 Events: 137       ~HR at bound   0.6718   0.7874
   Month: 24   P(Cross) if HR=1   0.0106   0.9213
             P(Cross) if HR=0.6   0.7505   0.0606
       Final                  Z   2.0154   2.0154
      N: 194        p (1-sided)   0.0219   0.0219
 Events: 173       ~HR at bound   0.7361   0.7361
   Month: 36   P(Cross) if HR=1   0.0228   0.9772
             P(Cross) if HR=0.6   0.9001   0.0999
> 
> # Second example: both timing and spending are calendar-based
> # This results in less spending at interims and leaves more for final analysis
> y <- gsSurvCalendar(spending = "calendar") |> toInteger()
> gsBoundSummary(y)
    Analysis              Value Efficacy Futility
   IA 1: 29%                  Z   3.0107  -0.3784
      N: 126        p (1-sided)   0.0013   0.6474
  Events: 49       ~HR at bound   0.4231   1.1142
   Month: 12   P(Cross) if HR=1   0.0013   0.3526
             P(Cross) if HR=0.6   0.1123   0.0148
   IA 2: 79%                  Z   2.5581   1.1380
      N: 188        p (1-sided)   0.0053   0.1276
 Events: 133       ~HR at bound   0.6417   0.8209
   Month: 24   P(Cross) if HR=1   0.0062   0.8785
             P(Cross) if HR=0.6   0.6593   0.0437
       Final                  Z   1.9854   1.9854
      N: 188        p (1-sided)   0.0235   0.0235
 Events: 168       ~HR at bound   0.7361   0.7361
   Month: 36   P(Cross) if HR=1   0.0237   0.9763
             P(Cross) if HR=0.6   0.9006   0.0994
> 
> # Note that calendar timing for spending relates to planned timing for y
> # rather than timing in y after toInteger() conversion
> 
> # Values plugged into spending function for calendar time
> y$usTime
[1] 0.3333333 0.6666667 1.0000000
> # Actual calendar fraction from design after toInteger() conversion
> y$T / max(y$T)
[1] 0.3317243 0.6637288 1.0000000
> 
> 
> 
> cleanEx()
> nameEx("nNormal")
> ### * nNormal
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: nNormal
> ### Title: Normal distribution sample size (2-sample)
> ### Aliases: nNormal
> ### Keywords: design
> 
> ### ** Examples
> 
> 
> # EXAMPLES
> # equal variances
> n=nNormal(delta1=.5,sd=1.1,alpha=.025,beta=.2)
> n
[1] 151.9543
> x <- gsDesign(k = 3, n.fix = n, test.type = 4, alpha = 0.025, beta = 0.1, timing = c(.5,.75),
+ sfu = sfLDOF, sfl = sfHSD, sflpar = -1, delta1 = 0.5, endpoint = 'normal') 
> gsBoundSummary(x)
  Analysis                 Value Efficacy Futility
 IA 1: 50%                     Z   2.9626   0.6475
     N: 86           p (1-sided)   0.0015   0.2587
                 ~delta at bound   0.6109   0.1335
             P(Cross) if delta=0   0.0015   0.7413
           P(Cross) if delta=0.5   0.2954   0.0378
 IA 2: 75%                     Z   2.3590   1.3115
    N: 128           p (1-sided)   0.0092   0.0948
                 ~delta at bound   0.3972   0.2208
             P(Cross) if delta=0   0.0096   0.9155
           P(Cross) if delta=0.5   0.7309   0.0650
     Final                     Z   2.0141   2.0141
    N: 171           p (1-sided)   0.0220   0.0220
                 ~delta at bound   0.2937   0.2937
             P(Cross) if delta=0   0.0219   0.9781
           P(Cross) if delta=0.5   0.9000   0.1000
> summary(x)
[1] "Asymmetric two-sided group sequential design with non-binding futility bound, 3 analyses, sample size 171, 90 percent power, 2.5 percent (1-sided) Type I error. Efficacy bounds derived using a Lan-DeMets O'Brien-Fleming approximation spending function (no parameters). Futility bounds derived using a Hwang-Shih-DeCani spending function with gamma = -1."
> # unequal variances, fixed design
> nNormal(delta1 = .5, sd = 1.1, sd2 = 2, alpha = .025, beta = .2)
[1] 327.1413
> # unequal sample sizes
> nNormal(delta1 = .5, sd = 1.1, alpha = .025, beta = .2, ratio = 2)
[1] 170.9486
> # non-inferiority assuming a better effect than null
> nNormal(delta1 = .5, delta0 = -.1, sd = 1.2)
[1] 168.1188
> 
> 
> 
> cleanEx()
> nameEx("nSurv")
> ### * nSurv
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tEventsIA
> ### Title: Advanced time-to-event sample size calculation
> ### Aliases: tEventsIA nEventsIA nSurv gsSurv print.nSurv print.gsSurv
> ###   xtable.gsSurv
> ### Keywords: Bernstein Foulkes Freedman Lachin Lagakos Schoenfeld and
> ###   design hazards non-inferiority power proportional sample size
> ###   stratified super-superiority survival
> 
> ### ** Examples
> 
> 
> # Vary accrual rate gamma to obtain power
> # T, minfup and R all specified, although R will be adjusted on output
> # gamma as input will be multiplied in output to achieve desired power
> # Default method is Lachin and Foulkes
> x_nsurv <- nSurv(
+   lambdaC = log(2) / 6, R = 10, hr = .5, eta = .001, gamma = 1,
+   alpha = 0.02, beta = .15, T = 36, minfup = 12, method = "LachinFoulkes"
+ )
> # Demonstrate print method
> print(x_nsurv)
nSurv fixed-design summary (method=LachinFoulkes; target=Accrual rate)
HR=0.500 vs HR0=1.000 | alpha=0.020 (sided=1) | power=85.0%
N=95.7 subjects | D=78.1 events | T=36.0 study duration | accrual=24.0 Accrual duration | minfup=12.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Key inputs (names preserved):
                               desc    item value input
                    Accrual rate(s)   gamma 3.986     1
           Accrual rate duration(s)       R    24    10
             Control hazard rate(s) lambdaC 0.116 0.116
            Control dropout rate(s)     eta 0.001 0.001
       Experimental dropout rate(s)    etaE 0.001  etaE
 Event and dropout rate duration(s)       S  NULL     S
> # Same assumptions for group sequential design
> x_gs <- gsSurv(
+   k = 4, sfl = gsDesign::sfPower, sflpar = .5, lambdaC = log(2) / 6, hr = .5,
+   eta = .001, gamma = 1, T = 36, minfup = 12, method = "LachinFoulkes"
+ )
> print(x_gs)
Group sequential design (method=LachinFoulkes; k=4 analyses; Two-sided asymmetric with non-binding futility)
N=140.7 subjects | D=114.8 events | T=36.0 study duration | accrual=24.0 Accrual duration | minfup=12.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Spending functions:
  Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4.
  Futility bounds derived using a Kim-DeMets (power) spending function with rho = 0.

Analysis summary:
Method: LachinFoulkes 
    Analysis              Value Efficacy Futility
   IA 1: 25%                  Z   3.1554   0.2264
       N: 76        p (1-sided)   0.0008   0.4105
  Events: 29       ~HR at bound   0.3079   0.9190
   Month: 13   P(Cross) if HR=1   0.0008   0.5895
             P(Cross) if HR=0.5   0.0995   0.0500
   IA 2: 50%                  Z   2.8183   0.8619
      N: 116        p (1-sided)   0.0024   0.1944
  Events: 58       ~HR at bound   0.4752   0.7965
   Month: 20   P(Cross) if HR=1   0.0030   0.8366
             P(Cross) if HR=0.5   0.4388   0.0707
   IA 3: 75%                  Z   2.4390   1.4589
      N: 142        p (1-sided)   0.0074   0.0723
  Events: 87       ~HR at bound   0.5912   0.7302
   Month: 26   P(Cross) if HR=1   0.0085   0.9445
             P(Cross) if HR=0.5   0.7776   0.0866
       Final                  Z   2.0136   2.0136
      N: 142        p (1-sided)   0.0220   0.0220
 Events: 115       ~HR at bound   0.6867   0.6867
   Month: 36   P(Cross) if HR=1   0.0187   0.9813
             P(Cross) if HR=0.5   0.9000   0.1000

Key inputs (names preserved):
                               desc    item value input
                    Accrual rate(s)   gamma 5.863     1
           Accrual rate duration(s)       R    24    12
             Control hazard rate(s) lambdaC 0.116 0.116
            Control dropout rate(s)     eta 0.001 0.001
       Experimental dropout rate(s)    etaE 0.001  etaE
 Event and dropout rate duration(s)       S  NULL     S
> # Demonstrate xtable method for gsSurv
> print(xtable::xtable(x_gs,
+   footnote = "This is a footnote; note that it can be wide.",
+   caption = "Caption example for xtable output."
+ ))
% latex table generated in R 4.5.0 by xtable 1.8-8 package
% Wed Feb 25 16:26:32 2026
\begin{table}[ht]
\centering
\begin{tabular}{rllll}
  \hline
 & Analysis & Value & Futility & Efficacy \\ 
  \hline
1 & IA 1: 25$\backslash$\% & Z-value & 0.23 & 3.16 \\ 
  2 & N: 76 & HR & 0.92 & 0.31 \\ 
  3 & Events: 29 & p (1-sided) & 0.4105 & 8e-04 \\ 
  4 & 12.8 months & P$\backslash$\{Cross$\backslash$\} if HR=1 & 0.5895 & 8e-04 \\ 
  5 &   & P$\backslash$\{Cross$\backslash$\} if HR=0.5 & 0.05 & 0.0995 \\ 
  6 & $\backslash$hline IA 2: 50$\backslash$\% & Z-value & 0.86 & 2.82 \\ 
  7 & N: 116 & HR & 0.8 & 0.48 \\ 
  8 & Events: 58 & p (1-sided) & 0.1944 & 0.0024 \\ 
  9 & 19.6 months & P$\backslash$\{Cross$\backslash$\} if HR=1 & 0.8366 & 0.003 \\ 
  10 &   & P$\backslash$\{Cross$\backslash$\} if HR=0.5 & 0.0707 & 0.4388 \\ 
  11 & $\backslash$hline IA 3: 75$\backslash$\% & Z-value & 1.46 & 2.44 \\ 
  12 & N: 142 & HR & 0.73 & 0.59 \\ 
  13 & Events: 87 & p (1-sided) & 0.0723 & 0.0074 \\ 
  14 & 25.7 months & P$\backslash$\{Cross$\backslash$\} if HR=1 & 0.9445 & 0.0085 \\ 
  15 &   & P$\backslash$\{Cross$\backslash$\} if HR=0.5 & 0.0866 & 0.7776 \\ 
  16 & $\backslash$hline Final analysis & Z-value & 2.01 & 2.01 \\ 
  17 & N: 142 & HR & 0.69 & 0.69 \\ 
  18 & Events: 115 & p (1-sided) & 0.022 & 0.022 \\ 
  19 & 36 months & P$\backslash$\{Cross$\backslash$\} if HR=1 & 0.9813 & 0.0187 \\ 
  20 &   & P$\backslash$\{Cross$\backslash$\} if HR=0.5 & 0.1 & 0.9 $\backslash$$\backslash$ $\backslash$hline $\backslash$multicolumn\{4\}\{p\{ 9cm \}\}\{$\backslash$footnotesize This is a footnote; note that it can be wide. \} \\ 
   \hline
\end{tabular}
\caption{Caption example for xtable output.} 
\end{table}
> # Demonstrate nEventsIA method
> # find expected number of events at time 12 in the above trial
> nEventsIA(x = x_gs, tIA = 10)
[1] 18.92635
> 
> # find time at which 1/4 of events are expected
> tEventsIA(x = x_gs, timing = .25)
$T
[1] 12.76571

$eDC
[1] 17.79583

$eDE
[1] 10.90882

$eNC
[1] 37.42481

$eNE
[1] 37.42481

> 
> # Adjust accrual duration R to achieve desired power
> # Trial duration T input as NULL and will be computed based on
> # accrual duration R and minimum follow-up duration minfup
> # Minimum follow-up duration minfup is specified
> # We use the Schoenfeld method to compute accrual duration R
> # Control median survival time is 6
> nSurv(
+   lambdaC = log(2) / 6, hr = .5, eta = .001, gamma = 6,
+   alpha = .025, beta = .1, minfup = 12, T = NULL, method = "Schoenfeld"
+ )
nSurv fixed-design summary (method=Schoenfeld; target=Accrual duration)
HR=0.500 vs HR0=1.000 | alpha=0.025 (sided=1) | power=90.0%
N=109.5 subjects | D=86.2 events | T=30.2 study duration | accrual=18.2 Accrual duration | minfup=12.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Key inputs (names preserved):
                               desc    item  value input
                    Accrual rate(s)   gamma      6     6
           Accrual rate duration(s)       R 18.243    12
             Control hazard rate(s) lambdaC  0.116 0.116
            Control dropout rate(s)     eta  0.001 0.001
       Experimental dropout rate(s)    etaE  0.001  etaE
 Event and dropout rate duration(s)       S   NULL     S
> # Same assumptions for group sequential design
> gsSurv(
+   k = 4, sfu = gsDesign::sfHSD, sfupar = -4, sfl = gsDesign::sfPower, sflpar = .5,
+   lambdaC = log(2) / 6, hr = .5, eta = .001, gamma = 6,
+   T = 36, minfup = 12, method = "Schoenfeld"
+ ) |>
+   print()
Group sequential design (method=Schoenfeld; k=4 analyses; Two-sided asymmetric with non-binding futility)
N=142.9 subjects | D=116.6 events | T=36.0 study duration | accrual=24.0 Accrual duration | minfup=12.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Spending functions:
  Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4.
  Futility bounds derived using a Kim-DeMets (power) spending function with rho = 0.

Analysis summary:
Method: Schoenfeld 
    Analysis              Value Efficacy Futility
   IA 1: 25%                  Z   3.1554   0.2264
       N: 78        p (1-sided)   0.0008   0.4105
  Events: 30       ~HR at bound   0.3107   0.9196
   Month: 13   P(Cross) if HR=1   0.0008   0.5895
             P(Cross) if HR=0.5   0.0995   0.0500
   IA 2: 50%                  Z   2.8183   0.8619
      N: 118        p (1-sided)   0.0024   0.1944
  Events: 59       ~HR at bound   0.4780   0.7979
   Month: 20   P(Cross) if HR=1   0.0030   0.8366
             P(Cross) if HR=0.5   0.4388   0.0707
   IA 3: 75%                  Z   2.4390   1.4589
      N: 144        p (1-sided)   0.0074   0.0723
  Events: 88       ~HR at bound   0.5936   0.7320
   Month: 26   P(Cross) if HR=1   0.0085   0.9445
             P(Cross) if HR=0.5   0.7776   0.0866
       Final                  Z   2.0136   2.0136
      N: 144        p (1-sided)   0.0220   0.0220
 Events: 117       ~HR at bound   0.6887   0.6887
   Month: 36   P(Cross) if HR=1   0.0187   0.9813
             P(Cross) if HR=0.5   0.9000   0.1000

Key inputs (names preserved):
                               desc    item value input
                    Accrual rate(s)   gamma 5.955     6
           Accrual rate duration(s)       R    24    12
             Control hazard rate(s) lambdaC 0.116 0.116
            Control dropout rate(s)     eta 0.001 0.001
       Experimental dropout rate(s)    etaE 0.001  etaE
 Event and dropout rate duration(s)       S  NULL     S
> 
> # Vary minimum follow-up duration minfup to obtain power
> # Accrual duration R rate gamma are fixed and will not change on output.
> # Trial duration T and minimum follow-up minfup are input as NULL
> # and will be computed on output.
> # We will use the Freedman method to compute sample size
> # Control median survival time is 6
> # Often this method will fail as the accrual duration and rate provide too
> # little or too much sample size.
> nSurv(
+   lambdaC = log(2) / 6, hr = .5, eta = .001, gamma = 6, R = 25,
+   alpha = .025, beta = .1, minfup = NULL, T = NULL, method = "Freedman"
+ )
nSurv fixed-design summary (method=Freedman; target=Follow-up duration)
HR=0.500 vs HR0=1.000 | alpha=0.025 (sided=1) | power=90.0%
N=150.0 subjects | D=86.8 events | T=25.3 study duration | accrual=25.0 Accrual duration | minfup=0.3 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Key inputs (names preserved):
                               desc    item value input
                    Accrual rate(s)   gamma     6     6
           Accrual rate duration(s)       R    25    25
             Control hazard rate(s) lambdaC 0.116 0.116
            Control dropout rate(s)     eta 0.001 0.001
       Experimental dropout rate(s)    etaE 0.001  etaE
 Event and dropout rate duration(s)       S  NULL     S
> # Same assumptions for group sequential design
> gsSurv(
+   k = 4, sfu = gsDesign::sfHSD, sfupar = -4, sfl = gsDesign::sfPower, sflpar = .5,
+   lambdaC = log(2) / 6, hr = .5, eta = .001, gamma = 6,
+   T = 36, minfup = 12, method = "Freedman"
+ ) |>
+   print()
Group sequential design (method=Freedman; k=4 analyses; Two-sided asymmetric with non-binding futility)
N=154.5 subjects | D=126.1 events | T=36.0 study duration | accrual=24.0 Accrual duration | minfup=12.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Spending functions:
  Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4.
  Futility bounds derived using a Kim-DeMets (power) spending function with rho = 0.

Analysis summary:
Method: Freedman 
    Analysis              Value Efficacy Futility
   IA 1: 25%                  Z   3.1554   0.2264
       N: 84        p (1-sided)   0.0008   0.4105
  Events: 32       ~HR at bound   0.3249   0.9225
   Month: 13   P(Cross) if HR=1   0.0008   0.5895
             P(Cross) if HR=0.5   0.0995   0.0500
   IA 2: 50%                  Z   2.8183   0.8619
      N: 128        p (1-sided)   0.0024   0.1944
  Events: 64       ~HR at bound   0.4916   0.8048
   Month: 20   P(Cross) if HR=1   0.0030   0.8366
             P(Cross) if HR=0.5   0.4388   0.0707
   IA 3: 75%                  Z   2.4390   1.4589
      N: 156        p (1-sided)   0.0074   0.0723
  Events: 95       ~HR at bound   0.6055   0.7407
   Month: 26   P(Cross) if HR=1   0.0085   0.9445
             P(Cross) if HR=0.5   0.7776   0.0866
       Final                  Z   2.0136   2.0136
      N: 156        p (1-sided)   0.0220   0.0220
 Events: 127       ~HR at bound   0.6986   0.6986
   Month: 36   P(Cross) if HR=1   0.0187   0.9813
             P(Cross) if HR=0.5   0.9000   0.1000

Key inputs (names preserved):
                               desc    item value input
                    Accrual rate(s)   gamma 6.437     6
           Accrual rate duration(s)       R    24    12
             Control hazard rate(s) lambdaC 0.116 0.116
            Control dropout rate(s)     eta 0.001 0.001
       Experimental dropout rate(s)    etaE 0.001  etaE
 Event and dropout rate duration(s)       S  NULL     S
> 
> # piecewise constant enrollment rates (vary accrual rate to achieve power)
> # also piecewise constant failure rates
> # will specify annualized enrollment and failure rates
> nSurv(
+   lambdaC = -log(c(.95, .97, .98)), # 5%, 3% and 2% annual failure rates
+   S = c(1, 1), # 1 year duration for first 2 failure rates, 3rd continues indefinitely
+   R = c(.25, .25, 1.5), # 2-year enrollment with ramp-up over first 1/2 year
+   gamma = c(1, 3, 6), # 1, 3 and 6 annualized enrollment rates will be
+   # multiplied by ratio to achieve desired power
+   hr = .5, eta = -log(1 - .01), # 1% annual censoring rate
+   minfup = 3, T = 5, # 5-year trial duration with 3-year minimum follow-up
+   alpha = .025, beta = .1, method = "LachinFoulkes"
+ )
nSurv fixed-design summary (method=LachinFoulkes; target=Accrual rate)
HR=0.500 vs HR0=1.000 | alpha=0.025 (sided=1) | power=90.0%
N=1088.8 subjects | D=91.1 events | T=5.0 study duration | accrual=2.0 Accrual duration | minfup=3.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Key inputs (names preserved):
                               desc    item                     value
                    Accrual rate(s)   gamma 108.876, 326.629, 653.258
           Accrual rate duration(s)       R           0.25, 0.25, 1.5
             Control hazard rate(s) lambdaC         0.051, 0.03, 0.02
            Control dropout rate(s)     eta          0.01, 0.01, 0.01
       Experimental dropout rate(s)    etaE          0.01, 0.01, 0.01
 Event and dropout rate duration(s)       S                      1, 1
             input
           1, 3, 6
   0.25, 0.25, 1.5
 0.051, 0.03, 0.02
              0.01
              etaE
              1, 1
> # Same assumptions for group sequential design
> gsSurv(
+   k = 4, sfu = gsDesign::sfHSD, sfupar = -4, sfl = gsDesign::sfPower, sflpar = .5,
+   lambdaC = -log(c(.95, .97, .98)), # 5%, 3% and 2% annual failure rates
+   S = c(1, 1), # 1 year duration for first 2 failure rates, 3rd continues indefinitely
+   R = c(.25, .25, 1.5), # 2-year enrollment with ramp-up over first 1/2 year
+   gamma = c(1, 3, 6), # 1, 3 and 6 annualized enrollment rates will be
+   # multiplied by ratio to achieve desired power
+   hr = .5, eta = -log(1 - .01), # 1% annual censoring rate
+   minfup = 3, T = 5, # 5-year trial duration with 3-year minimum follow-up
+   alpha = .025, beta = .1, method = "LachinFoulkes"
+ ) |>
+   print()
Group sequential design (method=LachinFoulkes; k=4 analyses; Two-sided asymmetric with non-binding futility)
N=1451.2 subjects | D=121.4 events | T=5.0 study duration | accrual=2.0 Accrual duration | minfup=3.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Spending functions:
  Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4.
  Futility bounds derived using a Kim-DeMets (power) spending function with rho = 0.

Analysis summary:
Method: LachinFoulkes 
    Analysis              Value Efficacy Futility
   IA 1: 25%                  Z   3.1554   0.2264
     N: 1198        p (1-sided)   0.0008   0.4105
  Events: 31       ~HR at bound   0.3181   0.9211
    Month: 2   P(Cross) if HR=1   0.0008   0.5895
             P(Cross) if HR=0.5   0.0995   0.0500
   IA 2: 50%                  Z   2.8183   0.8619
     N: 1452        p (1-sided)   0.0024   0.1944
  Events: 61       ~HR at bound   0.4851   0.8015
    Month: 2   P(Cross) if HR=1   0.0030   0.8366
             P(Cross) if HR=0.5   0.4388   0.0707
   IA 3: 75%                  Z   2.4390   1.4589
     N: 1452        p (1-sided)   0.0074   0.0723
  Events: 92       ~HR at bound   0.5998   0.7366
    Month: 3   P(Cross) if HR=1   0.0085   0.9445
             P(Cross) if HR=0.5   0.7776   0.0866
       Final                  Z   2.0136   2.0136
     N: 1452        p (1-sided)   0.0220   0.0220
 Events: 122       ~HR at bound   0.6939   0.6939
    Month: 5   P(Cross) if HR=1   0.0187   0.9813
             P(Cross) if HR=0.5   0.9000   0.1000

Key inputs (names preserved):
                               desc    item                     value
                    Accrual rate(s)   gamma 145.125, 435.375, 870.749
           Accrual rate duration(s)       R           0.25, 0.25, 1.5
             Control hazard rate(s) lambdaC         0.051, 0.03, 0.02
            Control dropout rate(s)     eta          0.01, 0.01, 0.01
       Experimental dropout rate(s)    etaE          0.01, 0.01, 0.01
 Event and dropout rate duration(s)       S                      1, 1
             input
           1, 3, 6
   0.25, 0.25, 1.5
 0.051, 0.03, 0.02
              0.01
              etaE
              1, 1
> 
> # combine it all: 2 strata, 2 failure rate periods
> # Note that method = "LachinFoulkes" may be preferred here
> nSurv(
+   lambdaC = matrix(log(2) / c(6, 12, 18, 24), ncol = 2), hr = .5,
+   eta = matrix(log(2) / c(40, 50, 45, 55), ncol = 2), S = 3,
+   gamma = matrix(c(3, 6, 5, 7), ncol = 2), R = c(5, 10), minfup = 12,
+   alpha = .025, beta = .1, method = "BernsteinLagakos"
+ )
nSurv fixed-design summary (method=BernsteinLagakos; target=Accrual rate)
HR=0.500 vs HR0=1.000 | alpha=0.025 (sided=1) | power=90.0%
N=226.8 subjects | D=78.7 events | T=18.0 study duration | accrual=6.0 Accrual duration | minfup=12.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Expected events by stratum (H1):
  control experimental  total
1  26.517       16.431 42.949
2  22.980       12.761 35.741

Key inputs (names preserved):
                               desc    item                           value
                    Accrual rate(s)   gamma  12.84, 25.68, 21.4 ... (len=4)
           Accrual rate duration(s)       R                            5, 1
             Control hazard rate(s) lambdaC 0.116, 0.058, 0.039 ... (len=4)
            Control dropout rate(s)     eta 0.017, 0.014, 0.015 ... (len=4)
       Experimental dropout rate(s)    etaE 0.017, 0.014, 0.015 ... (len=4)
 Event and dropout rate duration(s)       S                               3
                           input
             3, 6, 5 ... (len=4)
                           5, 10
 0.116, 0.058, 0.039 ... (len=4)
 0.017, 0.014, 0.015 ... (len=4)
                            etaE
                               3
> # Same assumptions for group sequential design
> gsSurv(
+   k = 4, sfu = gsDesign::sfHSD, sfupar = -4, sfl = gsDesign::sfPower, sflpar = .5,
+   lambdaC = matrix(log(2) / c(6, 12, 18, 24), ncol = 2), hr = .5,
+   eta = matrix(log(2) / c(40, 50, 45, 55), ncol = 2), S = 3,
+   gamma = matrix(c(3, 6, 5, 7), ncol = 2), R = c(5, 10), minfup = 12,
+   alpha = .025, beta = .1, method = "BernsteinLagakos"
+ ) |>
+   print()
Group sequential design (method=BernsteinLagakos; k=4 analyses; Two-sided asymmetric with non-binding futility)
N=302.4 subjects | D=104.9 events | T=18.0 study duration | accrual=6.0 Accrual duration | minfup=12.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Spending functions:
  Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4.
  Futility bounds derived using a Kim-DeMets (power) spending function with rho = 0.

Analysis summary:
Method: BernsteinLagakos 
    Analysis              Value Efficacy Futility
   IA 1: 25%                  Z   3.1554   0.2264
      N: 250        p (1-sided)   0.0008   0.4105
  Events: 27       ~HR at bound   0.2916   0.9154
    Month: 5   P(Cross) if HR=1   0.0008   0.5895
             P(Cross) if HR=0.5   0.0995   0.0500
   IA 2: 50%                  Z   2.8183   0.8619
      N: 304        p (1-sided)   0.0024   0.1944
  Events: 53       ~HR at bound   0.4592   0.7882
    Month: 8   P(Cross) if HR=1   0.0030   0.8366
             P(Cross) if HR=0.5   0.4388   0.0707
   IA 3: 75%                  Z   2.4390   1.4589
      N: 304        p (1-sided)   0.0074   0.0723
  Events: 79       ~HR at bound   0.5770   0.7197
   Month: 12   P(Cross) if HR=1   0.0085   0.9445
             P(Cross) if HR=0.5   0.7776   0.0866
       Final                  Z   2.0136   2.0136
      N: 304        p (1-sided)   0.0220   0.0220
 Events: 105       ~HR at bound   0.6749   0.6749
   Month: 18   P(Cross) if HR=1   0.0187   0.9813
             P(Cross) if HR=0.5   0.9000   0.1000

Key inputs (names preserved):
                               desc    item                             value
                    Accrual rate(s)   gamma 17.115, 28.525, 34.23 ... (len=4)
           Accrual rate duration(s)       R                              5, 1
             Control hazard rate(s) lambdaC   0.116, 0.039, 0.058 ... (len=4)
            Control dropout rate(s)     eta   0.017, 0.015, 0.014 ... (len=4)
       Experimental dropout rate(s)    etaE   0.017, 0.015, 0.014 ... (len=4)
 Event and dropout rate duration(s)       S                                 3
                           input
             3, 5, 6 ... (len=4)
                           5, 10
 0.116, 0.039, 0.058 ... (len=4)
 0.017, 0.015, 0.014 ... (len=4)
                            etaE
                               3

Expected events by stratum (H1) at final analysis:
   stratum control experimental  total
 Stratum 1  35.346       21.902 57.248
 Stratum 2  30.631       17.010 47.641
> 
> # Example to compute power for a fixed design.
> # Trial duration T, minimum follow-up minfup and accrual duration R are all
> # specified and will not change on output.
> # beta=NULL will compute power and output will be the same as if beta were specified.
> # This option is not available for group sequential designs.
> nSurv(
+   lambdaC = log(2) / 6, hr = .5, eta = .001, gamma = 6, R = 25,
+   alpha = .025, beta = NULL, minfup = 12, T = 36, method = "LachinFoulkes"
+ ) |>
+   print()
nSurv fixed-design summary (method=LachinFoulkes; target=Power)
HR=0.500 vs HR0=1.000 | alpha=0.025 (sided=1) | power=96.5%
N=144.0 subjects | D=117.5 events | T=36.0 study duration | accrual=24.0 Accrual duration | minfup=12.0 minimum follow-up | ratio=1 randomization ratio (experimental/control)

Key inputs (names preserved):
                               desc    item value input
                    Accrual rate(s)   gamma     6     6
           Accrual rate duration(s)       R    24    25
             Control hazard rate(s) lambdaC 0.116 0.116
            Control dropout rate(s)     eta 0.001 0.001
       Experimental dropout rate(s)    etaE 0.001  etaE
 Event and dropout rate duration(s)       S  NULL     S
> 
> 
> 
> cleanEx()
> nameEx("nSurvival")
> ### * nSurvival
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: print.nSurvival
> ### Title: Time-to-event sample size calculation (Lachin-Foulkes)
> ### Aliases: print.nSurvival nSurvival nEvents zn2hr hrn2z hrz2n
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> 
> # consider a trial with
> # 2 year maximum follow-up
> # 6 month uniform enrollment
> # Treatment/placebo hazards = 0.1/0.2 per 1 person-year
> # drop out hazard 0.1 per 1 person-year
> # alpha = 0.025 (1-sided)
> # power = 0.9 (default beta=.1)
> 
> ss <- nSurvival(
+   lambda1 = .2, lambda2 = .1, eta = .1, Ts = 2, Tr = .5,
+   sided = 1, alpha = .025
+ )
> 
> #  group sequential translation with default bounds
> #  note that delta1 is log hazard ratio; used later in gsBoundSummary summary
> x <- gsDesign(
+   k = 5, test.type = 2, n.fix = ss$nEvents, nFixSurv = ss$n,
+   delta1 = log(ss$lambda2 / ss$lambda1)
+ )
> # boundary plot
> plot(x)
> # effect size plot
> plot(x, plottype = "hr")
> # total sample size
> x$nSurv
[1] 440
> # number of events at analyses
> x$n.I
[1] 18.44213 36.88425 55.32638 73.76850 92.21063
> # print the design
> x
Group sequential design sample size for time-to-event outcome
with sample size 440. The analysis plan below shows events
at each analysis.
Symmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Spending computations assume trial stops
if a bound is crossed.

             
  Analysis N   Z   Nominal p  Spend
         1 19 3.25    0.0006 0.0006
         2 37 2.99    0.0014 0.0013
         3 56 2.69    0.0036 0.0028
         4 74 2.37    0.0088 0.0063
         5 93 2.03    0.0214 0.0140
     Total                   0.0250 

++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4      5 Total E{N}
  0.0000 0.0006 0.0013 0.0028 0.0063 0.0140 0.025 91.5
  0.3415 0.0370 0.1512 0.2647 0.2699 0.1771 0.900 66.4

Lower boundary (futility or Type II Error)
          Analysis
   Theta     1      2      3      4     5 Total
  0.0000 6e-04 0.0013 0.0028 0.0063 0.014 0.025
  0.3415 0e+00 0.0000 0.0000 0.0000 0.000 0.000
> # overall design summary
> cat(summary(x))
Symmetric two-sided group sequential design with 5 analyses, time-to-event outcome with sample size 440 and 93 events required, 90 percent power, 2.5 percent (1-sided) Type I error. Bounds derived using a  Hwang-Shih-DeCani spending function with gamma = -4.> # tabular summary of bounds
> gsBoundSummary(x, deltaname = "HR", Nname = "Events", logdelta = TRUE)
   Analysis              Value Efficacy Futility
  IA 1: 20%                  Z   3.2527  -3.2527
 Events: 19        p (1-sided)   0.0006   0.0006
                  ~HR at bound   0.2198   4.5487
              P(Cross) if HR=1   0.0006   0.0006
            P(Cross) if HR=0.5   0.0370   0.0000
  IA 2: 40%                  Z   2.9860  -2.9860
 Events: 37        p (1-sided)   0.0014   0.0014
                  ~HR at bound   0.3741   2.6734
              P(Cross) if HR=1   0.0018   0.0018
            P(Cross) if HR=0.5   0.1883   0.0000
  IA 3: 60%                  Z   2.6917  -2.6917
 Events: 56        p (1-sided)   0.0036   0.0036
                  ~HR at bound   0.4849   2.0621
              P(Cross) if HR=1   0.0047   0.0047
            P(Cross) if HR=0.5   0.4530   0.0000
  IA 4: 80%                  Z   2.3737  -2.3737
 Events: 74        p (1-sided)   0.0088   0.0088
                  ~HR at bound   0.5754   1.7380
              P(Cross) if HR=1   0.0110   0.0110
            P(Cross) if HR=0.5   0.7229   0.0000
      Final                  Z   2.0253  -2.0253
 Events: 93        p (1-sided)   0.0214   0.0214
                  ~HR at bound   0.6558   1.5247
              P(Cross) if HR=1   0.0250   0.0250
            P(Cross) if HR=0.5   0.9000   0.0000
> 
> 
> 
> # approximate number of events required using Schoenfeld's method
> # for 2 different hazard ratios
> nEvents(hr = c(.5, .6), tbl = TRUE)
   hr   n alpha sided beta Power     delta ratio hr0        se
1 0.5  88 0.025     1  0.1   0.9 0.3465736     1   1 0.2132007
2 0.6 162 0.025     1  0.1   0.9 0.2554128     1   1 0.1571348
> # vector output
> nEvents(hr = c(.5, .6))
[1]  87.4793 161.0686
> 
> # approximate power using Schoenfeld's method
> # given 2 sample sizes and hr=.6
> nEvents(hr = .6, n = c(50, 100), tbl = TRUE)
   hr   n alpha sided      beta     Power     delta ratio hr0        se
1 0.6  50 0.025     1 0.5611646 0.4388354 0.2554128     1   1 0.2828427
2 0.6 100 0.025     1 0.2762012 0.7237988 0.2554128     1   1 0.2000000
> # vector output
> nEvents(hr = .6, n = c(50, 100))
[1] 0.4388354 0.7237988
> 
> # approximate hazard ratio corresponding to 100 events and z-statistic of 2
> zn2hr(n = 100, z = 2)
[1] 0.67032
> # same when hr0 is 1.1
> zn2hr(n = 100, z = 2, hr0 = 1.1)
[1] 0.7373521
> # same when hr0 is .9 and hr1 is greater than hr0
> zn2hr(n = 100, z = 2, hr0 = .9, hr1 = 1)
[1] 1.342642
> 
> # approximate number of events corresponding to z-statistic of 2 and
> # estimated hazard ratio of .5 (or 2)
> hrz2n(hr = .5, z = 2)
[1] 33.3019
> hrz2n(hr = 2, z = 2)
[1] 33.3019
> 
> # approximate z statistic corresponding to 75 events
> # and estimated hazard ratio of .6 (or 1/.6)
> # assuming 2-to-1 randomization of experimental to control
> hrn2z(hr = .6, n = 75, ratio = 2)
[1] -2.085437
> hrn2z(hr = 1 / .6, n = 75, ratio = 2)
[1] 2.085437
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("normalGrid")
> ### * normalGrid
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: normalGrid
> ### Title: Normal Density Grid
> ### Aliases: normalGrid
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> #  standard normal distribution
> x <- normalGrid(r = 3)
> plot(x$z, x$wgts)
> 
> #  verify that numerical integration replicates sigma
> #  get grid points and weights
> x <- normalGrid(mu = 2, sigma = 3)
> 
> # compute squared deviation from mean for grid points
> dev <- (x$z - 2)^2
> 
> # multiply squared deviations by integration weights and sum
> sigma2 <- sum(dev * x$wgts)
> 
> # square root of sigma2 should be sigma (3)
> sqrt(sigma2)
[1] 3.000001
> 
> # do it again with larger r to increase accuracy
> x <- normalGrid(r = 22, mu = 2, sigma = 3)
> sqrt(sum((x$z - 2)^2 * x$wgts))
[1] 3
> 
> # this can also be done by combining gridwgts and density
> sqrt(sum((x$z - 2)^2 * x$gridwgts * x$density))
[1] 3
> 
> # integrate normal density and compare to built-in function
> # to compute probability of being within 1 standard deviation
> # of the mean
> pnorm(1) - pnorm(-1)
[1] 0.6826895
> x <- normalGrid(bounds = c(-1, 1))
> sum(x$wgts)
[1] 0.6826895
> sum(x$gridwgts * x$density)
[1] 0.6826895
> 
> # find expected sample size for default design with
> # n.fix=1000
> x <- gsDesign(n.fix = 1000)
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

                  ----Lower bounds----  ----Upper bounds-----
  Analysis   N    Z   Nominal p Spend+  Z   Nominal p Spend++
         1  357 -0.24    0.4057 0.0148 3.01    0.0013  0.0013
         2  714  0.94    0.8267 0.0289 2.55    0.0054  0.0049
         3 1070  2.00    0.9772 0.0563 2.00    0.0228  0.0188
     Total                      0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Hwang-Shih-DeCani spending function with gamma = -2.
++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3  Total  E{N}
  0.0000 0.0013 0.0049 0.0171 0.0233 624.9
  0.1025 0.1412 0.4403 0.3185 0.9000 791.3

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3  Total
  0.0000 0.4057 0.4290 0.1420 0.9767
  0.1025 0.0148 0.0289 0.0563 0.1000
> 
> # set a prior distribution for theta
> y <- normalGrid(r = 3, mu = x$theta[2], sigma = x$theta[2] / 1.5)
> z <- gsProbability(
+   k = 3, theta = y$z, n.I = x$n.I, a = x$lower$bound,
+   b = x$upper$bound
+ )
> z <- gsProbability(d = x, theta = y$z)
> cat(
+   "Expected sample size averaged over normal\n prior distribution for theta with \n mu=",
+   x$theta[2], "sigma=", x$theta[2] / 1.5, ":",
+   round(sum(z$en * y$wgt), 1), "\n"
+ )
Expected sample size averaged over normal
 prior distribution for theta with 
 mu= 0.1025057 sigma= 0.06833715 : 682.2 
> plot(y$z, z$en,
+   xlab = "theta", ylab = "E{N}",
+   main = "Expected sample size for different theta values"
+ )
> lines(y$z, z$en)
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("plot.gsDesign")
> ### * plot.gsDesign
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.gsDesign
> ### Title: Plots for group sequential designs
> ### Aliases: plot.gsDesign plot.gsProbability
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> #  symmetric, 2-sided design with O'Brien-Fleming-like boundaries
> #  lower bound is non-binding (ignored in Type I error computation)
> #  sample size is computed based on a fixed design requiring n=100
> x <- gsDesign(k = 5, test.type = 2, n.fix = 100)
> x
Symmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Spending computations assume trial stops
if a bound is crossed.

              
  Analysis  N   Z   Nominal p  Spend
         1  21 3.25    0.0006 0.0006
         2  41 2.99    0.0014 0.0013
         3  62 2.69    0.0036 0.0028
         4  82 2.37    0.0088 0.0063
         5 103 2.03    0.0214 0.0140
     Total                    0.0250 

++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -4.

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4      5 Total  E{N}
  0.0000 0.0006 0.0013 0.0028 0.0063 0.0140 0.025 101.6
  0.3242 0.0370 0.1512 0.2647 0.2699 0.1771 0.900  73.7

Lower boundary (futility or Type II Error)
          Analysis
   Theta     1      2      3      4     5 Total
  0.0000 6e-04 0.0013 0.0028 0.0063 0.014 0.025
  0.3242 0e+00 0.0000 0.0000 0.0000 0.000 0.000
> 
> # the following translate to calls to plot.gsDesign since x was
> # returned by gsDesign; run these commands one at a time
> plot(x)
> plot(x, plottype = 2)
> plot(x, plottype = 3)
> plot(x, plottype = 4)
> plot(x, plottype = 5)
> plot(x, plottype = 6)
> plot(x, plottype = 7)
> 
> #  choose different parameter values for power plot
> #  start with design in x from above
> y <- gsProbability(
+   k = 5, theta = seq(0, .5, .025), x$n.I,
+   x$lower$bound, x$upper$bound
+ )
> 
> # the following translates to a call to plot.gsProbability since
> # y has that type
> plot(y)
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sequentiaPValue")
> ### * sequentiaPValue
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sequentialPValue
> ### Title: Sequential p-value computation
> ### Aliases: sequentialPValue
> 
> ### ** Examples
> 
> 
> # Derive Group Sequential Design 
> x <- gsSurv(k = 4, alpha = 0.025, beta = 0.1, timing = c(.5,.65,.8), sfu = sfLDOF,
+             sfl = sfHSD, sflpar = 2, lambdaC = log(2)/6, hr = 0.6,
+             eta = 0.01 , gamma = c(2.5,5,7.5,10), R = c( 2,2,2,6 ),
+             T = 30 , minfup = 18)
> x$n.I
[1] 109.2757 142.0585 174.8412 218.5515
> # Analysis at IA2
> sequentialPValue(gsD=x,n.I=c(100,160),Z=c(1.5,2))
[1] 0.05363369
> # Use planned spending instead of information fraction; do final analysis
> sequentialPValue(gsD=x,n.I=c(100,160,190,230),Z=c(1.5,2,2.5,3),usTime=x$timing)
[1] 0.001452684
> # Check bounds for updated design to verify at least one was crossed
> xupdate <- gsDesign(maxn.IPlan=max(x$n.I),n.I=c(100,160,190,230),usTime=x$timing,
+                     delta=x$delta,delta1=x$delta1,k=4,alpha=x$alpha,test.type=1,
+                     sfu=x$upper$sf,sfupar=x$upper$param)
> 
> 
> 
> cleanEx()
> nameEx("sfDistribution")
> ### * sfDistribution
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfLogistic
> ### Title: Two-parameter Spending Function Families
> ### Aliases: sfLogistic sfBetaDist sfCauchy sfExtremeValue sfExtremeValue2
> ###   sfNormal
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # design a 4-analysis trial using a Kim-DeMets spending function
> # for both lower and upper bounds
> x <- gsDesign(k = 4, sfu = sfPower, sfupar = 3, sfl = sfPower, sflpar = 1.5)
> 
> # print the design
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.282 -0.52    0.3015 0.0125 3.36    0.0004  0.0004
         2  0.564  0.53    0.7028 0.0229 2.76    0.0029  0.0027
         3  0.846  1.32    0.9072 0.0296 2.36    0.0092  0.0074
         4  1.128  2.03    0.9788 0.0350 2.03    0.0212  0.0145
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Kim-DeMets (power) spending function with rho = 1.5.
++ alpha spending:
 Kim-DeMets (power) spending function with rho = 3.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4  Total  E{N}
  0.0000 0.0004 0.0027 0.0073 0.0116 0.0221 0.579
  3.2415 0.0507 0.3248 0.3619 0.1626 0.9000 0.768

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4  Total
  0.0000 0.3015 0.4138 0.2008 0.0619 0.9779
  3.2415 0.0125 0.0229 0.0296 0.0350 0.1000
> 
> # plot the alpha- and beta-spending functions
> plot(x, plottype = 5)
> 
> # start by showing how to fit two points with sfLogistic
> # plot the spending function using many points to obtain a smooth curve
> # note that curve fits the points x=.1,  y=.01 and x=.4,  y=.1
> # specified in the 3rd parameter of sfLogistic
> t <- 0:100 / 100
> plot(t, sfLogistic(1, t, c(.1, .4, .01, .1))$spend,
+   xlab = "Proportion of final sample size",
+   ylab = "Cumulative Type I error spending",
+   main = "Logistic Spending Function Examples",
+   type = "l", cex.main = .9
+ )
> lines(t, sfLogistic(1, t, c(.01, .1, .1, .4))$spend, lty = 2)
> 
> # now just give a=0 and b=1 as 3rd parameters for sfLogistic
> lines(t, sfLogistic(1, t, c(0, 1))$spend, lty = 3)
> 
> # try a couple with unconventional shapes again using
> # the xy form in the 3rd parameter
> lines(t, sfLogistic(1, t, c(.4, .6, .1, .7))$spend, lty = 4)
> lines(t, sfLogistic(1, t, c(.1, .7, .4, .6))$spend, lty = 5)
> legend(
+   x = c(.0, .475), y = c(.76, 1.03), lty = 1:5,
+   legend = c(
+     "Fit (.1, 01) and (.4, .1)", "Fit (.01, .1) and (.1, .4)",
+     "a=0,  b=1", "Fit (.4, .1) and (.6, .7)",
+     "Fit (.1, .4) and (.7, .6)"
+   )
+ )
> 
> # set up a function to plot comparsons of all
> # 2-parameter spending functions
> plotsf <- function(alpha, t, param) {
+   plot(t, sfCauchy(alpha, t, param)$spend,
+     xlab = "Proportion of enrollment",
+     ylab = "Cumulative spending", type = "l", lty = 2
+   )
+   lines(t, sfExtremeValue(alpha, t, param)$spend, lty = 5)
+   lines(t, sfLogistic(alpha, t, param)$spend, lty = 1)
+   lines(t, sfNormal(alpha, t, param)$spend, lty = 3)
+   lines(t, sfExtremeValue2(alpha, t, param)$spend, lty = 6, col = 2)
+   lines(t, sfBetaDist(alpha, t, param)$spend, lty = 7, col = 3)
+   legend(
+     x = c(.05, .475), y = .025 * c(.55, .9),
+     lty = c(1, 2, 3, 5, 6, 7),
+     col = c(1, 1, 1, 1, 2, 3),
+     legend = c(
+       "Logistic", "Cauchy", "Normal", "Extreme value",
+       "Extreme value 2", "Beta distribution"
+     )
+   )
+ }
> # do comparison for a design with conservative early spending
> # note that Cauchy spending function is quite different
> # from the others
> param <- c(.25, .5, .05, .1)
> plotsf(.025, t, param)
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sfExponential")
> ### * sfExponential
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfExponential
> ### Title: Exponential Spending Function
> ### Aliases: sfExponential
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # use 'best' exponential approximation for k=6 to O'Brien-Fleming design
> # (see manual for details)
> gsDesign(
+   k = 6, sfu = sfExponential, sfupar = 0.7849295,
+   test.type = 2
+ )$upper$bound
[1] 4.998123 3.598098 2.933292 2.530838 2.253723 2.047082
> 
> # show actual O'Brien-Fleming bound
> gsDesign(k = 6, sfu = "OF", test.type = 2)$upper$bound
[1] 5.028296 3.555542 2.903088 2.514148 2.248722 2.052793
> 
> # show Lan-DeMets approximation
> # (not as close as sfExponential approximation)
> gsDesign(k = 6, sfu = sfLDOF, test.type = 2)$upper$bound
[1] 5.366558 3.710340 2.969736 2.538677 2.252190 2.044790
> 
> # plot exponential spending function across a range of values of interest
> t <- 0:100 / 100
> plot(t, sfExponential(0.025, t, 0.8)$spend,
+   xlab = "Proportion of final sample size",
+   ylab = "Cumulative Type I error spending",
+   main = "Exponential Spending Function Example", type = "l"
+ )
> lines(t, sfExponential(0.025, t, 0.5)$spend, lty = 2)
> lines(t, sfExponential(0.025, t, 0.3)$spend, lty = 3)
> lines(t, sfExponential(0.025, t, 0.2)$spend, lty = 4)
> lines(t, sfExponential(0.025, t, 0.15)$spend, lty = 5)
> legend(
+   x = c(.0, .3), y = .025 * c(.7, 1), lty = 1:5,
+   legend = c(
+     "nu = 0.8", "nu = 0.5", "nu = 0.3", "nu = 0.2",
+     "nu = 0.15"
+   )
+ )
> text(x = .59, y = .95 * .025, labels = "<--approximates O'Brien-Fleming")
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sfHSD")
> ### * sfHSD
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfHSD
> ### Title: Hwang-Shih-DeCani Spending Function
> ### Aliases: sfHSD
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # design a 4-analysis trial using a Hwang-Shih-DeCani spending function
> # for both lower and upper bounds
> x <- gsDesign(k = 4, sfu = sfHSD, sfupar = -2, sfl = sfHSD, sflpar = 1)
> 
> # print the design
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size   ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*  Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.324 0.03    0.5136 0.0350 2.80    0.0025  0.0025
         2  0.649 0.88    0.8096 0.0273 2.58    0.0049  0.0042
         3  0.973 1.51    0.9349 0.0212 2.34    0.0096  0.0069
         4  1.297 2.09    0.9817 0.0165 2.09    0.0183  0.0114
     Total                       0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Hwang-Shih-DeCani spending function with gamma = 1.
++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -2.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4  Total   E{N}
  0.0000 0.0025 0.0042 0.0065 0.0072 0.0203 0.5477
  3.2415 0.1695 0.3553 0.2774 0.0978 0.9000 0.7533

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4  Total
  0.0000 0.5136 0.3156 0.1169 0.0336 0.9797
  3.2415 0.0350 0.0273 0.0212 0.0165 0.1000
> 
> # since sfHSD is the default for both sfu and sfl,
> # this could have been written as
> x <- gsDesign(k = 4, sfupar = -2, sflpar = 1)
> 
> # print again
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size   ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*  Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.324 0.03    0.5136 0.0350 2.80    0.0025  0.0025
         2  0.649 0.88    0.8096 0.0273 2.58    0.0049  0.0042
         3  0.973 1.51    0.9349 0.0212 2.34    0.0096  0.0069
         4  1.297 2.09    0.9817 0.0165 2.09    0.0183  0.0114
     Total                       0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Hwang-Shih-DeCani spending function with gamma = 1.
++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -2.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4  Total   E{N}
  0.0000 0.0025 0.0042 0.0065 0.0072 0.0203 0.5477
  3.2415 0.1695 0.3553 0.2774 0.0978 0.9000 0.7533

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4  Total
  0.0000 0.5136 0.3156 0.1169 0.0336 0.9797
  3.2415 0.0350 0.0273 0.0212 0.0165 0.1000
> 
> # plot the spending function using many points to obtain a smooth curve
> # show default values of gamma to see how the spending function changes
> # also show gamma=1 which is supposed to approximate a Pocock design
> t <- 0:100 / 100
> plot(t, sfHSD(0.025, t, -4)$spend,
+   xlab = "Proportion of final sample size",
+   ylab = "Cumulative Type I error spending",
+   main = "Hwang-Shih-DeCani Spending Function Example", type = "l"
+ )
> lines(t, sfHSD(0.025, t, -2)$spend, lty = 2)
> lines(t, sfHSD(0.025, t, 1)$spend, lty = 3)
> legend(
+   x = c(.0, .375), y = .025 * c(.8, 1), lty = 1:3,
+   legend = c("gamma= -4", "gamma= -2", "gamma= 1")
+ )
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sfLDOF")
> ### * sfLDOF
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfLDOF
> ### Title: Lan-DeMets Spending function overview
> ### Aliases: sfLDOF sfLDPocock
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # 2-sided,  symmetric 6-analysis trial Pocock
> # spending function approximation
> gsDesign(k = 6, sfu = sfLDPocock, test.type = 2)$upper$bound
[1] 2.495115 2.476907 2.454964 2.437262 2.423276 2.412059
> 
> # show actual Pocock design
> gsDesign(k = 6, sfu = "Pocock", test.type = 2)$upper$bound
[1] 2.453211 2.453211 2.453211 2.453211 2.453211 2.453211
> 
> # approximate Pocock again using a standard
> # Hwang-Shih-DeCani approximation
> gsDesign(k = 6, sfu = sfHSD, sfupar = 1, test.type = 2)$upper$bound
[1] 2.507958 2.471981 2.443139 2.426686 2.420302 2.421749
> 
> # use 'best' Hwang-Shih-DeCani approximation for Pocock,  k=6;
> # see manual for details
> gsDesign(k = 6, sfu = sfHSD, sfupar = 1.3354376, test.type = 2)$upper$bound
[1] 2.469285 2.448341 2.436191 2.437278 2.448837 2.468360
> 
> # 2-sided, symmetric 6-analysis trial
> # O'Brien-Fleming spending function approximation
> gsDesign(k = 6, sfu = sfLDOF, test.type = 2)$upper$bound
[1] 5.366558 3.710340 2.969736 2.538677 2.252190 2.044790
> 
> # show actual O'Brien-Fleming bound
> gsDesign(k = 6, sfu = "OF", test.type = 2)$upper$bound
[1] 5.028296 3.555542 2.903088 2.514148 2.248722 2.052793
> 
> # approximate again using a standard Hwang-Shih-DeCani
> # approximation to O'Brien-Fleming
> x <- gsDesign(k = 6, test.type = 2)
> x$upper$bound
[1] 3.325024 3.103223 2.860383 2.603454 2.330046 2.034988
> x$upper$param
[1] -4
> 
> # use 'best' exponential approximation for k=6; see manual for details
> gsDesign(
+   k = 6, sfu = sfExponential, sfupar = 0.7849295,
+   test.type = 2
+ )$upper$bound
[1] 4.998123 3.598098 2.933292 2.530838 2.253723 2.047082
> 
> # plot spending functions for generalized Lan-DeMets approximation of
> ti <-(0:100)/100
> rho <- c(.05,.5,1,1.5,2,2.5,3:6,8,10,12.5,15,20,30,200)/10
> df <- NULL
> for(r in rho){
+   df <- rbind(df,data.frame(t=ti,rho=r,alpha=.025,spend=sfLDOF(alpha=.025,t=ti,param=r)$spend))
+ }
> ggplot(df,aes(x=t,y=spend,col=as.factor(rho)))+
+   geom_line()+
+   guides(col=guide_legend(expression(rho)))+
+   ggtitle("Generalized Lan-DeMets O'Brien-Fleming Spending Function")
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sfLinear")
> ### * sfLinear
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfLinear
> ### Title: Piecewise Linear and Step Function Spending Functions
> ### Aliases: sfLinear sfStep
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # set up alpha spending and beta spending to be piecewise linear
> sfupar <- c(.2, .4, .05, .2)
> sflpar <- c(.3, .5, .65, .5, .75, .9)
> x <- gsDesign(sfu = sfLinear, sfl = sfLinear, sfupar = sfupar, sflpar = sflpar)
> plot(x, plottype = "sf")
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size   ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*  Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.474 0.63    0.7342 0.0542 2.67    0.0038  0.0037
         2  0.948 1.60    0.9455 0.0363 2.27    0.0117  0.0101
         3  1.422 2.11    0.9827 0.0095 2.11    0.0173  0.0111
     Total                       0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Piecewise linear spending function with line points = 0.3, line points = 0.5, line points = 0.65, line points = 0.5, line points = 0.75, line points = 0.9.
++ alpha spending:
 Piecewise linear spending function with line points = 0.2, line points = 0.4, line points = 0.05, line points = 0.2.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3 Total   E{N}
  0.0000 0.0038 0.0096 0.0056 0.019 0.6143
  3.2415 0.3291 0.4762 0.0947 0.900 0.8155

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3 Total
  0.0000 0.7342 0.2181 0.0288 0.981
  3.2415 0.0542 0.0363 0.0095 0.100
> 
> # now do an example where there is no lower-spending at interim 1
> # and no upper spending at interim 2
> sflpar <- c(1 / 3, 2 / 3, 0, .25)
> sfupar <- c(1 / 3, 2 / 3, .1, .1)
> x <- gsDesign(sfu = sfLinear, sfl = sfLinear, sfupar = sfupar, sflpar = sflpar)
> plot(x, plottype = "sf")
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*    Z   Nominal p Spend+   Z   Nominal p Spend++
         1  0.343 -20.00    0.0000  0.000  2.81    0.0025  0.0025
         2  0.685   0.72    0.7652  0.025 20.00    0.0000  0.0000
         3  1.028   1.99    0.9765  0.075  1.99    0.0235  0.0225
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Piecewise linear spending function with line points = 0.33333, line points = 0.66667, line points = 0, line points = 0.25.
++ alpha spending:
 Piecewise linear spending function with line points = 0.33333, line points = 0.66667, line points = 0.1, line points = 0.1.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1 2      3  Total   E{N}
  0.0000 0.0025 0 0.0219 0.0244 0.7638
  3.2415 0.1814 0 0.7186 0.9000 0.8947

Lower boundary (futility or Type II Error)
          Analysis
   Theta 1      2      3  Total
  0.0000 0 0.7651 0.2105 0.9756
  3.2415 0 0.0250 0.0750 0.1000
> 
> # now do an example where timing of interims changes slightly, but error spending does not
> # also, spend all alpha when at least >=90 percent of final information is in the analysis
> sfupar <- c(.2, .4, .9, ((1:3) / 3)^3)
> x <- gsDesign(k = 3, n.fix = 100, sfu = sfStep, sfupar = sfupar, test.type = 1)
> plot(x, pl = "sf")
> # original planned sample sizes
> ceiling(x$n.I)
[1]  34  68 102
> # cumulative spending planned at original interims
> cumsum(x$upper$spend)
[1] 0.0009259259 0.0074074074 0.0250000000
> # change timing of analyses;
> # note that cumulative spending "P(Cross) if delta=0" does not change from cumsum(x$upper$spend)
> # while full alpha is spent, power is reduced by reduced sample size
> y <- gsDesign(
+   k = 3, sfu = sfStep, sfupar = sfupar, test.type = 1,
+   maxn.IPlan = x$n.I[x$k], n.I = c(30, 70, 95),
+   n.fix = x$n.fix
+ )
> # note that full alpha is used, but power is reduced due to lowered sample size
> gsBoundSummary(y)
  Analysis               Value Efficacy
 IA 1: 29%                   Z   3.1130
     N: 30         p (1-sided)   0.0009
               ~delta at bound   1.7534
           P(Cross) if delta=0   0.0009
           P(Cross) if delta=1   0.0905
 IA 2: 69%                   Z   2.4662
     N: 70         p (1-sided)   0.0068
               ~delta at bound   0.9094
           P(Cross) if delta=0   0.0074
           P(Cross) if delta=1   0.6004
     Final                   Z   1.9975
     N: 95         p (1-sided)   0.0229
               ~delta at bound   0.6322
           P(Cross) if delta=0   0.0250
           P(Cross) if delta=1   0.8807
> 
> # now show how step function can be abused by 'adapting' stage 2 sample size based on interim result
> x <- gsDesign(k = 2, delta = .05, sfu = sfStep, sfupar = c(.02, .001), timing = .02, test.type = 1)
> # spending jumps from miniscule to full alpha at first analysis after interim 1
> plot(x, pl = "sf")
> # sample sizes at analyses:
> ceiling(x$n.I)
[1]   85 4204
> # simulate 1 million stage 1 sum of 178 Normal(0,1) random variables
> # Normal(0,Variance=178) under null hypothesis
> s1 <- rnorm(1000000, 0, sqrt(178))
> # compute corresponding z-values
> z1 <- s1 / sqrt(178)
> # set stage 2 sample size to 1 if z1 is over final bound, otherwise full sample size
> n2 <- rep(1, 1000000)
> n2[z1 < 1.96] <- ceiling(x$n.I[2]) - ceiling(178)
> # now sample n2 observations for second stage
> s2 <- rnorm(1000000, 0, sqrt(n2))
> # add sum and divide by standard deviation
> z2 <- (s1 + s2) / (sqrt(178 + n2))
> # By allowing full spending when final analysis is either
> # early or late depending on observed interim z1,
> # Type I error is now almost twice the planned .025
> sum(z1 >= x$upper$bound[1] | z2 >= x$upper$bound[2]) / 1000000
[1] 0.046803
> # if stage 2 sample size is random and independent of z1 with same frequency,
> # this is not a problem
> s1alt <- rnorm(1000000, 0, sqrt(178))
> z1alt <- s1alt / sqrt(178)
> z2alt <- (s1alt + s2) / sqrt(178 + n2)
> sum(z1alt >= x$upper$bound[1] | z2alt >= x$upper$bound[2]) / 1000000
[1] 0.024982
> 
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sfPoints")
> ### * sfPoints
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfPoints
> ### Title: Pointwise Spending Function
> ### Aliases: sfPoints
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # example to specify spending on a pointwise basis
> x <- gsDesign(
+   k = 6, sfu = sfPoints, sfupar = c(.01, .05, .1, .25, .5, 1),
+   test.type = 2
+ )
> x
Symmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Spending computations assume trial stops
if a bound is crossed.

           Sample
            Size 
  Analysis Ratio*  Z   Nominal p  Spend
         1  0.171 3.48    0.0002 0.0003
         2  0.342 3.07    0.0011 0.0010
         3  0.512 2.94    0.0017 0.0013
         4  0.683 2.58    0.0050 0.0037
         5  0.854 2.33    0.0099 0.0063
         6  1.025 2.03    0.0211 0.0125
     Total                       0.0250 

++ alpha spending:
 User-specified spending function with Points = 0.01, Points = 0.05, Points = 0.1, Points = 0.25, Points = 0.5, Points = 1.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4      5      6 Total   E{N}
  0.0000 0.0002 0.0010 0.0013 0.0038 0.0063 0.0125 0.025 1.0171
  3.2415 0.0161 0.1072 0.1626 0.2666 0.2066 0.1409 0.900 0.7282

Lower boundary (futility or Type II Error)
          Analysis
   Theta     1     2      3      4      5      6 Total
  0.0000 2e-04 0.001 0.0013 0.0038 0.0063 0.0125 0.025
  3.2415 0e+00 0.000 0.0000 0.0000 0.0000 0.0000 0.000
> 
> # get proportion of upper spending under null hypothesis
> # at each analysis
> y <- x$upper$prob[, 1] / .025
> 
> # change to cumulative proportion of spending
> for (i in 2:length(y))
+   y[i] <- y[i - 1] + y[i]
> 
> # this should correspond to input sfupar
> round(y, 6)
[1] 0.01 0.05 0.10 0.25 0.50 1.00
> 
> # plot these cumulative spending points
> plot(1:6 / 6, y,
+   main = "Pointwise spending function example",
+   xlab = "Proportion of final sample size",
+   ylab = "Cumulative proportion of spending",
+   type = "p"
+ )
> 
> # approximate this with a t-distribution spending function
> # by fitting 3 points
> tx <- 0:100 / 100
> lines(tx, sfTDist(1, tx, c(c(1, 3, 5) / 6, .01, .1, .5))$spend)
> text(x = .6, y = .9, labels = "Pointwise Spending Approximated by")
> text(x = .6, y = .83, "t-Distribution Spending with 3-point interpolation")
> 
> # example without lower spending at initial interim or
> # upper spending at last interim
> x <- gsDesign(
+   k = 3, sfu = sfPoints, sfupar = c(.25, .25),
+   sfl = sfPoints, sflpar = c(0, .25)
+ )
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*    Z   Nominal p Spend+   Z   Nominal p Spend++
         1  0.351 -20.00    0.0000  0.000  2.50    0.0063  0.0063
         2  0.703   0.76    0.7758  0.025 20.00    0.0000  0.0000
         3  1.054   2.04    0.9793  0.075  2.04    0.0207  0.0188
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 User-specified spending function with Points = 0, Points = 0.25, Points = 1.
++ alpha spending:
 User-specified spending function with Points = 0.25, Points = 0.25, Points = 1.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1 2      3  Total   E{N}
  0.0000 0.0063 0 0.0182 0.0245 0.7773
  3.2415 0.2822 0 0.6178 0.9000 0.8470

Lower boundary (futility or Type II Error)
          Analysis
   Theta 1      2      3  Total
  0.0000 0 0.7755 0.2001 0.9755
  3.2415 0 0.0250 0.0750 0.1000
> 
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sfPower")
> ### * sfPower
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfPower
> ### Title: Kim-DeMets (power) Spending Function
> ### Aliases: sfPower
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # design a 4-analysis trial using a Kim-DeMets spending function
> # for both lower and upper bounds
> x <- gsDesign(k = 4, sfu = sfPower, sfupar = 3, sfl = sfPower, sflpar = 1.5)
> 
> # print the design
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size    ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.282 -0.52    0.3015 0.0125 3.36    0.0004  0.0004
         2  0.564  0.53    0.7028 0.0229 2.76    0.0029  0.0027
         3  0.846  1.32    0.9072 0.0296 2.36    0.0092  0.0074
         4  1.128  2.03    0.9788 0.0350 2.03    0.0212  0.0145
     Total                        0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Kim-DeMets (power) spending function with rho = 1.5.
++ alpha spending:
 Kim-DeMets (power) spending function with rho = 3.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4  Total  E{N}
  0.0000 0.0004 0.0027 0.0073 0.0116 0.0221 0.579
  3.2415 0.0507 0.3248 0.3619 0.1626 0.9000 0.768

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4  Total
  0.0000 0.3015 0.4138 0.2008 0.0619 0.9779
  3.2415 0.0125 0.0229 0.0296 0.0350 0.1000
> 
> # plot the spending function using many points to obtain a smooth curve
> # show rho=3 for approximation to O'Brien-Fleming and rho=.75 for
> # approximation to Pocock design.
> # Also show rho=2 for an intermediate spending.
> # Compare these to Hwang-Shih-DeCani spending with gamma=-4,  -2,  1
> t <- 0:100 / 100
> plot(t, sfPower(0.025, t, 3)$spend,
+   xlab = "Proportion of sample size",
+   ylab = "Cumulative Type I error spending",
+   main = "Kim-DeMets (rho) versus Hwang-Shih-DeCani (gamma) Spending",
+   type = "l", cex.main = .9
+ )
> lines(t, sfPower(0.025, t, 2)$spend, lty = 2)
> lines(t, sfPower(0.025, t, 0.75)$spend, lty = 3)
> lines(t, sfHSD(0.025, t, 1)$spend, lty = 3, col = 2)
> lines(t, sfHSD(0.025, t, -2)$spend, lty = 2, col = 2)
> lines(t, sfHSD(0.025, t, -4)$spend, lty = 1, col = 2)
> legend(
+   x = c(.0, .375), y = .025 * c(.65, 1), lty = 1:3,
+   legend = c("rho= 3", "rho= 2", "rho= 0.75")
+ )
> legend(
+   x = c(.0, .357), y = .025 * c(.65, .85), lty = 1:3, bty = "n", col = 2,
+   legend = c("gamma= -4", "gamma= -2", "gamma=1")
+ )
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sfSpecial")
> ### * sfSpecial
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfTruncated
> ### Title: Truncated, trimmed and gapped spending functions
> ### Aliases: sfTruncated sfTrimmed sfGapped
> ### Keywords: design
> 
> ### ** Examples
> 
> 
> 
> # Eliminate efficacy spending forany interim at or before 20 percent of information.
> # Complete spending at first interim at or after 80 percent of information.
> tx <- (0:100) / 100
> s <- sfHSD(alpha = .05, t = tx, param = 1)$spend
> x <- data.frame(t = tx, Spending = s, sf = "Original spending")
> param <- list(trange = c(.2, .8), sf = sfHSD, param = 1)
> s <- sfTruncated(alpha = .05, t = tx, param = param)$spend
> x <- rbind(x, data.frame(t = tx, Spending = s, sf = "Truncated"))
> s <- sfTrimmed(alpha = .05, t = tx, param = param)$spend
> x <- rbind(x, data.frame(t = tx, Spending = s, sf = "Trimmed"))
> s <- sfGapped(alpha = .05, t = tx, param = param)$spend
> x <- rbind(x, data.frame(t = tx, Spending = s, sf = "Gapped"))
> ggplot2::ggplot(x, ggplot2::aes(x = t, y = Spending, col = sf)) + 
+ ggplot2::geom_line()
> 
> 
> # now apply the sfTrimmed version in gsDesign
> # initially, eliminate the early efficacy analysis
> # note: final spend must occur at > next to last interim
> x <- gsDesign(
+   k = 4, n.fix = 100, sfu = sfTrimmed,
+   sfupar = list(sf = sfHSD, param = 1, trange = c(.3, .9))
+ )
> 
> # first upper bound=20 means no testing there
> gsBoundSummary(x)
  Analysis               Value Efficacy Futility
 IA 1: 25%                   Z  20.0000  -0.5316
     N: 31         p (1-sided)   0.0000   0.7025
               ~delta at bound  11.1795  -0.2972
           P(Cross) if delta=0   0.0000   0.2975
           P(Cross) if delta=1   0.0000   0.0102
 IA 2: 50%                   Z   2.1555   0.4956
     N: 61         p (1-sided)   0.0156   0.3101
               ~delta at bound   0.8520   0.1959
           P(Cross) if delta=0   0.0155   0.7033
           P(Cross) if delta=1   0.6458   0.0269
 IA 3: 75%                   Z   2.3061   1.3812
     N: 92         p (1-sided)   0.0106   0.0836
               ~delta at bound   0.7442   0.4457
           P(Cross) if delta=0   0.0208   0.9208
           P(Cross) if delta=1   0.8136   0.0545
     Final                   Z   2.3352   2.3352
    N: 122         p (1-sided)   0.0098   0.0098
               ~delta at bound   0.6527   0.6527
           P(Cross) if delta=0   0.0242   0.9758
           P(Cross) if delta=1   0.9000   0.1000
> 
> # now, do not eliminate early efficacy analysis
> param <- list(sf = sfHSD, param = 1, trange = c(0, .9))
> x <- gsDesign(k = 4, n.fix = 100, sfu = sfTrimmed, sfupar = param)
> 
> # The above means if final analysis is done a little early, all spending can occur
> # Suppose we set calendar date for final analysis based on
> # estimated full information, but come up with only 97 pct of plan
> xA <- gsDesign(
+   k = x$k, n.fix = 100, n.I = c(x$n.I[1:3], .97 * x$n.I[4]),
+   test.type = x$test.type,
+   maxn.IPlan = x$n.I[x$k],
+   sfu = sfTrimmed, sfupar = param
+ )
> # now accelerate without the trimmed spending function
> xNT <- gsDesign(
+   k = x$k, n.fix = 100, n.I = c(x$n.I[1:3], .97 * x$n.I[4]),
+   test.type = x$test.type,
+   maxn.IPlan = x$n.I[x$k],
+   sfu = sfHSD, sfupar = 1
+ )
> # Check last bound if analysis done at early time
> x$upper$bound[4]
[1] 2.357469
> # Now look at last bound if done at early time with trimmed spending function
> # that allows capture of full alpha
> xA$upper$bound[4]
[1] 2.343624
> # With original spending function, we don't get full alpha and therefore have
> # unnecessarily stringent bound at final analysis
> xNT$upper$bound[4]
[1] 2.37218
> 
> # note that if the last analysis is LATE, all 3 approaches should give the same
> # final bound that has a little larger z-value
> xlate <- gsDesign(
+   k = x$k, n.fix = 100, n.I = c(x$n.I[1:3], 1.25 * x$n.I[4]),
+   test.type = x$test.type,
+   maxn.IPlan = x$n.I[x$k],
+   sfu = sfHSD, sfupar = 1
+ )
> xlate$upper$bound[4]
[1] 2.435171
> 
> # eliminate futility after the first interim analysis
> # note that by setting trange[1] to .2, the spend at t=.2 is used for the first
> # interim at or after 20 percent of information
> x <- gsDesign(n.fix = 100, sfl = sfGapped, sflpar = list(trange = c(.2, .9), sf = sfHSD, param = 1))
> 
> 
> 
> cleanEx()
> nameEx("sfTDist")
> ### * sfTDist
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfTDist
> ### Title: t-distribution Spending Function
> ### Aliases: sfTDist
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # 3-parameter specification: a,  b,  df
> sfTDist(1, 1:5 / 6, c(-1, 1.5, 4))$spend
[1] 0.02851967 0.08253974 0.18695048 0.38823035 0.72415039
> 
> # 5-parameter specification fits 2 points,  in this case
> # the 1st 2 interims are at 25% and 50% of observations with
> # cumulative error spending of 10% and 20%, respectively
> # final parameter is df
> sfTDist(1, 1:3 / 4, c(.25, .5, .1, .2, 4))$spend
[1] 0.1000000 0.2000000 0.3724396
> 
> # 6-parameter specification fits 3 points
> # Interims are at 25%. 50% and 75% of observations
> # with cumulative spending of 10%, 20% and 50%, respectively
> # Note: not all 3 point combinations can be fit
> sfTDist(1, 1:3 / 4, c(.25, .5, .75, .1, .2, .5))$spend
[1] 0.1000000 0.2000000 0.5000006
> 
> # Example of error message when the 3-points specified
> # in the 6-parameter version cannot be fit
> try(sfTDist(1, 1:3 / 4, c(.25, .5, .75, .1, .2, .3))$errmsg)
Error in sfTDist(1, 1:3/4, c(0.25, 0.5, 0.75, 0.1, 0.2, 0.3)) : 
  6-parameter specification of t-distribution spending function did not produce a solution
> 
> # sfCauchy (sfTDist with 1 df) and sfNormal (sfTDist with infinite df)
> # show the limits of what sfTdist can fit
> # for the third point are u3 from 0.344 to 0.6 when t3=0.75
> sfNormal(1, 1:3 / 4, c(.25, .5, .1, .2))$spend[3]
[1] 0.3439558
> sfCauchy(1, 1:3 / 4, c(.25, .5, .1, .2))$spend[3]
[1] 0.6
> 
> # plot a few t-distribution spending functions fitting
> # t=0.25, .5 and u=0.1, 0.2
> # to demonstrate the range of flexibility
> t <- 0:100 / 100
> plot(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 1))$spend,
+   xlab = "Proportion of final sample size",
+   ylab = "Cumulative Type I error spending",
+   main = "t-Distribution Spending Function Examples", type = "l"
+ )
> lines(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 1.5))$spend, lty = 2)
> lines(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 3))$spend, lty = 3)
> lines(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 10))$spend, lty = 4)
> lines(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 100))$spend, lty = 5)
> legend(
+   x = c(.0, .3), y = .025 * c(.7, 1), lty = 1:5,
+   legend = c("df = 1", "df = 1.5", "df = 3", "df = 10", "df = 100")
+ )
> 
> 
> 
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("sfXG")
> ### * sfXG
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sfXG1
> ### Title: Xi and Gallo conditional error spending functions
> ### Aliases: sfXG1 sfXG sfXG2 sfXG3
> ### Keywords: design
> 
> ### ** Examples
> 
> # Plot conditional error spending spending functions across
> # a range of values of interest
> pts <- seq(0, 1.2, 0.01)
> pal <- palette()
> 
> plot(
+   pts,
+   sfXG1(0.025, pts, 0.5)$spend,
+   type = "l", col = pal[1],
+   xlab = "t", ylab = "Spending", main = "Xi-Gallo, Method 1"
+ )
> lines(pts, sfXG1(0.025, pts, 0.6)$spend, col = pal[2])
> lines(pts, sfXG1(0.025, pts, 0.75)$spend, col = pal[3])
> lines(pts, sfXG1(0.025, pts, 0.9)$spend, col = pal[4])
> legend(
+   "topleft",
+   legend = c("gamma=0.5", "gamma=0.6", "gamma=0.75", "gamma=0.9"),
+   col = pal[1:4],
+   lty = 1
+ )
> 
> plot(
+   pts,
+   sfXG2(0.025, pts, 0.14)$spend,
+   type = "l", col = pal[1],
+   xlab = "t", ylab = "Spending", main = "Xi-Gallo, Method 2"
+ )
> lines(pts, sfXG2(0.025, pts, 0.25)$spend, col = pal[2])
> lines(pts, sfXG2(0.025, pts, 0.5)$spend, col = pal[3])
> lines(pts, sfXG2(0.025, pts, 0.75)$spend, col = pal[4])
> lines(pts, sfXG2(0.025, pts, 0.9)$spend, col = pal[5])
> legend(
+   "topleft",
+   legend = c("gamma=0.14", "gamma=0.25", "gamma=0.5", "gamma=0.75", "gamma=0.9"),
+   col = pal[1:5],
+   lty = 1
+ )
> 
> plot(
+   pts,
+   sfXG3(0.025, pts, 0.013)$spend,
+   type = "l", col = pal[1],
+   xlab = "t", ylab = "Spending", main = "Xi-Gallo, Method 3"
+ )
> lines(pts, sfXG3(0.025, pts, 0.02)$spend, col = pal[2])
> lines(pts, sfXG3(0.025, pts, 0.05)$spend, col = pal[3])
> lines(pts, sfXG3(0.025, pts, 0.1)$spend, col = pal[4])
> lines(pts, sfXG3(0.025, pts, 0.25)$spend, col = pal[5])
> lines(pts, sfXG3(0.025, pts, 0.5)$spend, col = pal[6])
> lines(pts, sfXG3(0.025, pts, 0.75)$spend, col = pal[7])
> lines(pts, sfXG3(0.025, pts, 0.9)$spend, col = pal[8])
> legend(
+   "bottomright",
+   legend = c(
+     "gamma=0.013", "gamma=0.02", "gamma=0.05", "gamma=0.1",
+     "gamma=0.25", "gamma=0.5", "gamma=0.75", "gamma=0.9"
+   ),
+   col = pal[1:8],
+   lty = 1
+ )
> 
> 
> 
> cleanEx()
> nameEx("spendingFunction")
> ### * spendingFunction
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.spendfn
> ### Title: Spending Function
> ### Aliases: summary.spendfn spendingFunction
> ### Keywords: design
> 
> ### ** Examples
> 
> # Example 1: simple example showing what most users need to know
> 
> # Design a 4-analysis trial using a Hwang-Shih-DeCani spending function
> # for both lower and upper bounds
> x <- gsDesign(k = 4, sfu = sfHSD, sfupar = -2, sfl = sfHSD, sflpar = 1)
> 
> # Print the design
> x
Asymmetric two-sided group sequential design with
90 % power and 2.5 % Type I Error.
Upper bound spending computations assume
trial continues if lower bound is crossed.

           Sample
            Size   ----Lower bounds----  ----Upper bounds-----
  Analysis Ratio*  Z   Nominal p Spend+  Z   Nominal p Spend++
         1  0.324 0.03    0.5136 0.0350 2.80    0.0025  0.0025
         2  0.649 0.88    0.8096 0.0273 2.58    0.0049  0.0042
         3  0.973 1.51    0.9349 0.0212 2.34    0.0096  0.0069
         4  1.297 2.09    0.9817 0.0165 2.09    0.0183  0.0114
     Total                       0.1000                 0.0250 
+ lower bound beta spending (under H1):
 Hwang-Shih-DeCani spending function with gamma = 1.
++ alpha spending:
 Hwang-Shih-DeCani spending function with gamma = -2.
* Sample size ratio compared to fixed design with no interim

Boundary crossing probabilities and expected sample size
assume any cross stops the trial

Upper boundary (power or Type I Error)
          Analysis
   Theta      1      2      3      4  Total   E{N}
  0.0000 0.0025 0.0042 0.0065 0.0072 0.0203 0.5477
  3.2415 0.1695 0.3553 0.2774 0.0978 0.9000 0.7533

Lower boundary (futility or Type II Error)
          Analysis
   Theta      1      2      3      4  Total
  0.0000 0.5136 0.3156 0.1169 0.0336 0.9797
  3.2415 0.0350 0.0273 0.0212 0.0165 0.1000
> # Summarize the spending functions
> summary(x$upper)
[1] "Hwang-Shih-DeCani spending function with gamma = -2"
> summary(x$lower)
[1] "Hwang-Shih-DeCani spending function with gamma = 1"
> 
> # Plot the alpha- and beta-spending functions
> plot(x, plottype = 5)
> 
> # What happens to summary if we used a boundary function design
> x <- gsDesign(test.type = 2, sfu = "OF")
> y <- gsDesign(test.type = 1, sfu = "WT", sfupar = .25)
> summary(x$upper)
[1] "O'Brien-Fleming boundary"
> summary(y$upper)
[1] "Wang-Tsiatis boundary with Delta = 0.25"
> 
> # Example 2: advanced example: writing a new spending function
> # Most users may ignore this!
> 
> # Implementation of 2-parameter version of
> # beta distribution spending function
> # assumes t and alpha are appropriately specified (does not check!)
> sfbdist <- function(alpha, t, param) {
+   # Check inputs
+   checkVector(param, "numeric", c(0, Inf), c(FALSE, TRUE))
+   if (length(param) != 2) {
+     stop(
+       "b-dist example spending function parameter must be of length 2"
+     )
+   }
+ 
+   # Set spending using cumulative beta distribution and return
+   x <- list(
+     name = "B-dist example", param = param, parname = c("a", "b"),
+     sf = sfbdist, spend = alpha *
+       pbeta(t, param[1], param[2]), bound = NULL, prob = NULL
+   )
+ 
+   class(x) <- "spendfn"
+ 
+   x
+ }
> 
> # Now try it out!
> # Plot some example beta (lower bound) spending functions using
> # the beta distribution spending function
> t <- 0:100 / 100
> plot(
+   t, sfbdist(1, t, c(2, 1))$spend,
+   type = "l",
+   xlab = "Proportion of information",
+   ylab = "Cumulative proportion of total spending",
+   main = "Beta distribution Spending Function Example"
+ )
> lines(t, sfbdist(1, t, c(6, 4))$spend, lty = 2)
> lines(t, sfbdist(1, t, c(.5, .5))$spend, lty = 3)
> lines(t, sfbdist(1, t, c(.6, 2))$spend, lty = 4)
> legend(
+   x = c(.65, 1), y = 1 * c(0, .25), lty = 1:4,
+   legend = c("a=2, b=1", "a=6, b=4", "a=0.5, b=0.5", "a=0.6, b=2")
+ )
> 
> 
> 
> cleanEx()
> nameEx("ssrCP")
> ### * ssrCP
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: condPower
> ### Title: Sample size re-estimation based on conditional power
> ### Aliases: condPower ssrCP plot.ssrCP z2NC z2Z z2Fisher Power.ssrCP
> ### Keywords: design
> 
> ### ** Examples
> 
> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> # quick trick for simple conditional power based on interim z-value, stage 1 and 2 sample size
> # assumed treatment effect and final alpha level
> # and observed treatment effect
> alpha <- .01 # set final nominal significance level
> timing <- .6 # set proportion of sample size, events or statistical information at IA
> n2 <- 40 # set stage 2 sample size events or statistical information
> hr <- .6 # for this example we will derive conditional power based on hazard ratios
> n.fix <- nEvents(hr=hr,alpha=alpha) # you could otherwise make n.fix an arbitrary positive value
> # this just derives a group sequential design that should not change sample size from n.fix
> # due to stringent IA bound
> x <- gsDesign(k=2,n.fix=n.fix,alpha=alpha,test.type=1,sfu=sfHSD,
+ sfupar=-20,timing=timing,delta1=log(hr))
> # derive effect sizes for which you wish to compute conditional power
> hrpostIA = seq(.4,1,.05)
> # in the following, we convert HR into standardized effect size based on the design in x
> powr <- condPower(x=x,z1=1,n2=x$n.I[2]-x$n.I[1],theta=log(hrpostIA)/x$delta1*x$theta[2])
> ggplot(
+   data.frame(
+     x = hrpostIA,
+     y = condPower(
+       x = x,
+       z1 = 1,
+       n2 = x$n.I[2] - x$n.I[1],
+       theta = log(hrpostIA) / x$delta1 * x$theta[2]
+     )
+   ),
+   aes(x = x, y = y)
+ ) +
+   geom_line() +
+   labs(
+     x = "HR post IA",
+     y = "Conditional power",
+     title = "Conditional power as a function of assumed HR"
+   )
> 
> # Following is a template for entering parameters for ssrCP
> # Natural parameter value null and alternate hypothesis values
> delta0 <- 0
> delta1 <- 1
> # timing of interim analysis for underlying group sequential design
> timing <- .5
> # upper spending function
> sfu <- sfHSD
> # upper spending function paramater
> sfupar <- -12
> # maximum sample size inflation
> maxinflation <- 2
> # assumed enrollment overrrun at IA
> overrun <- 25
> # interim z-values for plotting
> z <- seq(0, 4, .025)
> # Type I error (1-sided)
> alpha <- .025
> # Type II error for design
> beta <- .1
> # Fixed design sample size
> n.fix <- 100
> # conditional power interval where sample
> # size is to be adjusted
> cpadj <- c(.3, .9)
> # targeted Type II error when adapting sample size
> betastar <- beta
> # combination test (built-in options are: z2Z, z2NC, z2Fisher)
> z2 <- z2NC
> 
> # use the above parameters to generate design
> # generate a 2-stage group sequential design with
> x <- gsDesign(
+   k = 2, n.fix = n.fix, timing = timing, sfu = sfu, sfupar = sfupar,
+   alpha = alpha, beta = beta, delta0 = delta0, delta1 = delta1
+ )
> # extend this to a conditional power design
> xx <- ssrCP(
+   x = x, z1 = z, overrun = overrun, beta = betastar, cpadj = cpadj,
+   maxinc = maxinflation, z2 = z2
+ )
> # plot the stage 2 sample size
> plot(xx)
> # demonstrate overlays on this plot
> # overlay with densities for z1 under different hypotheses
> lines(z, 80 + 240 * dnorm(z, mean = 0), col = 2)
> lines(z, 80 + 240 * dnorm(z, mean = sqrt(x$n.I[1]) * x$theta[2]), col = 3)
> lines(z, 80 + 240 * dnorm(z, mean = sqrt(x$n.I[1]) * x$theta[2] / 2), col = 4)
> lines(z, 80 + 240 * dnorm(z, mean = sqrt(x$n.I[1]) * x$theta[2] * .75), col = 5)
> axis(side = 4, at = 80 + 240 * seq(0, .4, .1), labels = as.character(seq(0, .4, .1)))
> mtext(side = 4, expression(paste("Density for ", z[1])), line = 2)
> text(x = 1.5, y = 90, col = 2, labels = expression(paste("Density for ", theta, "=0")))
> text(x = 3.00, y = 180, col = 3, labels = expression(paste("Density for ", theta, "=",
+  theta[1])))
> text(x = 1.00, y = 180, col = 4, labels = expression(paste("Density for ", theta, "=",
+  theta[1], "/2")))
> text(x = 2.5, y = 140, col = 5, labels = expression(paste("Density for ", theta, "=",
+  theta[1], "*.75")))
> # overall line for max sample size
> nalt <- xx$maxinc * x$n.I[2]
> lines(x = par("usr")[1:2], y = c(nalt, nalt), lty = 2)
> 
> # compare above design with different combination tests
> # use sufficient statistic for final testing
> xxZ <- ssrCP(
+   x = x, z1 = z, overrun = overrun, beta = betastar, cpadj = cpadj,
+   maxinc = maxinflation, z2 = z2Z
+ )
> # use Fisher combination test for final testing
> xxFisher <- ssrCP(
+   x = x, z1 = z, overrun = overrun, beta = betastar, cpadj = cpadj,
+   maxinc = maxinflation, z2 = z2Fisher
+ )
> # combine data frames from these designs
> y <- rbind(
+   data.frame(xx$dat, Test = "Normal combination"),
+   data.frame(xxZ$dat, Test = "Sufficient statistic"),
+   data.frame(xxFisher$dat, Test = "Fisher combination")
+ )
> # plot stage 2 statistic required for positive combination test
> ggplot2::ggplot(data = y, ggplot2::aes(x = z1, y = z2, col = Test)) + 
+ ggplot2::geom_line()
> # plot total sample size versus stage 1 test statistic
> ggplot2::ggplot(data = y, ggplot2::aes(x = z1, y = n2, col = Test)) + 
+ ggplot2::geom_line()
> # check achieved Type I error for sufficient statistic design
> Power.ssrCP(x = xxZ, theta = 0)
  theta delta     Power       en
1     0     0 0.0220804 95.11565
> 
> # compare designs using observed vs planned theta for conditional power
> xxtheta1 <- ssrCP(
+   x = x, z1 = z, overrun = overrun, beta = betastar, cpadj = cpadj,
+   maxinc = maxinflation, z2 = z2, theta = x$delta
+ )
> # combine data frames for the 2 designs
> y <- rbind(
+   data.frame(xx$dat, "CP effect size" = "Obs. at IA"),
+   data.frame(xxtheta1$dat, "CP effect size" = "Alt. hypothesis")
+ )
> # plot stage 2 sample size by design
> ggplot2::ggplot(data = y, ggplot2::aes(x = z1, y = n2, col = CP.effect.size)) + 
+ ggplot2::geom_line()
> # compare power and expected sample size
> y1 <- Power.ssrCP(x = xx)
> y2 <- Power.ssrCP(x = xxtheta1)
> # combine data frames for the 2 designs
> y3 <- rbind(
+   data.frame(y1, "CP effect size" = "Obs. at IA"),
+   data.frame(y2, "CP effect size" = "Alt. hypothesis")
+ )
> # plot expected sample size by design and effect size
> ggplot2::ggplot(data = y3, ggplot2::aes(x = delta, y = en, col = CP.effect.size)) + 
+ ggplot2::geom_line() +
+ ggplot2::xlab(expression(delta)) + 
+ ggplot2::ylab("Expected sample size")
> # plot power by design and effect size
> ggplot2::ggplot(data = y3, ggplot2::aes(x = delta, y = Power, col = CP.effect.size)) + 
+ ggplot2::geom_line() + 
+ ggplot2::xlab(expression(delta))
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()

detaching ‘package:ggplot2’

> nameEx("toBinomialExact")
> ### * toBinomialExact
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: toBinomialExact
> ### Title: Translate survival design bounds to exact binomial bounds
> ### Aliases: toBinomialExact
> 
> ### ** Examples
> 
> # The following code derives the group sequential design using the method
> # of Lachin and Foulkes
> 
> x <- gsSurv(
+   k = 3,                 # 3 analyses
+   test.type = 4,         # Non-binding futility bound 1 (no futility bound) and 4 are allowable
+   alpha = .025,          # 1-sided Type I error
+   beta = .1,             # Type II error (1 - power)
+   timing = c(0.45, 0.7), # Proportion of final planned events at interims
+   sfu = sfHSD,           # Efficacy spending function
+   sfupar = -4,           # Parameter for efficacy spending function
+   sfl = sfLDOF,          # Futility spending function; not needed for test.type = 1
+   sflpar = 0,            # Parameter for futility spending function
+   lambdaC = .001,        # Exponential failure rate
+   hr = 0.3,              # Assumed proportional hazard ratio (1 - vaccine efficacy = 1 - VE)
+   hr0 = 0.7,             # Null hypothesis VE
+   eta = 5e-04,           # Exponential dropout rate
+   gamma = 10,            # Piecewise exponential enrollment rates
+   R = 16,                # Time period durations for enrollment rates in gamma
+   T = 24,                # Planned trial duration
+   minfup = 8,            # Planned minimum follow-up
+   ratio = 3              # Randomization ratio (experimental:control)
+ )
> # Convert bounds to exact binomial bounds
> toBinomialExact(x)
             Bounds
  Analysis   N   a   b
         1  31  12  22
         2  48  23  30
         3  69  38  39

Boundary crossing probabilities and expected sample size assume
any cross stops the trial

Upper boundary
          Analysis
   Theta      1      2      3  Total E{N}
  0.6774 0.4328 0.3960 0.1523 0.9811 44.1
  0.4737 0.0068 0.0206 0.0578 0.0851 52.2

Lower boundary
          Analysis
   Theta      1      2      3  Total
  0.6774 0.0008 0.0030 0.0151 0.0189
  0.4737 0.2167 0.3767 0.3215 0.9149
> # Update bounds at time of analysis
> toBinomialExact(x, observedEvents = c(20,55,80))
             Bounds
  Analysis   N   a   b
         1  20   6  17
         2  55  28  33
         3  80  45  46

Boundary crossing probabilities and expected sample size assume
any cross stops the trial

Upper boundary
          Analysis
   Theta      1      2      3  Total E{N}
  0.6774 0.0732 0.8400 0.0668 0.9800 54.4
  0.4737 0.0006 0.0404 0.0205 0.0615 57.1

Lower boundary
          Analysis
   Theta      1      2      3  Total
  0.6774 0.0006 0.0067 0.0127 0.0200
  0.4737 0.0903 0.6571 0.1911 0.9385
> 
> 
> 
> cleanEx()
> nameEx("toInteger")
> ### * toInteger
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: toInteger
> ### Title: Translate group sequential design to integer events (survival
> ###   designs) or sample size (other designs)
> ### Aliases: toInteger
> 
> ### ** Examples
> 
> # The following code derives the group sequential design using the method
> # of Lachin and Foulkes
> 
> x <- gsSurv(
+   k = 3,                 # 3 analyses
+   test.type = 4,         # Non-binding futility bound 1 (no futility bound) and 4 are allowable
+   alpha = .025,          # 1-sided Type I error
+   beta = .1,             # Type II error (1 - power)
+   timing = c(0.45, 0.7), # Proportion of final planned events at interims
+   sfu = sfHSD,           # Efficacy spending function
+   sfupar = -4,           # Parameter for efficacy spending function
+   sfl = sfLDOF,          # Futility spending function; not needed for test.type = 1
+   sflpar = 0,            # Parameter for futility spending function
+   lambdaC = .001,        # Exponential failure rate
+   hr = 0.3,              # Assumed proportional hazard ratio (1 - vaccine efficacy = 1 - VE)
+   hr0 = 0.7,             # Null hypothesis VE
+   eta = 5e-04,           # Exponential dropout rate
+   gamma = 10,            # Piecewise exponential enrollment rates
+   R = 16,                # Time period durations for enrollment rates in gamma
+   T = 24,                # Planned trial duration
+   minfup = 8,            # Planned minimum follow-up
+   ratio = 3              # Randomization ratio (experimental:control)
+ )
> # Convert sample size to multiple of ratio + 1 = 4, round event counts.
> # Default is to round up both event count and sample size for final analysis
> toInteger(x)
Group sequential design (method=; k=3 analyses; Two-sided asymmetric with non-binding futility)
N=9064.0 subjects | D=69.0 events | T=24.2 study duration | accrual=16.0 Accrual duration | minfup=8.2 minimum follow-up | ratio=3 randomization ratio (experimental/control)

Spending functions:
  Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4.
  Futility bounds derived using a Lan-DeMets O'Brien-Fleming approximation spending function (no parameters).

Analysis summary:
   Analysis              Value Efficacy Futility
  IA 1: 45%                  Z   2.8273   0.0695
    N: 8626        p (1-sided)   0.0023   0.4723
 Events: 31       ~HR at bound   0.2167   0.6801
  Month: 15 P(Cross) if HR=0.7   0.0023   0.5277
            P(Cross) if HR=0.3   0.2863   0.0141
  IA 2: 70%                  Z   2.5197   1.1139
    N: 9064        p (1-sided)   0.0059   0.1327
 Events: 48       ~HR at bound   0.3022   0.4829
  Month: 19 P(Cross) if HR=0.7   0.0071   0.8716
            P(Cross) if HR=0.3   0.6265   0.0486
      Final                  Z   2.0035   2.0035
    N: 9064        p (1-sided)   0.0226   0.0226
 Events: 69       ~HR at bound   0.4010   0.4010
  Month: 24 P(Cross) if HR=0.7   0.0230   0.9770
            P(Cross) if HR=0.3   0.9027   0.0973

Key inputs (names preserved):
                               desc    item value   input
                    Accrual rate(s)   gamma 566.5   gamma
           Accrual rate duration(s)       R    16       R
             Control hazard rate(s) lambdaC 0.001 lambdaC
            Control dropout rate(s)     eta     0     eta
       Experimental dropout rate(s)    etaE     0    etaE
 Event and dropout rate duration(s)       S  NULL       S
> 
> 
> 
> cleanEx()
> nameEx("varBinomial")
> ### * varBinomial
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ciBinomial
> ### Title: Testing, Confidence Intervals, Sample Size and Power for
> ###   Comparing Two Binomial Rates
> ### Aliases: ciBinomial nBinomial simBinomial testBinomial varBinomial
> ### Keywords: design
> 
> ### ** Examples
> 
> 
> # Compute z-test test statistic comparing 39/500 to 13/500
> # use continuity correction in variance
> x <- testBinomial(x1 = 39, x2 = 13, n1 = 500, n2 = 500, adj = 1)
> x
[1] 3.701266
> pnorm(x, lower.tail = FALSE)
[1] 0.0001072634
> 
> # Compute with unadjusted variance
> x0 <- testBinomial(x1 = 39, x2 = 23, n1 = 500, n2 = 500)
> x0
[1] 2.098083
> pnorm(x0, lower.tail = FALSE)
[1] 0.0179489
> 
> # Perform 50k simulations to test validity of the above
> # asymptotic p-values
> # (you may want to perform more to reduce standard error of estimate)
> sum(as.double(x0) <=
+   simBinomial(p1 = .078, p2 = .078, n1 = 500, n2 = 500, nsim = 10000)) / 10000
[1] 0.0182
> sum(as.double(x0) <=
+   simBinomial(p1 = .052, p2 = .052, n1 = 500, n2 = 500, nsim = 10000)) / 10000
[1] 0.0174
> 
> # Perform a non-inferiority test to see if p2=400 / 500 is within 5% of
> # p1=410 / 500 use a z-statistic with unadjusted variance
> x <- testBinomial(x1 = 410, x2 = 400, n1 = 500, n2 = 500, delta0 = -.05)
> x
[1] 2.807617
> pnorm(x, lower.tail = FALSE)
[1] 0.002495478
> 
> # since chi-square tests equivalence (a 2-sided test) rather than
> # non-inferiority (a 1-sided test),
> # the result is quite different
> pchisq(testBinomial(
+   x1 = 410, x2 = 400, n1 = 500, n2 = 500, delta0 = -.05,
+   chisq = 1, adj = 1
+ ), 1, lower.tail = FALSE)
[1] 0.005012758
> 
> # now simulate the z-statistic witthout continuity corrected variance
> sum(qnorm(.975) <=
+   simBinomial(p1 = .8, p2 = .8, n1 = 500, n2 = 500, nsim = 100000)) / 100000
[1] 0.0241
> 
> # compute a sample size to show non-inferiority
> # with 5% margin, 90% power
> nBinomial(p1 = .2, p2 = .2, delta0 = .05, alpha = .025, sided = 1, beta = .1)
[1] 2697.607
> 
> # assuming a slight advantage in the experimental group lowers
> # sample size requirement
> nBinomial(p1 = .2, p2 = .19, delta0 = .05, alpha = .025, sided = 1, beta = .1)
[1] 4131.9
> 
> # compute a sample size for comparing 15% vs 10% event rates
> # with 1 to 2 randomization
> nBinomial(p1 = .15, p2 = .1, beta = .2, ratio = 2, alpha = .05)
[1] 1191.041
> 
> # now look at total sample size using 1-1 randomization
> n <- nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05)
> n
[1] 1079.853
> # check if inputing sample size returns the desired power
> nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, n = n)
[1] 0.8
> 
> # re-do with alternate output types
> nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, outtype = 2)
        n1       n2
1 539.9264 539.9264
> nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, outtype = 3)
         n       n1       n2 alpha sided beta Power    sigma0    sigma1   p1
1 1079.853 539.9264 539.9264  0.05     1  0.2   0.8 0.6614378 0.6595453 0.15
   p2 delta0   p10   p20
1 0.1      0 0.125 0.125
> 
> # look at power plot under different control event rate and
> # relative risk reductions
> library(dplyr)
Warning: package ‘dplyr’ was built under R version 4.5.2

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(ggplot2)
Warning: package ‘ggplot2’ was built under R version 4.5.2
> p1 <- seq(.075, .2, .000625)
> len <- length(p1)
> p2 <- c(p1 * .75, p1 * 2/3, p1 * .6, p1 * .5)
> Reduction <- c(rep("25 percent", len), rep("33 percent", len), 
+                rep("40 percent", len), rep("50 percent", len))
> df <- tibble(p1 = rep(p1, 4), p2, Reduction) |>
+   mutate(`Sample size` = nBinomial(p1, p2, beta = .2, alpha = .025, sided = 1))
> ggplot(df, aes(x = p1, y = `Sample size`, col = Reduction)) + 
+   geom_line() + 
+   xlab("Control group event rate") +
+   ylim(0,6000) +
+   ggtitle("Binomial sample size computation for 80 pct power")
> 
> # compute blinded estimate of treatment effect difference
> x1 <- rbinom(n = 1, size = 100, p = .2)
> x2 <- rbinom(n = 1, size = 200, p = .1)
> # blinded estimate of risk difference variance
> varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0)
[1] 0.001947333
> # blinded estimate of log-risk-ratio variance
> varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0, scale = "RR")
[1] 0.08282609
> # blinded estimate of log-odds-ratio variance
> varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0, scale = "OR")
[1] 0.1155426
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()

detaching ‘package:ggplot2’, ‘package:dplyr’

> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  3.624 0.112 3.792 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
