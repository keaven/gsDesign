[{"path":"https://keaven.github.io/gsDesign/articles/GentleIntroductionToGSD.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"A gentle introduction to group sequential design","text":"article intended give gentle mathematical statistical introduction group sequential design. also provide relatively simple examples literature explain clinical applications. programming shown, accessing source article required programming can accessed; substantial commenting provided source hope users can understand implement concepts developed . Hopefully, mathematical statistical concepts introduced discourage wishing understand underlying concepts group sequential design. group sequential design enables repeated analysis endpoint clinical trial enable possible early stopping trial either positive result, futility, safety issue. approach can limit exposure risk patients clinical trial investment past time known unacceptable safety risks established endpoint interest, limit investment trial interim results suggest evaluation positive efficacy finding futile, accelerate availability highly effective treatment enabling early approval following early positive finding. Examples outcomes might considered include: continuous outcome change baseline fixed follow-time HAM-D depression score, absolute difference risk ratio response rate (e.g., oncology) failure rate binary (yes/) outcome, hazard ratio time--event time--death disease progression oncology trial time cardiovascular event (death, myocardial infarction unstable angina). Examples include: new treatment major depression interim analysis continuous outcome stopped trial futility (Binneman et al. (2008)), new treatment patients unstable angina undergoing balloon angioplasty positive interim finding binary outcome death, myocardial infarction urgent repeat intervention within 30 days (CAPTURE Investigators (1997)), new treatment patients lung cancer based positive interim finding time--death (Gandhi et al. (2018)).","code":""},{"path":"https://keaven.github.io/gsDesign/articles/GentleIntroductionToGSD.html","id":"group-sequential-design-framework","dir":"Articles","previous_headings":"","what":"Group sequential design framework","title":"A gentle introduction to group sequential design","text":"assume two-arm clinical trial control experimental group. \\(k\\) analyses planned integer \\(k> 1.\\) natural parameter \\(\\delta\\) describing underlying treatment difference estimate asymptotically normal efficient estimate \\(\\hat\\delta_j\\) variance \\(\\sigma_j^2\\) corresponding statistical information \\(\\mathcal{}_j=1/\\sigma_j^2\\), analysis \\(j=1,2,\\ldots,k\\). positive value favoring experimental treatment negative value favoring control. assume consistent estimate \\(\\hat\\sigma_j^2\\) \\(\\sigma_j^2, j=1,2,\\ldots,k\\). information fraction defined \\(t_j=\\mathcal{}_i/\\mathcal{}_j\\) analysis \\(j=1,\\ldots,k\\). Correlations estimates different analyses \\(\\hbox{Corr}(\\hat\\delta_i,\\hat\\delta_j)=\\sqrt{\\mathcal{}_i/\\mathcal{}_j}=\\sqrt{t_j}\\) \\(1\\le \\le j\\le k.\\) test test \\(Z_j\\approx\\hat\\delta_j/\\hat{\\sigma}^2_j.\\) time--event outcome, \\(\\delta\\) typically represent logarithm hazard ratio control group versus experimental group. difference response rates, \\(\\delta\\) represent underlying response rates. continuous outcome HAM-D, examine difference change baseline milestone time point (e.g., 6 weeks Binneman et al. (2008)). \\(j=1,\\ldots,k\\), tests \\(Z_j\\) asymptotically multivariate normal correlations , \\(=1,\\ldots,k\\) \\(\\hbox{Cov}(Z_i,Z_j)=\\hbox{Corr}(\\hat\\delta_i,\\hat\\delta_j)\\) \\(E(Z_j)=\\delta\\sqrt{I_j}.\\) multivariate asymptotic normal distribution \\(Z_1,\\ldots,Z_k\\) referred canonical form Jennison Turnbull (2000) also summarized much surrounding literature.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/GentleIntroductionToGSD.html","id":"one-sided-testing","dir":"Articles","previous_headings":"Bounds for testing","what":"One-sided testing","title":"A gentle introduction to group sequential design","text":"assume primary test null hypothesis \\(H_{0}\\): \\(\\delta=0\\) alternative \\(H_{1}\\): \\(\\delta = \\delta_1\\) fixed effect size \\(\\delta_1 > 0\\) represents benefit experimental treatment compared control. assume interest stopping early good evidence reject one hypothesis favor . \\(=1,2,\\ldots,k-1\\), interim cutoffs \\(l_{}< u_{}\\) set; final cutoffs \\(l_{k}\\leq u_{k}\\) also set. \\(=1,2,\\ldots,k\\), trial stopped analysis \\(\\) reject \\(H_{0}\\) \\(l_{j}<Z_{j}< u_{j}\\), \\(j=1,2,\\dots,-1\\) \\(Z_{}\\geq u_{}\\). trial continues stage \\(\\), \\(H_{0}\\) rejected stage \\(\\), \\(Z_{}\\leq l_{}\\) \\(H_{1}\\) rejected favor \\(H_{0}\\), \\(=1,2,\\ldots,k\\). Thus, \\(3k\\) parameters define group sequential design: \\(l_{}\\), \\(u_{}\\), \\(\\mathcal{}_{}\\), \\(=1,2,\\ldots,k\\). Note \\(l_{k}< u_{k}\\) possibility completing trial without rejecting \\(H_{0}\\) \\(H_{1}\\). often restrict \\(l_{k}= u_{k}\\) one hypothesis rejected. begin one-sided test. case interest stopping early lower bound thus \\(l_i= -\\infty\\), \\(=1,2,\\ldots,k\\). probability first crossing upper bound analysis \\(\\), \\(=1,2,\\ldots,k\\), \\[\\alpha_{}^{+}(\\delta)=P_{\\delta}\\{\\{Z_{}\\geq u_{}\\}\\cap_{j=1}^{-1} \\{Z_{j}< u_{j}\\}\\}\\] Type error probability ever crossing upper bound \\(\\delta=0\\). value \\(\\alpha^+_{}(0)\\) commonly referred amount Type error spent analysis \\(\\), \\(1\\leq \\leq k\\). total upper boundary crossing probability trial denoted one-sided scenario \\[\\alpha^+(\\delta) \\equiv \\sum_{=1}^{k}\\alpha^+_{}(\\delta)\\] total Type error \\(\\alpha^+(0)\\). Assuming \\(\\alpha^+(0)=\\alpha\\) design said provide one-sided group sequential test level \\(\\alpha\\).","code":""},{"path":"https://keaven.github.io/gsDesign/articles/GentleIntroductionToGSD.html","id":"binding","dir":"Articles","previous_headings":"Bounds for testing","what":"Asymmetric two-sided testing","title":"A gentle introduction to group sequential design","text":"lower upper bounds testing real value \\(\\delta\\) representing treatment effect denote probability crossing upper boundary analysis \\(\\) without previously crossing bound \\[\\alpha_{}(\\delta)=P_{\\delta}\\{\\{Z_{}\\geq u_{}\\}\\cap_{j=1}^{-1} \\{ l_{j}<Z_{j}< u_{j}\\}\\},\\] \\(=1,2,\\ldots,k.\\) total probability crossing upper bound prior crossing lower bound denoted \\[\\alpha(\\delta)\\equiv\\sum_{=1}^{k}\\alpha_{}(\\delta).\\] Next, consider analogous notation lower bound. \\(=1,2,\\ldots,k\\) denote probability crossing lower bound analysis \\(\\) without previously crossing bound \\[\\beta_{}(\\delta)=P_{\\delta}\\{\\{Z_{}\\leq l_{}\\}\\cap_{j=1}^{-1}\\{ l_{j} <Z_{j}< u_{j}\\}\\}.\\] total lower boundary crossing probability case written \\[\\beta(\\delta)= {\\sum\\limits_{=1}^{k}} \\beta_{}(\\delta).\\] design final bounds equal (\\(l_k=u_k\\)), \\(\\beta(\\delta_1)\\) Type II error equal 1 minus power design. case, \\(\\beta_i(\\delta)\\) referred \\(\\beta\\)-spending analysis \\(, =1,\\ldots,k\\).","code":""},{"path":"https://keaven.github.io/gsDesign/articles/GentleIntroductionToGSD.html","id":"spending-function-design","dir":"Articles","previous_headings":"","what":"Spending function design","title":"A gentle introduction to group sequential design","text":"Type error often defined \\(\\alpha_i^+(0), =1,\\ldots,k\\). referred non-binding Type error since lower bound ignored calculation. means trial continued spite lower bound crossed interim analysis Type error still controlled design \\(\\alpha\\)-level. Phase III trials used approvals new treatments, non-binding Type error calculation generally expected regulators. given \\(0<\\alpha<1\\) define non-decreasing \\(\\alpha\\)-spending function \\(f(t; \\alpha)\\) \\(t\\geq 0\\) \\(\\alpha\\left( 0\\right) =0\\) \\(t\\geq 1\\), \\(f( t; \\alpha) =\\alpha\\). Letting \\(t_0=0\\), set \\(\\alpha_j(0)\\) \\(j=1,\\ldots,k\\) equation \\[\\alpha^+_{j}(0) = f(t_j;\\alpha)-f(t_{j-1}; \\alpha).\\] Assuming asymmetric lower bound, similarly use \\(\\beta\\)-spending function set \\(\\beta\\)-spending analysis \\(j=1,\\ldots, k\\) : \\[\\beta_{j}(\\delta_1) = g(t_j;\\delta_1, \\beta) - g(t_{j-1};\\delta_1, \\beta).\\] following example, function \\(\\Phi()\\) represents cumulative distribution function standard normal distribution function (.e., mean 0, standard deviation 1). major depression study Binneman et al. (2008) considered used Lan DeMets (1983) spending function approximating O’Brien-Fleming bound single interim analysis half way trial \\[f(t; \\alpha) = 2\\left(  1-\\Phi\\left(  \\frac{\\Phi ^{-1}(\\alpha/2)}{\\sqrt{t}}\\right)  \\right).\\] \\[g(t; \\beta) = 2\\left(  1-\\Phi\\left(  \\frac{\\Phi ^{-1}(\\beta/2)}{\\sqrt{t}}\\right)  \\right).\\] planned design used \\(\\alpha=0.1\\), one-sided Type II error 17% (83% power) interim analysis 50% final planned observations. leads Type \\(\\alpha\\)-spending 0.02 \\(\\beta\\)-spending 0.052 planned interim. advantage spending function approach bounds can adjusted number observations analyses different planned. actual observations experimental versus control analysis 59 opposed planned 67, resulted interim spending fraction \\(t_1=\\) 0.4403. Lan-DeMets spending function approximate O’Brien-Fleming bounds results \\(\\alpha\\)-spending 0.0132 (P(Cross) delta=0 row Efficacy column) \\(\\beta\\)-spending 0.0386 (P(Cross) delta=3 row Futility column). note Z-value 1-sided p-values table correspond exactly either can used evaluation statistical significance trial result. rows labeled ~delta bound approximations describe approximately treatment difference required cross bound; used formal evaluation whether bound crossed. O’Brien-Fleming spending function generally felt provide conservative bounds stopping interim analysis. error spending reserved final analysis example. futility bound required small trend wrong direction stop trial; nominal p-value 0.77 observed crossed futility bound, stopping trial since greater futility p-value bound 0.59. Finally, note final analysis, cumulative probability P(Cross) delta=0 less planned \\(\\alpha=0.10\\). probability represents \\(\\alpha(0)\\) excludes probability crossing lower bound interim analysis final analysis. value non-binding Type error still \\(\\alpha^+(0) = 0.10\\).","code":"library(gsDesign) delta1 <- 3 # Treatment effect, alternate hypothesis delta0 <- 0 # Treatment effect, null hypothesis ratio <- 1 # Randomization ratio (experimental / control) sd <- 7.5 # Standard deviation for change in HAM-D score alpha <- 0.1 # 1-sided Type I error beta <- 0.17 # Targeted Type II error (1 - targeted power) k <- 2 # Number of planned analyses test.type <- 4 # Asymmetric bound design with non-binding futility bound timing <- .5 # information fraction at interim analyses sfu <- sfLDOF # O'Brien-Fleming spending function for alpha-spending sfupar <- 0 # Parameter for upper spending function sfl <- sfLDOF # O'Brien-Fleming spending function for beta-spending sflpar <- 0 # Parameter for lower spending function delta <- 0 endpoint <- \"normal\" # Derive normal fixed design sample size n <- nNormal(   delta1 = delta1,   delta0 = delta0,   ratio = ratio,   sd = sd,   alpha = alpha,   beta = beta ) # Derive group sequential design based on parameters above x <- gsDesign(   k = k,   test.type = test.type,   alpha = alpha,   beta = beta,   timing = timing,   sfu = sfu,   sfupar = sfupar,   sfl = sfl,   sflpar = sflpar,   delta = delta, # Not used since n.fix is provided   delta1 = delta1,   delta0 = delta0,   endpoint = \"normal\",   n.fix = n ) # Convert sample size at each analysis to integer values x <- toInteger(x) # Updated alpha is unchanged alphau <- 0.1 # Updated sample size at each analysis n.I <- c(59, 134) # Updated number of analyses ku <- length(n.I) # Information fraction is used for spending usTime <- n.I / x$n.I[x$k] lsTime <- usTime # Update design based on actual interim sample size and planned final sample size xu <- gsDesign(   k = ku,   test.type = test.type,   alpha = alphau,   beta = x$beta,   sfu = sfu,   sfupar = sfupar,   sfl = sfl,   sflpar = sflpar,   n.I = n.I,   maxn.IPlan = x$n.I[x$k],   delta = x$delta,   delta1 = x$delta1,   delta0 = x$delta0,   endpoint = endpoint,   n.fix = n,   usTime = usTime,   lsTime = lsTime ) # Summarize bounds gsBoundSummary(xu, Nname = \"N\", digits = 4, ddigits = 2, tdigits = 1) #>   Analysis               Value Efficacy Futility #>  IA 1: 44%                   Z   2.2209  -0.2304 #>      N: 59         p (1-sided)   0.0132   0.5911 #>                ~delta at bound   4.3370  -0.4500 #>            P(Cross) if delta=0   0.0132   0.4089 #>            P(Cross) if delta=3   0.2468   0.0386 #>      Final                   Z   1.3047   1.3047 #>     N: 134         p (1-sided)   0.0960   0.0960 #>                ~delta at bound   1.6907   1.6907 #>            P(Cross) if delta=0   0.0965   0.9035 #>            P(Cross) if delta=3   0.8350   0.1650"},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"A cure model calendar-based design","text":"present study design time--event outcome based cure model (Rodrigues et al. (2009)). case, assumed tail behavior survival substantial interest desire stop final analysis substantial follow-4 years allowed accrue. assumed substantial events accrued time period, sacrifice power unreasonable. Due well substantial variability event accrual caused feasible differences event rates, use calendar-based design, including calendar-based spending (Lan DeMets (1989)). discuss potential advantages disadvantages cure model calendar-based design cases hazard rates events decrease substantially time true underlying distributions may meaningfully deviate anticipated time design.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"the-poisson-mixture-model","dir":"Articles","previous_headings":"","what":"The Poisson mixture model","title":"A cure model calendar-based design","text":"Poisson mixture model cure model can useful failure rate population expected decline substantially time based historical data. also property control group time--event follows Poisson mixture distribution, proportional hazards assumption treatment effect yield another Poisson mixture distribution experimental group. model flexible easy use control distribution specified two parameters transparent fashion: cure rate one survival rate arbitrarily specified time point.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"scenario-assumptions","dir":"Articles","previous_headings":"The Poisson mixture model","what":"Scenario assumptions","title":"A cure model calendar-based design","text":"consider three scenarios demonstrate spending can impact potential trial success fully understanding treatment group differences. following can adjusted reader vignette re-run. assume constant enrollment rate duration enrollment, allowing different assumed enrollment durations scenario. following code can easily changed study alternate scenarios.","code":"# Control group assumptions for three Poisson mixture cure models cure_rate <- c(.5, .35, .55) # Second time point for respective models t1 <- c(24, 24, 24) # Survival rate at 2nd time point for respective models s1 <- c(.65, .5, .68) time_unit <- \"month\" # Hazard ratio for experimental versus control for respective models hr <- c(.7, .75, .7) # Total study duration study_duration <- c(48, 48, 56) # Number of bins for piecewise approximation bins <- 5 # This code should be updated by user for their scenario # Enrollment duration by scenario enroll_duration <- c(12, 12, 20) # Dropout rate (exponential failure rate per time unit) by scenario dropout_rate <- c(.002, .001, .001)"},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"the-poisson-mixture-model-1","dir":"Articles","previous_headings":"The Poisson mixture model","what":"The Poisson Mixture Model","title":"A cure model calendar-based design","text":"Poisson mixture model (Rodrigues et al. (2009)) assumes cure rate \\(p\\) represent patients benefit long-term. survival function function time \\(t\\) control group (\\(c\\)) : \\[S_c(t)=\\exp(-\\theta(1-\\exp(-\\lambda t))),\\] \\(\\theta = -\\log(p)\\), \\(\\lambda> 0\\) constant hazard rate \\(t\\ge 0\\). component \\(\\exp(-\\lambda t)\\) exponential survival distribution; replaced arbitrary survival distribution \\(t>0\\) mixture model, exponential model simple, adequately flexible easy explain. two-parameter model can specified cure rate assumed survival rate \\(S_c(t_1)\\) time \\(0 <t_1<\\infty.\\) study, control group cure rate assumed 0.5, 0.35, 0.55 survival month assumed 0.65, 0.5, 0.68. can solve \\(\\theta\\) \\(\\lambda\\) follows: \\[S_c(\\infty) = e^\\theta \\Rightarrow \\theta = -\\log(S_c(\\infty)) \\] little algebra, can solve \\(\\lambda\\): \\[S_c(t_1)= \\exp(-\\theta(1-\\exp(-\\lambda t_1))) \\Rightarrow \\lambda =  -\\log(1 + \\log(S_c(t_1)) / \\theta) / t_1\\]","code":""},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"supporting-functions","dir":"Articles","previous_headings":"The Poisson mixture model","what":"Supporting functions","title":"A cure model calendar-based design","text":"create following functions support examples . pPM() computes Poisson mixture survival function hPM() computes Poisson mixture hazard rates readers skip reviewing code.","code":"# Poisson mixture survival pPM <- function(x = 0:20, cure_rate = .5, t1 = 10, s1 = .6) {   theta <- -log(cure_rate)   lambda <- -log(1 + log(s1) / theta) / t1   return(exp(-theta * (1 - exp(-lambda * x)))) } # Poisson mixture hazard rate hPM <- function(x = 0:20, cure_rate = .5, t1 = 10, s1 = .6) {   theta <- -log(cure_rate)   lambda <- -log(1 + log(s1) / theta) / t1   return(theta * lambda * exp(-lambda * x)) }"},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"examples","dir":"Articles","previous_headings":"The Poisson mixture model","what":"Examples","title":"A cure model calendar-based design","text":"note proportional hazards assumption hazard ratio \\(\\gamma > 0\\) survival funtion experimental group (e) : \\[S_e(t)=\\exp(-\\theta\\gamma(1-\\exp(-\\lambda t))).\\] noted , \\((1 - \\exp(-\\lambda t)\\) can replaced cumulative distribution positive random variable. setting chosen, ideal able cite published literature rationale study assumptions. points following graph indicate underlying cumulative hazard matches piecewise exponential specified cure rate models scenario. piecewise failure model used derive sample size targeted events time trial.  also evaluate failure rate time, higher scenario 2. later used design derivation. Note piecewise intervals used approximate changing hazard rates can made arbitrarily small get precise approximations . However, given uncertainty underlying assumptions, clear provides advantage.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"event-accumulation","dir":"Articles","previous_headings":"The Poisson mixture model","what":"Event Accumulation","title":"A cure model calendar-based design","text":"Based model, predict events accumulate control group, experimental group alternate hypothesis overall based either null hypothesis failure rate difference alternate hypothesis events accrue slowly experimental group. scenario. use denominator final planned events alternate hypothesis scenario 1. Now compare event accrual null alternate hypothesis scenario, 100% representing targeted final events scenario 1. user update code . 3 scenarios studied, event accrual quite different, creating difference spending issues.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"design-assumptions","dir":"Articles","previous_headings":"Study design","what":"Design assumptions","title":"A cure model calendar-based design","text":"choose calendar-based timing analyses well spending. done automatically gsSurv() function. two steps particular walk : get information fraction levels correspond targeted calendar analysis times plug planned design. Replacing information fraction levels calendar fraction levels \\(\\alpha\\)- \\(\\beta\\)-spending. begin specifying calendar times analysis find corresponding fractions final planned events calendar time design assumptions. Now move design assumptions.","code":"h1s1_EF <- event_accrual %>%   filter(Scenario == 1 & Hypothesis == \"H1\" & Time %in% c(12, 24, 36)) %>%   select(Time, EF) h1s1_EF #> # A tibble: 3 × 2 #>    Time    EF #>   <dbl> <dbl> #> 1    12 0.284 #> 2    24 0.683 #> 3    36 0.888 # Interim analysis timing (information fraction) timing <- h1s1_EF$EF timing_calendar <- h1s1_EF$Time / study_duration # Get hazard rate info for Scenario 1 control group control <- hazard %>% filter(Scenario == 1, Treatment == \"Control\") # Failure rates lambdaC <- control$hazard_rate # Interval durations S <- (control$Time - control$time_lagged)[1:(bins - 1)] # 1-sided Type I error alpha <- 0.025 # Type II error (1 - power) beta <- .1 # Test type 6: asymmetric 2-sided design, non-binding futility bound test.type <- 6 # 1-sided Type I error used for safety (for asymmetric 2-sided design) astar <- .2 # Spending functions (sfu, sfl) and parameters (sfupar, sflpar) sfu <- sfHSD # O'Brien-Fleming approximation by Lan and DeMets sfupar <- -4 # Not needed for sfLDPocock sfl <- sfLDPocock # Near-equal Z-values for each analysis sflpar <- NULL # Not needed for Pocock spending # Dropout rate (exponential parameter per unit of time) dropout_rate <- 0.002 # Experimental / control randomization ratio ratio <- 1"},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"study-design-and-event-accumulation","dir":"Articles","previous_headings":"Study design","what":"Study Design and Event Accumulation","title":"A cure model calendar-based design","text":"now assume trial enrolled constant enrollment rate 12, 12, 20 months trial duration 48, 48, 56. noted , event accumulation pattern highly sensitive assumptions design. Deviations plan accrual, hazard ratio overall time well relatively minor deviations cure model assumption substantially change calendar time event-based analysis timing. Thus, calendar-based timing spending (Lan DeMets (1989)) may appeal make timing analyses predictable. main risk likely -accumulation final targeted events trial. targeted 4-year window may considered clinically important well important limitation trial duration. Using predicted information fractions 6, 12, 24, 36, 48, 60 months plan calendar-based design. use arguments usTime lsTime change calendar-based spending upper lower bounds, respectively. However, pattern slowing event accumulation time year 1 seems reasonably likely persist. means calendar-based spending likely give conservative bounds since calendar fractions lower information fractions text overlay plot first interim: 10%, 20%, 40%, 60%, 80% 100%, respectively. now use information fractions text overlay set calendar-based design.","code":"design_calendar <-   gsSurv(     k = length(timing) + 1,     alpha = alpha,     beta = beta,     astar = astar,     test.type = test.type,     timing = timing, # Planned event fractions here     hr = hr[1],     R = enroll_duration[1],     gamma = 1,     T = study_duration[1],     minfup = study_duration[1] - enroll_duration[1],     ratio = ratio,     sfu = sfu,     sfupar = sfupar,     usTime = timing_calendar, # Use calendar-based spending     sfl = sfl,     sflpar = sflpar,     lambdaC = lambdaC,     lsTime = timing_calendar, # Use calendar-based spending     S = S   ) design_calendar %>%   gsBoundSummary(exclude = c(\"B-value\", \"CP\", \"CP H1\", \"PP\")) %>%   gt() %>%   tab_header(     title = \"Calendar-Based Design\",     subtitle = \"Calendar Spending\"   )"},{"path":"https://keaven.github.io/gsDesign/articles/PoissonMixtureModel.html","id":"considerations","dir":"Articles","previous_headings":"","what":"Considerations","title":"A cure model calendar-based design","text":"things note design: futility bounds advisory . particular, late futility bounds may ignored since follow-full time period may merit continuing trial. Substantial deviations event accumulation change timing analyses calendar times. considered acceptability time design. first efficacy bound extreme essentially makes first analysis futility . likely reasonable based minimal follow-time. Z-values hazard ratios required positive efficacy finding terribly extreme starting two-year follow-analysis. also probably reasonable long hazard ratio differences bounds clinically meaningful. extreme finding year 1 may likely required positive finding. trial may continued crossing efficacy bound follow-unlikely control patients well cross experimental therapy absence adverse clinical outcomes. Inference subsequent analyses using repeated p-values (Jennison Turnbull (2000)) sequential p-values (Liu Anderson (2008)) well-specified interpretable adjusted p-values.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Overview of survival endpoint design","text":"article/vignette provides summary functions gsDesign package supporting design evaluation trial designs time--event outcomes. focus detailed output options, numbers summarizing design based . looking level detail just want see design fixed group sequential design time--event endpoint, see vignette Basic time--event group sequential design using gsSurv. following functions support use straightforward Schoenfeld (1981) approximation 2-arm trials: nEvents(): number events achieve power power given number events interim analysis. zn2hr(), gsHR() gsBoundSummary(): approximate observed hazard ratio (HR) required achieve targeted Z-value given number events. hrn2z(): approximate Z-value corresponding specified HR event count. hrz2n(): approximate event count corresponding specified HR Z-value. functions directly support sample size calculations. done Lachin Foulkes (1986) method. Functions include: nSurvival(): Sample size restricted single enrollment rate; single analysis. nSurv(): flexible enrollment scenarios; single analysis. gsSurv(): Group sequential design extension nSurv(). Output survival design information supported various formats: gsBoundSummary(): Tabular summary design data frame. plot.gsDesign(): Various plot summaries design. gsHR(): Approximate HR required cross bound.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"schoenfeld-approximation-support","dir":"Articles","previous_headings":"","what":"Schoenfeld approximation support","title":"Overview of survival endpoint design","text":"assume hazard ratio \\(\\nu < 1\\) represents benefit experimental treatment control. let \\(\\delta = \\log\\nu\\) denote -called natural parameter case. Asymptotically distribution Cox model estimate \\(\\hat{\\delta}\\) proportional hazards assumption \\[\\hat\\delta\\sim \\hbox{Normal}(\\delta=\\log\\nu, (1+r)^2/nr).\\] Using Cox model estimate \\(\\delta\\), Wald test \\(\\hbox{H_0}: \\delta=0\\) can approximated asymptotic variance : \\[Z_W\\approx \\frac{\\sqrt {nr}}{1+r}\\hat\\delta=\\frac{\\ln(\\hat\\nu)\\sqrt{nr}}{1+r}.\\] Also, know Wald test \\(Z_W\\) standard normal version logrank \\(Z\\) asymptotically efficient therefore asymptotically equivalent. denote standardized effect size \\[\\theta = \\delta\\sqrt r / (1+r)= \\log(\\nu)\\sqrt r / (1+r).\\] Letting \\(\\hat\\theta = -\\sqrt r/(1+r)\\hat\\delta\\) \\[ \\hat \\theta \\sim \\hbox{Normal}(\\theta, 1/ n).\\] Thus, standardized Z version logrank approximately distributed \\[Z\\sim\\hbox{Normal}(\\sqrt n\\theta,1).\\] Treatment effect favoring experimental treatment compared control notation corresponds hazard ratio \\(\\nu < 1\\), well negative values standardized effect \\(\\theta\\), natural parameter \\(\\delta\\) standardized Z-test.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"power-and-sample-size-with-nevents","dir":"Articles","previous_headings":"Schoenfeld approximation support","what":"Power and sample size with nEvents()","title":"Overview of survival endpoint design","text":"Based , power logrank test approximated \\[P[Z\\le z]=\\Phi(z -\\sqrt n\\theta)=\\Phi(z- \\sqrt{nr}/(1+r)\\log\\nu).\\] Thus, assuming \\(n=100\\) events \\(\\delta = \\log\\nu=-\\log(.7)\\), \\(r=1\\) (equal randomization) approximate power logrank test \\(\\alpha=0.025\\) can compute gsDesign::nEvents() : solve number events \\(n\\) see many events required obtain desired power \\[1-\\beta=P(Z\\ge \\Phi^{-1}(1-\\alpha))\\] \\[n = \\left(\\frac{\\Phi^{-1} (1-\\alpha)+\\Phi^{-1}(1-\\beta)}{\\theta}\\right)^2 =\\frac{(1+r)^2}{r(\\log\\nu)^2}\\left({\\Phi^{-1} (1-\\alpha)+\\Phi^{-1}(1-\\beta)}\\right)^2.\\] Thus, approximate number events required power HR=0.7 \\(\\alpha=0.025\\) one-sided power \\(1-\\beta=0.9\\) , rounding , matches (tabular output): notation delta table changes sign standardized treatment effect \\(\\theta\\) : se table estimated standard error log hazard ratio \\(\\delta=\\log\\hat\\nu\\)","code":"n <- 100 hr <- .7 delta <- log(hr) alpha <- .025 r <- 1 pnorm(qnorm(alpha) - sqrt(n * r) / (1 + r) * delta) #> [1] 0.4299155 nEvents(n = n, alpha = alpha, hr = hr, r = r) #> [1] 0.4299155 beta <- 0.1 (1 + r)^2 / r / log(hr)^2 * ((qnorm(1 - alpha) + qnorm(1 - beta)))^2 #> [1] 330.3779 nEvents(hr = hr, alpha = alpha, beta = beta, r = 1, tbl = TRUE) %>%   kable() theta <- delta * sqrt(r) / (1 + r) theta #> [1] -0.1783375 (1 + r) / sqrt(331 * r) #> [1] 0.1099299"},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"group-sequential-design","dir":"Articles","previous_headings":"Schoenfeld approximation support","what":"Group sequential design","title":"Overview of survival endpoint design","text":"can create group sequential design problem either \\(\\theta\\) fixed design sample size. parameter delta gsDesign() corresponds standardized effect size sign changed \\(-\\theta\\) notation used Jennison Turnbull (2000), natural parameter, \\(\\log(\\hbox{HR})\\) parameter delta1 passed gsDesign(). name effect size specified deltaname parameter logdelta = TRUE indicates delta input needs exponentiated obtain HR output . example code can useful practice. begin passing number events fixed design parameter n.fix (continuous, rounded) adapt group sequential design.","code":"Schoenfeld <- gsDesign(   k = 2,   n.fix = nEvents(hr = hr, alpha = alpha, beta = beta, r = 1),   delta1 = log(hr) ) Schoenfeld %>%   gsBoundSummary(deltaname = \"HR\", logdelta = TRUE) %>%   kable(row.names = FALSE)"},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"information-based-design","dir":"Articles","previous_headings":"Schoenfeld approximation support","what":"Information based design","title":"Overview of survival endpoint design","text":"Exactly result can obtained following, passing standardized effect size theta parameter delta gsDesign(). noted asymptotic variance \\(\\hat\\theta\\) \\(1/n\\) corresponds statistical information \\(\\mathcal =n\\) parameter \\(\\theta\\). Thus, value corresponds number events statistical information standardized effect size \\(\\theta\\) required power trial desired level. Note plug natural parameter \\(\\delta= -\\log\\nu > 0\\), \\(n.\\) returns statistical information log hazard ratio. reader may wish look derive exact relationship events statistical information \\(\\delta\\).","code":"Schoenfeld <- gsDesign(k = 2, delta = -theta, delta1 = log(hr)) Schoenfeld$n.I #> [1] 172.2757 344.5514 gsDesign(k = 2, delta = -log(hr))$n.I #> [1] 43.06893 86.13786"},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"approximating-boundary-characteristics","dir":"Articles","previous_headings":"Schoenfeld approximation support","what":"Approximating boundary characteristics","title":"Overview of survival endpoint design","text":"Another application Schoenfeld (1981) method approximate boundary characteristics design. noted introduction , consider zn2hr(), gsHR() gsBoundSummary() approximate treatment effect required cross design bounds. zn2hr() complemented functions hrn2z() hrz2n(). begin basic approximation used across functions section follow sub-section example code reproduce table . return following equation : \\[Z\\approx Z_W\\approx \\frac{\\sqrt {nr}}{1+r}\\hat\\delta=\\frac{\\ln(\\hat\\nu)\\sqrt{nr}}{1+r}.\\] fixing \\(Z=z, n\\) can solve \\(\\hat\\nu\\) : \\[\\hat{\\nu} = \\exp(z(1+r)/\\sqrt{rn}).\\] fixing \\(\\hat\\nu\\) \\(z\\), can solve corresponding number events required: \\[ n = (z(1+r)/\\log(\\hat{\\nu}))^2/r.\\]","code":""},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"examples","dir":"Articles","previous_headings":"Schoenfeld approximation support","what":"Examples","title":"Overview of survival endpoint design","text":"first example, note event counts Schoenfeld actually continuous numbers rounded table: reproduce approximate hazard ratios required cross efficacy bounds using Schoenfeld approximations : following examples, assume \\(r=1\\). Assuming Cox model estimate \\(\\hat\\nu\\) corresponding event count, approximately Z-value (p-value) correspond ? use first equation : replicate Z-value Assuming efficacy bound Z-value event count, approximately hazard ratio must observed cross bound? use second equation : can reproduce zn2hr() switching sign z ; note default ratio = 1 functions often specified: Finally, want observed hazard ratio \\(\\hat\\nu = .8\\) represent positive result, many events need observe achieve 1-sided p-value 0.025? assuming 2:1 randomization? use third equation : replicated ","code":"Schoenfeld$n.I #> [1] 172.2757 344.5514 gsHR(   z = Schoenfeld$upper$bound, # Z-values at bound   i = 1:2, # Analysis number   x = Schoenfeld, # Group sequential design from above   ratio = r # Experimental/control randomization ratio ) #> [1] 0.6576844 0.8077846 r <- 1 hr <- .73 # Observed hr events <- 125 # Events in analysis  z <- log(hr) * sqrt(events * r) / (1 + r) c(z, pnorm(z)) # Z- and p-value #> [1] -1.75928655  0.03926443 hrn2z(hr = hr, n = events, ratio = r) #> [1] -1.759287 z <- qnorm(.025) events <- 120 exp(z * (1 + r) / sqrt(r * events)) #> [1] 0.6991858 zn2hr(z = -z, n = events, ratio = r) #> [1] 0.6991858 r <- 2 hr <- .8 z <- qnorm(.025) events <- (z * (1 + r) / log(hr))^2 / r events #> [1] 347.1683 hrz2n(hr = hr, z = z, ratio = r) #> [1] 347.1683"},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"lachin-and-foulkes-design","dir":"Articles","previous_headings":"","what":"Lachin and Foulkes design","title":"Overview of survival endpoint design","text":"purpose sample size power group sequential design, Lachin Foulkes (1986) based substantial evaluation documented . try make clear strengths weaknesses Lachin Foulkes (1986) method well implementation gsDesign::nSurv() (fixed design) gsDesign::gsSurv() (group sequential) functions. historical testing purposes, also discuss use less flexible gsDesign::nSurvival() function independently programmed can used limited validations gsDesign::nSurv().","code":""},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"model-assumptions","dir":"Articles","previous_headings":"Lachin and Foulkes design","what":"Model assumptions","title":"Overview of survival endpoint design","text":"detail specification comes flexibility allowed Lachin Foulkes (1986) method. model assumes fixed enrollment period piecewise constant enrollment rates fixed minimum follow-period Piecewise exponential failure rates control group single, constant hazard ratio experimental group Piecewise exponential loss--follow-rates stratified population fixed randomization ratio experimental control group assignment proportional hazards assumption, allows great deal flexibility trial design assumptions. Lachin Foulkes (1986) adjusts piecewise constant enrollment rates proportionately derive sample size, gsDesign$nSurv() also enables approach Kim Tsiatis (1990) fixes enrollment rates extends final enrollment rate duration power trial; minimum follow-period still assumed approach. enable drop-option proposed Lachin Foulkes (1986). two practical differences Lachin Foulkes (1986) method Schoenfeld (1981) method : assuming enrollment, failure dropout rates method delivers sample size \\(N\\) well events required. variance log hazard ratio \\(\\hat\\delta\\) computed differently null (\\(\\sigma^2_0\\)) alternate hypothesis (\\(\\sigma^2_1\\)) variance incorporated formula \\[N = \\left(\\frac{\\Phi^{-1}(1-\\alpha)\\sigma_0 + \\Phi^{-1}(1-\\beta)\\sigma_1}{\\delta}\\right).\\] null hypothesis derived averaging alternate hypothesis rates, weighting according proportion randomized group.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"fixed-design","dir":"Articles","previous_headings":"Lachin and Foulkes design","what":"Fixed design","title":"Overview of survival endpoint design","text":"use hazard ratio 0.7 Schoenfeld (1981) sample size calculations . assume trial enroll constant rate 12 months, control group median 8 months (exponential failure rate \\(\\lambda = \\log(2)/8\\)), dropout rate 0.001 per month, 16 months minimum follow-. , assume randomization ratio \\(r=1\\), one-sided Type error \\(\\alpha=0.025\\), 90% power equivalent Type II error \\(\\beta=0.1\\). Recall Schoenfeld (1981) method recommended 331 events. two methods tend yield similar event count recommendations, . methods also differ slightly; see Lachin Foulkes (1986). Sample size recommendations can vary methods. can get result nSurvival() routine since single enrollment, failure dropout rate proposed example.","code":"r <- 1 # Experimental/control randomization ratio alpha <- 0.025 # 1-sided Type I error beta <- 0.1 # Type II error (1 - power) hr <- 0.7 # Hazard ratio (experimental / control) controlMedian <- 8 dropoutRate <- 0.001 # Exponential dropout rate per time unit enrollDuration <- 12 minfup <- 16 # Minimum follow-up Nlf <- nSurv(   lambdaC = log(2) / controlMedian,   hr = hr,   eta = dropoutRate,   T = enrollDuration + minfup, # Trial duration   minfup = minfup,   ratio = r,   alpha = alpha,   beta = beta ) cat(paste(\"Sample size: \", ceiling(Nlf$n), \"Events: \", ceiling(Nlf$d), \"\\n\")) #> Sample size:  422 Events:  330 lambda1 <- log(2) / controlMedian nSurvival(   lambda1 = lambda1,   lambda2 = lambda1 * hr,   Ts = enrollDuration + minfup,   Tr = enrollDuration,   eta = dropoutRate,   ratio = r,   alpha = alpha,   beta = beta ) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Study duration (fixed):          Ts=28 #> Accrual duration (fixed):        Tr=12 #> Uniform accrual:              entry=\"unif\" #> Control median:      log(2)/lambda1=8 #> Experimental median: log(2)/lambda2=11.4 #> Censoring median:        log(2)/eta=693.1 #> Control failure rate:       lambda1=0.087 #> Experimental failure rate:  lambda2=0.061 #> Censoring rate:                 eta=0.001 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1 #> Sample size based on hazard ratio=0.7 (type=\"rr\") #> Sample size (computed):           n=422 #> Events required (computed): nEvents=330"},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"group-sequential-design-1","dir":"Articles","previous_headings":"Lachin and Foulkes design","what":"Group sequential design","title":"Overview of survival endpoint design","text":"Although use Schoenfeld (1981) sample size, still used approximate HR bound calculation :","code":"k <- 2 # Total number of analyses lfgs <- gsSurv(   k = 2,   lambdaC = log(2) / controlMedian,   hr = hr,   eta = dropoutRate,   T = enrollDuration + minfup, # Trial duration   minfup = minfup,   ratio = r,   alpha = alpha,   beta = beta ) lfgs %>%   gsBoundSummary() %>%   kable(row.names = FALSE) events <- lfgs$n.I z <- lfgs$upper$bound zn2hr(z = z, n = events) # Schoenfeld approximation to HR #> [1] 0.6571386 0.8074431"},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"plotting","dir":"Articles","previous_headings":"Lachin and Foulkes design","what":"Plotting","title":"Overview of survival endpoint design","text":"various plots available. approximate hazard ratios required cross bounds use Schoenfeld (1981) approximation. ggplot2 version plot, use default base = FALSE.","code":"plot(lfgs, pl = \"hr\", dgt = 4, base = TRUE)"},{"path":"https://keaven.github.io/gsDesign/articles/SurvivalOverview.html","id":"event-accrual","dir":"Articles","previous_headings":"Lachin and Foulkes design","what":"Event accrual","title":"Overview of survival endpoint design","text":"variance calculations Lachin Foulkes method mostly determined expected event accrual null alternate hypotheses. null hypothesis characterized seemingly designed event accrual similar hypothesis. can see expected events accrued analysis alternate hypothesis : worth noting events accrue rate null alternate hypothesis, expected duration time achieve targeted events shortened. Keep mind can many reasons events accrue different rate design plan. expected event accrual events time design can computed follows:  hand, want know expected time accrue 25% final events expected enrollment accrual time, compute using: expected accrual events without design returned gsDesign::gsSurv(), see help file gsDesign::eEvents().","code":"tibble::tibble(   Analysis = 1:2,   `Control events` = lfgs$eDC,   `Experimental events` = lfgs$eDE ) %>%   kable() Month <- seq(0.025, enrollDuration + minfup, .025) plot(   c(0, Month),   c(0, sapply(Month, function(x) {     nEventsIA(tIA = x, x = lfgs)   })),   type = \"l\", xlab = \"Month\", ylab = \"Expected events\",   main = \"Expected event accrual over time\" ) b <- tEventsIA(x = lfgs, timing = 0.25) cat(paste(   \" Time: \", b$T,   \"\\n Expected enrollment:\", b$eNC + b$eNE,   \"\\n Expected control events:\", b$eDC,   \"\\n Expected experimental events:\", b$eDE, \"\\n\" )) #>  Time:  8.88072854965729  #>  Expected enrollment: 325.066468979827  #>  Expected control events: 49.0303966242417  #>  Expected experimental events: 36.7672374839294"},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Vaccine efficacy trial design","text":"article explores method approximating design using exact binomial method Chan Bohidar (1998) time--event design using method Lachin Foulkes (1986). allows use spending functions derive boundaries exact method. time--event design can used set boundaries Chan Bohidar (1998) method, allow specification enrollment duration study duration determine enrollment rates sample size required. vignette also illustrates concept super-superiority often used prevention studies.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"parameterization","dir":"Articles","previous_headings":"","what":"Parameterization","title":"Vaccine efficacy trial design","text":"begin assumption require large sample size due endpoint small incidence rate. apply vaccine study prevention study relatively small number events expected.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"exact-binomial-approach","dir":"Articles","previous_headings":"Parameterization","what":"Exact binomial approach","title":"Vaccine efficacy trial design","text":"Paralleling notation Chan Bohidar (1998), assume \\(N_C, P_C\\) binomial sample size probability event participant assigned control; experimental treatment group, labelled \\(N_E, P_E\\). Vaccine efficacy defined \\[\\pi = 1 - P_E/P_C.\\] parameter \\(\\pi\\) often labelled \\(VE\\) vaccine efficacy. Taking account randomization ratio \\(r\\) (experimental / control) approximate probability given event experimental group \\[ \\begin{aligned} p &= rP_E/(rP_E+ P_C)\\\\   &= r/(r + P_C/P_E)\\\\   &= r/(r + (1-\\pi)^{-1}). \\end{aligned} \\] can inverted obtain \\[\\pi = 1 - \\frac{1}{r(1/p-1)}. \\] example interest, begin alternate hypothesis vaccine efficacy \\(\\pi_1 = 0.7\\) experimental:control randomization ratio \\(r=3\\). converts alternate hypothesis (approximate) probability event experimental group use inversion formula revert \\(\\pi_1 = 0.7\\) Letting null hypothesis vaccine efficacy \\(\\pi_0 = 0.3\\), exact binomial null hypothesis probability event experimental group also translate several vaccine efficacy values proportion events experimental group: Chapter 12 Jennison Turnbull (2000) walks design analyze study using fixed group sequential design. may advantages disadvantages compared proposed . However, time--event approximation gives proposed bounds, also sample size study duration approximations.","code":"pi1 <- .7 ratio <- 3 p1 <- ratio / (ratio + 1 / (1 - pi1)) p1 #> [1] 0.4736842 1 - 1 / (ratio * (1 / p1 - 1)) #> [1] 0.7 pi0 <- .3 p0 <- ratio / (ratio + 1 / (1 - pi0)) p0 #> [1] 0.6774194 ve <- c(.5, .6, .65, .7, .75, .8) prob_experimental <- ratio / (ratio + 1 / (1 - ve)) tibble(VE = ve, \"P(Experimental)\" = prob_experimental) %>%   gt() %>%   tab_options(data_row.padding = px(1)) %>%   fmt_number(columns = 2, decimals = 3)"},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"the-time-to-event-approach","dir":"Articles","previous_headings":"","what":"The time-to-event approach","title":"Vaccine efficacy trial design","text":"time--event formulation exponential failure rates \\(\\lambda_C\\) control \\(\\lambda_E\\) experimental group assigned participants, define \\[\\pi = 1 - \\lambda_E / \\lambda_C\\] 1 minus hazard ratio often used time--event studies. following examine closely time--event method using asymptotic distributional assumptions can approximate appropriate exact binomial design. also define planned number events \\(K\\) planned analyses \\(D_k, 1\\le k\\le K\\).","code":""},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"generating-a-design","dir":"Articles","previous_headings":"","what":"Generating a design","title":"Vaccine efficacy trial design","text":"begin specifying parameters. alpha beta parameters met exactly due discrete group sequential probability calculations performed. Thus, may need adjust parameters slightly ensure final design operating characteristics within targeted range. current version includes designs use non-binding futility bounds futility bounds. design generated first using asymptotic theory time--event design specified spending functions. design adapted design using exact binomial method Chan Bohidar (1998). randomization ratio (experimental/control) assumed 3:1 Logunov et al. (2021) trial.","code":"alpha <- 0.023 # Type I error; this was adjusted from .025 to ensure Type I error control beta <- 0.09 # Type II error (1 - power); this was reduced from .1 to .09 to ensure power k <- 3 # number of analyses in group sequential design timing <- c(.45, .7) # Relative timing of interim analyses compared to final sfu <- sfHSD # Efficacy bound spending function (Hwang-Shih-DeCani) sfupar <- -4 # Parameter for efficacy spending function sfl <- sfLDOF # Futility bound spending function (O'Brien-Fleming-like here) sflpar <- 1 # Futility bound spending function parameter; this is the standard O'Brien-Fleming timename <- \"Month\" # Time unit failRate <- .002 # Exponential failure rate dropoutRate <- .0001 # Exponential dropout rate enrollDuration <- 8 # Enrollment duration trialDuration <- 24 # Planned trial duration VE1 <- .7 # Alternate hypothesis vaccine efficacy VE0 <- .3 # Null hypothesis vaccine efficacy ratio <- 3 # Experimental/Control enrollment ratio test.type <- 4 # 1 for one-sided, 4 for non-binding futility"},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"the-time-to-event-design","dir":"Articles","previous_headings":"Generating a design","what":"The time-to-event design","title":"Vaccine efficacy trial design","text":"Now generate design. resulting alpha beta satisfy requirements, adjust parameters satisfactory result obtained. Now convert design integer event counts analyses. achieved rounding interim analysis event counts design rounding final analysis event count. result slight change event fractions interim analyses well slight change targeted 90% power. now explain rationale behind spending function choices. Recall hazard ratio (HR) 1 minus VE. ~HR bound represents approximate hazard ratio required cross bound. Thus, small HR’s interim analyses along small cumulative efficacy spending suggest crossing interim efficacy bound provide result strong enough potentially justify new treatment. hazard ratio ~0.7 (VE ~ 0.3) interim 1 futility bound mean efficacy trend better null hypothesis futility bound crossed. second analysis futility bound approximate VE 0.5 worth discussion data monitoring committee well planners trial; custom spending function used set first second interim bounds desired levels. textual summary design : Asymmetric two-sided group sequential design non-binding futility bound, 3 analyses, time--event outcome sample size 3832 72 events required, 91 percent power, 2.3 percent (1-sided) Type error detect hazard ratio 0.3 null hypothesis hazard ratio 0.7. Enrollment total study durations assumed 8 24.1 months, respectively. Efficacy bounds derived using Hwang-Shih-DeCani spending function gamma = -4. Futility bounds derived using Lan-DeMets O’Brien-Fleming approximation spending function none = 1.","code":"# Derive Group Sequential Design # This determines final sample size x <- gsSurv(   k = k, test.type = test.type, alpha = alpha, beta = beta, timing = timing,   sfu = sfu, sfupar = sfupar, sfl = sfl, sflpar = sflpar,   lambdaC = failRate, eta = dropoutRate,   # Translate vaccine efficacy to HR   hr = 1 - VE1, hr0 = 1 - VE0,   R = enrollDuration, T = trialDuration,   minfup = trialDuration - enrollDuration, ratio = ratio ) xx <- toInteger(x) gsBoundSummary(xx,   tdigits = 1, logdelta = TRUE, deltaname = \"HR\", Nname = \"Events\",   exclude = c(\"B-value\", \"CP\", \"CP H1\", \"PP\") ) %>%   gt() %>%   tab_header(     title = \"Initial group sequential approximation\",     subtitle = \"Integer event counts at analyses\"   ) %>%   tab_options(data_row.padding = px(1)) cat(summary(xx, timeunit = \"months\"))"},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"converting-to-an-exact-binomial-design","dir":"Articles","previous_headings":"","what":"Converting to an exact binomial design","title":"Vaccine efficacy trial design","text":"now convert exact binomial design. bound counts described initial table displayed. N total event count, maximum number events experimental group cross efficacy bound. example, 13 fewer 32 events interim 1 experimental group efficacy bound crossed. futility bound b; first interim, 22 32 total events experimental group futility bound crossed alternate hypothesis rejected. second third tables give probabilities crossing upper (futility) lower (efficacy) bounds null (Theta = 0.6774) alternate (Theta` = 0.4737) hypotheses, respectively; calculations done exact binomial distribution assumptions. Total Type error 0.0187 (third table, next last row) targeted 0.025. Total power 0.9145 (third table, last row) targeted 90%.","code":"xb <- toBinomialExact(x)"},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"combined-summary-table","dir":"Articles","previous_headings":"Converting to an exact binomial design","what":"Combined summary table","title":"Vaccine efficacy trial design","text":"Next, look \\(\\alpha\\)- \\(\\beta\\)-spending time--event design compare exact bound restricted discrete possible counts bounds. \\(\\alpha\\)- \\(\\beta\\)-spending, exact binomial design spending analysis allowed spending function.","code":"# Function to print summary table for VE design veTable <- function(xbDesign, tteDesign, ve) {   # Analysis, N, Time, Total Cases, Success(Cases, VE, VE lower CI, Spend), Futility (Cases, VE, Spend), Type I Error, Power table   ratio <- tteDesign$ratio   prob_experimental <- ratio / (ratio + 1 / (1 - ve))   power_table <- gsBinomialExact(     k = xbDesign$k, theta = prob_experimental,     n.I = xbDesign$n.I, a = xbDesign$lower$bound,     b = xbDesign$upper$bound   )$lower$prob   # Cumulative sum within rows   power_table <- apply(power_table, 2, cumsum)   colnames(power_table) <- paste(ve * 100, \"%\", sep = \"\")   out_tab <- tibble(     Analysis = 1:tteDesign$k,     Time = tteDesign$T,     N = as.vector(round(tteDesign$eNC + tteDesign$eNE)),     Cases = xbDesign$n.I,     Success = xb$lower$bound,     Futility = xb$upper$bound,     ve_efficacy = 1 - 1 / (ratio * (xbDesign$n.I / xbDesign$lower$bound - 1)), # Efficacy bound     ve_futility = 1 - 1 / (ratio * (xbDesign$n.I / xbDesign$upper$bound - 1)), # Futility bound     alpha = as.vector(cumsum(       gsBinomialExact(         k = k, theta = xbDesign$theta[1], n.I = xbDesign$n.I,         a = xbDesign$lower$bound, b = xbDesign$n.I + 1       )$lower$prob     )),     beta = as.vector(cumsum(xbDesign$upper$prob[, 2]))   )   out_tab <- cbind(out_tab, power_table) } veTable(xb, x, ve) %>%   gt() %>%   fmt_number(columns = 2, decimals = 1) %>%   fmt_number(columns = c(7:8, 11:16), decimals = 2) %>%   fmt_number(columns = 9:10, decimals = 4) %>%   tab_spanner(label = \"Experimental Cases at Bound\", columns = 5:6, id = \"cases\") %>%   tab_spanner(label = \"Power by Vaccine Efficacy\", columns = 11:16, id = \"power\") %>%   tab_spanner(label = \"Error Spending\", columns = 9:10, id = \"spend\") %>%   tab_spanner(label = \"Vaccine Efficacy at Bound\", columns = 7:8, id = \"vebound\") %>%   cols_label(     ve_efficacy = \"Efficacy\",     ve_futility = \"Futility\"   ) %>%   tab_footnote(     footnote = \"Cumulative spending at each analysis\",     locations = cells_column_spanners(spanners = \"spend\")   ) %>%   tab_footnote(     footnote = \"Experimental case counts to cross between success and futility counts do not stop trial\",     locations = cells_column_spanners(spanners = \"cases\")   ) %>%   tab_footnote(     footnote = \"Exact vaccine efficacy required to cross bound\",     locations = cells_column_spanners(spanners = \"vebound\")   ) %>%   tab_footnote(     footnote = \"Cumulative power at each analysis by underlying vaccine efficacy\",     locations = cells_column_spanners(spanners = \"power\")   ) %>%   tab_footnote(     footnote = \"Efficacy spending ignores non-binding futility bound\",     location = cells_column_labels(columns = alpha)   ) %>%   tab_header(\"Design Bounds and Operating Characteristics\") # Cumulative beta-spending at lower bounds cumsum(xx$lower$spend) # Asymptotic design #> [1] 0.01098749 0.04190350 0.09000000 # Cumulative alpha-spending at efficacy bounds cumsum(gsProbability(k = xx$k, n.I = xx$n.I, a = rep(-20, xx$k), b = xx$upper$bound, theta = 0)$upper$prob) #> [1] 0.002109848 0.006472510 0.023000001"},{"path":"https://keaven.github.io/gsDesign/articles/VaccineEfficacy.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Vaccine efficacy trial design","text":"provided extended example show Chan Bohidar (1998) exact binomial using spending function bounds can derived two-step process delivers sample size bounds 1) deriving related time--event design using asymptotic methods 2) converting exact binomial design. Adjustments made target Type Type II error probabilities asymptotic approximation ensure exact binomial Type Type II error rates achieved. method seems reasonable straightforward approach develop complete design.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/binomialSPRTExample.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Binomial SPRT","text":"sequential probability ratio test (SPRT) proposed Wald (1947), Wald Wolfowitz (1948). way continuous sampling establish raise concerns product quality. wide literature topic attempt summarize . clinical trials, SPRT single arm binary endpoint can useful raise alleviate concerns short-term endpoint occurrence important safety endpoint , efficacy, response rate. function binomialSPRT() implements single arm version SPRT binary outcome. comparative SPRT tests also available comparing multiple arms, cover . may think sequential design trial obligates evaluation every observation. alternative view can analyze whenever want worry whether Type error controlled.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/binomialSPRTExample.html","id":"response-rate-example","dir":"Articles","previous_headings":"","what":"Response rate example","title":"Binomial SPRT","text":"Consider single arm historical data suggesting positive response treatment occurs 10% patients currently available treatments. Assume interest trial well-powered detect response rate 35% new treatment. SPRT defined continuous testing procedure without maximum sample size. Practically speaking, implemented minimum maximum sample size. example assume minimum sample size 10 maximum sample size 25. initially set one-sided Type error \\(\\alpha=0.08\\) power 80% (\\(1-\\beta = 0.2\\)):  plot tests first 10 patients. 4/10 responded, can reject null hypothesis 10% response rate. 0 1 10 responded, can conclude targeted 35% response rate realistic. Note number responses required cross bound step function due discrete nature problem. see maximum sample size 25: 4 fewer patients responded accept null hypothesis 10% event rate. 7 patients responded reject null hypothesis favor larger response rate. 5 6 patients respond indeterminate result can reject neither null hypothesis 10% response rate alternate hypothesis 35% response rate.","code":"library(gsDesign) b <- binomialSPRT(p0 = .1, p1 = .35, alpha = .08, beta = .2, minn = 10, maxn = 25) plot(b)"},{"path":"https://keaven.github.io/gsDesign/articles/binomialSPRTExample.html","id":"summarizing-design-properties","dir":"Articles","previous_headings":"","what":"Summarizing design properties","title":"Binomial SPRT","text":"Functions available summarize design properties. example, can make power plot:  Probability three possible outcomes summarized underlying response rate: Solid line: indeterminate outcome (bound crossed 10 25 patients). Note probabilities small, even response rates half-way null alternative hypotheses. Short-dashed line: reject H0. targeted 10% Type error rate, can see since truncated design analyze 10 25 patient Type error less 5%; targeted 1-sided \\(\\alpha=0.08.\\) Long-dashed line: Reject H1. can see > 90% chance rejecting 35% response rate true response rate 10%. now provide summary table operating characteristics. user can ignore reviewing code, may copy wishing produce similar table.","code":"library(ggplot2) p <- plot(b, plottype = 2) p + scale_y_continuous(breaks = seq(0, 90, 10)) library(dplyr) library(tidyr) # Compute boundary crossing probabilities for selected response rates b_power <- gsBinomialExact(   k = length(b$n.I), theta = seq(.1, .45, .05), n.I = b$n.I,   a = b$lower$bound, b = b$upper$bound ) b_power %>%   as_table() %>%   as_gt()"},{"path":"https://keaven.github.io/gsDesign/articles/binomialSPRTExample.html","id":"safety-monitoring-example","dir":"Articles","previous_headings":"","what":"Safety monitoring example","title":"Binomial SPRT","text":"Next consider safety monitoring example. Suppose new treatment mechanism action potential elevated rate specific adverse experience (AE); e.g., serious rash. Suppose already occurs low frequency population proposed study rate 4% 10% rate considered unacceptable. comparison two arms considered SPRT, demonstrate monitoring bound experimental arm . assume proposed sample size study 75 per arm stop trial serious rash 4 patients studied experimental group.  see serious rashes first 25 experimental group patients 1 first 40 reject 10% rate concern. hand, first 4 first 4 14 patients serious rashes 5 first 15 29 patients serious rashes can reject hypothesis elevation presumed 4% population rate. design operating characteristics now summarized plot table.  see can fairly high possibility indeterminate outcome end trial. include extreme values summary table, can see indeterminate probability lowers outside range 0.04 0.10. average sample size also goes ; however, account enrollment may occur included analysis due inadequate follow-assess endpoint. Note sequential patients analyzed, cross high rate bound incomplete data included safe can still declare crossed high rate bound number adverse experience cases go missing cases filled .","code":"safety_design <- binomialSPRT(p0 = .04, p1 = .1, alpha = .04, beta = .2, minn = 4, maxn = 75) plot(safety_design) plot(safety_design, plottype = 2) safety_power <- gsBinomialExact(   k = length(safety_design$n.I),   theta = seq(.02, .16, .02),   n.I = safety_design$n.I,   a = safety_design$lower$bound,   b = safety_design$upper$bound ) safety_power %>%   as_table() %>%   as_gt(     theta_label = gt::html(\"Underlying<br>AE rate\"),     prob_decimals = 3,     bound_label = c(\"low rate\", \"high rate\")   )"},{"path":"https://keaven.github.io/gsDesign/articles/binomialSPRTExample.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Binomial SPRT","text":"shown : derive bounds truncated sequential probability ratio test (SPRT), plot bounds design, plot operating characteristics design, print table summarizing design. noted observed power Type error lower specified Type error power can higher. means user needs consider inputs iterative basis control operating characteristics truncated SPRT. design can use responses failures. instance, can provide method early monitoring excessive risk key adverse events study.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Basic time-to-event group sequential design using gsSurv","text":"article/vignette provides basic time--event endpoint designs fixed designs using nSurv() group sequential designs using gsSurv(). detail specification comes flexibility allowed Lachin Foulkes (1986) method sample size proportional hazards model piecewise constant enrollment, piecewise exponential failure dropout rates. Users may also interested Shiny interface learning tool. use simplest options single stratum exponential failure dropout rates; see help file gsSurv() examples stratified population piecewise exponential failure. apply Lachin Foulkes (1986) sample size method extend group sequential design. method fixes duration study varies enrollment rates power trial. also use Lachin Foulkes (1986) basic power calculation compute sample size along lines Kim Tsiatis (1990) enrollment rates fixed enrollment duration allowed vary enroll sufficient sample size power study.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"fixed-design-derivation","dir":"Articles","previous_headings":"","what":"Fixed design derivation","title":"Basic time-to-event group sequential design using gsSurv","text":"Since parameters used design interim also used group sequential design, first specify derive design interim analysis.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"outcome-and-dropout-distributions","dir":"Articles","previous_headings":"Fixed design derivation","what":"Outcome and dropout distributions","title":"Basic time-to-event group sequential design using gsSurv","text":"begin information median time--event control group, dropout rate, hazard ratios null alternate hypotheses experimental therapy compared control, desired Type II error rates.","code":"# Median control time-to-event median <- 12 # Exponential dropout rate per unit of time eta <- .001 # Hypothesized experimental/control hazard ratio # (alternate hypothesis) hr <- .75 # Null hazard ratio (1 for superiority, >1 for non-inferiority) hr0 <- 1 # Type I error (1-sided) alpha <- .025 # Type II error (1-power) beta <- .1"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"enrollment-and-trial-duration","dir":"Articles","previous_headings":"Fixed design derivation","what":"Enrollment and trial duration","title":"Basic time-to-event group sequential design using gsSurv","text":"Next, plan trial duration enrollment pattern. two basic methods . Lachin Foulkes (1986) method demonstrated fixes enrollment pattern duration well trial duration changes absolute enrollment rates obtain desired power. alternate recommended method along lines Kim Tsiatis (1990), fixing enrollment rates follow-duration, varying total trial duration power design; also demonstrated .","code":"# Study duration T <- 36 # Follow-up duration of last patient enrolled minfup <- 12 # Enrollment period durations R <- c(1, 2, 3, 4) # Relative enrollment rates during above periods gamma <- c(1, 1.5, 2.5, 4) # Randomization ratio, experimental/control ratio <- 1"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"deriving-design-with-no-interim-analyses","dir":"Articles","previous_headings":"Fixed design derivation","what":"Deriving design with no interim analyses","title":"Basic time-to-event group sequential design using gsSurv","text":"information sufficient design trial interim analyses. Note calling nSurv(), transform median time--event (\\(m\\)) exponential event rate (\\(\\lambda\\)) formula \\[\\lambda=\\log(2)/m.\\] textual summary design given printing . group sequential design shown later, much complete formatted output shown.","code":"library(gsDesign)  x <- nSurv(   R = R,   gamma = gamma,   eta = eta,   minfup = minfup,   T = T,   lambdaC = log(2) / median,   hr = hr,   hr0 = hr0,   beta = beta,   alpha = alpha ) x #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Accrual rate  #> Hazard ratio                  H1/H0=0.75/1 #> Study duration:                   T=36 #> Accrual duration:                   24 #> Min. end-of-study follow-up: minfup=12 #> Expected events (total, H1):        507.1519 #> Expected sample size (total):       775.0306 #> Accrual rates: #>      Stratum 1 #> 0-1     9.2818 #> 1-3    13.9227 #> 3-6    23.2045 #> 6-24   37.1272 #> Control event rates (H1): #>       Stratum 1 #> 0-Inf    0.0578 #> Censoring rates: #>       Stratum 1 #> 0-Inf     0.001 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"varying-enrollment-duration-to-power-trial","dir":"Articles","previous_headings":"Fixed design derivation","what":"Varying enrollment duration to power trial","title":"Basic time-to-event group sequential design using gsSurv","text":"set T = NULL , specified enrollment rates changed enrollment duration adjusted achieve desired power. low enrollment rates specified gamma , resulted long trial.","code":"# THIS CODE IS EXAMPLE ONLY; NOT EXECUTED HERE nSurv(   R = R,   gamma = gamma,   eta = eta,   minfup = minfup,   T = NULL, # This was changed   lambdaC = log(2) / median,   hr = hr,   hr0 = hr0,   beta = beta,   alpha = alpha )"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"group-sequential-design","dir":"Articles","previous_headings":"","what":"Group sequential design","title":"Basic time-to-event group sequential design using gsSurv","text":"Now move group sequential design.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"additional-parameters","dir":"Articles","previous_headings":"Group sequential design","what":"Additional parameters","title":"Basic time-to-event group sequential design using gsSurv","text":"parameters used. set number analyses, timing spending function parameters. deserve careful attention every trial tend somewhat customized fit--purpose according involved designing trial. choices considered following: desire stop early lack positive trend earlier interim might soon stop meaningful safety problem desire stop efficacy, extreme effect size p-value required cross bound considered appropriate data relatively mature, meaningful length time planned final analysis treatment effect efficacy bound likely least treatment effect used power trial Lan-DeMets spending function approximating O’Brien-Fleming bound Lan DeMets (1983) often acceptable regulators early stopping Type II error (1-power) may set differently fixed design meaningful futility analyses can performed course trial.","code":"# Number of analyses (interim + final) k <- 3 # Timing of interim analyses (k-1 increasing numbers >0 and <1). # Proportion of final events at each interim. timing <- c(.25, .75) # Efficacy bound spending function. # We use Lan-DeMets spending function approximating O'Brien-Fleming bound. # No parameter required for this spending function. sfu <- sfLDOF sfupar <- NULL # Futility bound spending function sfl <- sfHSD # Futility bound spending parameter specification sflpar <- -7 # Type II error = 1 - Power beta <- .15"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"generating-the-design","dir":"Articles","previous_headings":"Group sequential design","what":"Generating the design","title":"Basic time-to-event group sequential design using gsSurv","text":"Now prepared generate design.","code":"# Generate design x <- gsSurv(   k = k, timing = timing, R = R, gamma = gamma, eta = eta,   minfup = minfup, T = T, lambdaC = log(2) / median,   hr = hr, hr0 = hr0, beta = beta, alpha = alpha,   sfu = sfu, sfupar = sfupar, sfl = sfl, sflpar = sflpar )"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"textual-summary","dir":"Articles","previous_headings":"Group sequential design","what":"Textual summary","title":"Basic time-to-event group sequential design using gsSurv","text":"design summary : Asymmetric two-sided group sequential design non-binding futility bound, 3 analyses, time--event outcome sample size 676 443 events required, 85 percent power, 2.5 percent (1-sided) Type error detect hazard ratio 0.75. Enrollment total study durations assumed 24 36 months, respectively. Efficacy bounds derived using Lan-DeMets O’Brien-Fleming approximation spending function none = 1. Futility bounds derived using Hwang-Shih-DeCani spending function gamma = -7. important addition provided median time--event assumed 12 months control group.","code":"cat(summary(x))"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"tabular-summaries","dir":"Articles","previous_headings":"Group sequential design","what":"Tabular summaries","title":"Basic time-to-event group sequential design using gsSurv","text":"Following enrollment rates required power trial. Next provide tabular summary bounds design. added extensive footnoting table, may may required design. However, seen makes many choices design parameters properties transparent. attempt made automate , may worth considering template wish make choice across many trials. Note exclude argument gsBoundSummary() allows additional descriptions design bounds conditional predictive power; see help file details just provide exclude = NULL gsBoundSummary() see options.","code":"library(gt) library(tibble)  tibble(   Period = paste(\"Month\", rownames(x$gamma)),   Rate = as.numeric(x$gamma) ) %>%   gt() %>%   tab_header(title = \"Enrollment rate requirements\") # Footnote text for table footnote1 <- \"P{Cross} is the probability of crossing the given bound (efficacy or futility) at or before the given analysis under the assumed hazard ratio (HR).\" footnote2 <- \" Design assumes futility bound is discretionary (non-binding); upper boundary crossing probabilities shown here assume trial stops at first boundary crossed and thus total less than the design Type I error.\" footnoteHR <- \"HR presented is not a requirement, but an estimate of approximately what HR would be required to cross each bound.\" footnoteM <- \"Month is approximated given enrollment and event rate assumptions under alternate hypothesis.\"  # Spending function footnotes footnoteUS <- \"Efficacy bound set using Lan-DeMets spending function approximating an O'Brien-Fleming bound.\" footnoteLS <- paste(   \"Futility bound set using \", x$lower$name, \" beta-spending function with \",   x$lower$parname, \"=\", x$lower$param, \".\",   sep = \"\" )  # Caption text for table caption <- paste(   \"Overall survival trial design with HR=\", hr, \", \",   100 * (1 - beta), \"% power and \",   100 * alpha, \"% Type I error\",   sep = \"\" ) gsBoundSummary(x) %>%   gt() %>%   tab_header(title = \"Time-to-event group sequential design\") %>%   cols_align(\"left\") %>%   tab_footnote(footnoteUS, locations = cells_column_labels(columns = 3)) %>%   tab_footnote(footnoteLS, locations = cells_column_labels(columns = 4)) %>%   tab_footnote(footnoteHR, locations = cells_body(columns = 2, rows = c(3, 8, 13))) %>%   tab_footnote(footnoteM, locations = cells_body(columns = 1, rows = c(4, 9, 14))) %>%   tab_footnote(footnote1, locations = cells_body(columns = 2, rows = c(4, 5, 9, 10, 14, 15))) %>%   tab_footnote(footnote2, locations = cells_body(columns = 2, rows = c(4, 9, 14)))"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"summary-plots","dir":"Articles","previous_headings":"Group sequential design","what":"Summary plots","title":"Basic time-to-event group sequential design using gsSurv","text":"Several plots available summarize design; see help plot.gsDesign(); one easy way see generate checking plots code generated Shiny interface. power plot information-rich, also requires explanation; thus, demonstrate . solid black line represents trial power effect size. Power interim 1 represented black dotted line. Cumulative power interim 2 represented black dashed line. red dotted line 1 minus probability crossing futility bound percentage scale. red dashed line 1 minus cumulative probability crossing futility bound interim 2.","code":"library(ggplot2) library(scales)  plot(x, plottype = \"power\", cex = .8, xlab = \"HR\") +   scale_y_continuous(labels = scales::percent)"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"update-bounds-at-time-of-analysis","dir":"Articles","previous_headings":"","what":"Update bounds at time of analysis","title":"Basic time-to-event group sequential design using gsSurv","text":"Analyses rarely occur exactly number events planned. advantage spending function approach design bounds can updated account actual number events observed analysis. fact, analyses can added deleted noting changes timing analyses made knowledge unblinded study results. suggest tables plot may particular use. also present computation conditional predictive power. First, update actual number events interims 1 2 assume final analysis event count still originally planned: simple updates Z-values p-values design based information fraction just requires fraction final events planned, include number events treatment effect output: Now print design summary, selecting minimal calculations table provide guidance review results. wish see possible summaries bounds, change exclude = NULL . assumed futility guidance based hazard ratio interim analysis; generally case, option bounds guidance rather strict inferential interpretation.","code":"# Number of events (final is still planned number) n.I <- c(115, 364, ceiling(x$n.I[x$k])) xu <- gsDesign(   alpha = x$alpha, beta = x$beta, test.type = x$test.type,   maxn.IPlan = x$n.I[x$k], n.I = n.I,   sfu = sfu, sfupar = sfupar, sfl = sfl, sflpar = sflpar,   delta = x$delta, delta1 = x$delta1, delta0 = x$delta0 ) gsBoundSummary(   xu,   deltaname = \"HR\",   logdelta = TRUE,   Nname = \"Events\",   exclude = c(     \"Spending\", \"B-value\", \"CP\", \"CP H1\",     \"PP\", \"P(Cross) if HR=1\", \"P(Cross) if HR=0.75\"   ) ) %>%   gt() %>%   cols_align(\"left\") %>%   tab_header(     title = \"Time-to-event group sequential bound guidance\",     subtitle = \"Bounds updated based on event counts through IA2\"   ) %>%   tab_footnote(     \"Nominal p-value required to establish statistical significance.\",     locations = cells_body(columns = 3, rows = c(2, 5, 8))   ) %>%   tab_footnote(     \"Interim futility guidance based on observed HR is non-binding.\",     locations = cells_body(columns = 4, rows = c(3, 6))   ) %>%   tab_footnote(     \"HR bounds are approximations; decisions on crossing are based solely on p-values.\",     locations = cells_body(column = 2, rows = c(3, 6, 9))   )"},{"path":"https://keaven.github.io/gsDesign/articles/gsSurvBasicExamples.html","id":"evaluating-interim-results","dir":"Articles","previous_headings":"Update bounds at time of analysis","what":"Evaluating interim results","title":"Basic time-to-event group sequential design using gsSurv","text":"recommend 3 things present summarize results addition standard summaries logrank p-value, hazard ratio based Cox model, median time--event Kaplan-Meier curves treatment group. Conditional power current trend, null hypothesis treatment difference (conditional error), alternative hypothesis. Predictive power, conditional power averaged posterior distribution treatment effect. B-value plot evaluate trend test statistics towards positive conclusion. summaries, assume updated interim event counts used along interim Z-values 0.25 2 interim 1 interim 2, respectively. Conditional power interim analysis 2 computed current trend, null hypothesis (HR=1), alternate hypothesis (HR=0.75 case) follows: Predictive power incorporates uncertainty conditional power evaluation. computation assumes prior distribution treatment effect updates posterior distribution treatment effect based recent interim result. conditional probability positive finding averaged according posterior. specify normal prior standardized effect size using gsDesign::normalGrid() function. select weak prior mean half-way alternative (x$delta) null (0) hypotheses variance equivalent observing 5% (=1/20) targeted events final analysis; following shows standard deviation prior well twice mean, prior relatively weak. Now based interim 2 result, compute predictive power positive final analysis. B-value (Proschan, Lan, Wittes (2006)) Z-value multiplied square root information fraction (interim information divided final planned information. plot B-value scale, present efficacy bounds analysis black, futility guidance red, observed interim tests blue connected solid lines, dashed blue line project final result. constant treatment effect (proportional hazards time--event outcome tested logrank test) blue line behaves like observations Brownian motion linear trend (“constant drift”). comparable Z-value plot effect increasing square root number events, B-value plot trend linear event count. trend proportional logarithm underlying hazard ratio. projected final test based dashed line represents linear trend based recent B-value computed; projection used conditional power calculation current trend computed .","code":"Z <- c(0.25, 2) gsCP(   x = xu, # Updated design   i = 2, # Interim analysis 2   zi = Z[2] # Observed Z-value for testing )$upper$prob #>           [,1]     [,2]      [,3] #> [1,] 0.6599398 0.301728 0.7764629 prior <- normalGrid(   mu = x$delta / 2,   sigma = sqrt(20 / max(x$n.I)) ) cat(paste(   \" Prior mean:\", round(x$delta / 2, 3),   \"\\n Prior standard deviation\", round(sqrt(20 / x$n.fix), 3), \"\\n\" )) #>  Prior mean: 0.072  #>  Prior standard deviation 0.215 gsPP(   x = xu, # Updated design   i = 2, # Interim analysis 2   zi = Z[2], # Observed Z-value for testing   theta = prior$z, # Grid points for above prior   wgts = prior$wgts # Weights for averaging over grid ) #> [1] 0.6407376 maxx <- 450 # Max for x-axis specified by user ylim <- c(-1, 3) # User-specified y-axis limits analysis <- 2 # Current analysis specified by user # Following code should require no further changes plot(   xu,   plottype = \"B\", base = TRUE, xlim = c(0, maxx), ylim = ylim, main = \"B-value projection\",   lty = 1, col = 1:2, xlab = \"Events\" ) N <- c(0, xu$n.I[1:analysis]) B <- c(0, Z * sqrt(xu$timing[1:analysis])) points(x = N, y = B, col = 4) lines(x = N, y = B, col = 4) slope <- B[analysis + 1] / N[analysis + 1] Nvals <- c(N[analysis + 1], max(xu$n.I)) lines(   x = Nvals,   y = B[analysis + 1] + c(0, slope * (Nvals[2] - Nvals[1])),   col = 4,   lty = 2 )"},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/nNormal.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Two-sample normal sample size","text":"Limited support provided 2-sample design normally distributed random variable outcome. Users encouraged look guidance Jennison Turnbull (2000). provide tool large sample case reasonable estimate standard deviation available, reasonable sample size can computed based straightforward distribution theory outlined .","code":""},{"path":"https://keaven.github.io/gsDesign/articles/nNormal.html","id":"the-problem-considered","dir":"Articles","previous_headings":"","what":"The problem considered","title":"Two-sample normal sample size","text":"overall sample size notation used gsDesign consider standardized effect size parameter referred \\(\\theta\\) Jennison Turnbull (2000). begin 2-sample normal problem assume possibly different standard deviation treatment group. \\(j = 1, 2\\), let \\(X_{j, }\\), \\(= 1, 2, \\ldots n_j\\) represent independent identically distributed observations following normal distribution mean \\(\\mu_j\\) standard deviation \\(\\sigma_j\\). natural parameter comparing two distributions \\[\\delta = \\mu_2 - \\mu_1\\] wish test \\(\\delta > 0\\) one-sided testing scenario test superiority treatment 2 treatment 1. also consider testing, say, \\(\\delta > \\delta_0\\) non-inferiority scenario \\(\\delta_0<0\\) super superiority \\(\\delta_0>0\\). normally t-test used , large sample sizes nearly equivalent Z-test defined : \\[Z=\\frac{\\bar X_2 - \\bar X_1-\\delta_0}{\\sqrt{\\sigma^2_2/n_2 + \\sigma_1^2/n_1}}\\approx \\frac{\\bar X_2 - \\bar X_1}{\\sqrt{s^2_2/n_2 + s_1^2/n_1}}=t\\] \\(\\bar X_j\\) sample mean \\(s_j^2\\) sample variance group \\(j=1,2\\). far right hand side Welch’s t-test. examples use \\(t\\)-test show sample size computation based \\(Z\\)-test works well chosen problems.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/nNormal.html","id":"sample-size","dir":"Articles","previous_headings":"","what":"Sample size","title":"Two-sample normal sample size","text":"Thus, \\(n_2=rn/(1+r)\\), \\(n_1=n/(1+r)\\) \\(r=1\\) \\(n_1=n_2=n/2\\). Now completed needed notation, interested theory behind sample size power calculation used may skip rest section. let \\[\\sigma^2=(1+r)(\\sigma_1^2+\\sigma_2^2/r)\\] define \\[ \\theta= (\\delta -\\delta_0)/\\sigma.\\] given assumptions, \\[Z \\sim \\hbox{Normal}\\left(\\sqrt n\\theta,1\\right).\\] null hypothesis \\(\\delta=\\delta_0\\), \\(Z\\sim \\hbox{Normal}(0,1)\\). Thus, regardless \\(n\\) \\[P_0[Z\\ge \\Phi^{-1}(1-\\alpha)]=\\alpha.\\] alternate hypothesis \\(\\delta=\\delta_1\\) denote corresponding \\(\\theta_1\\). define type II error \\(\\beta\\) power \\(1-\\beta\\) \\[ \\begin{align} 1-\\beta =& P_1[Z\\ge \\Phi^{-1}(1-\\alpha)]\\\\ =& P[Z-\\sqrt n\\theta_1\\ge \\Phi^{-1}(1-\\alpha)-\\sqrt n\\theta_1]\\\\ =&\\Phi(\\Phi^{-1}(1-\\alpha)-\\sqrt n\\theta_1)). \\end{align}\\] power \\(1-\\beta\\) fixed, can invert formula compute sample size : \\[n= \\left(\\frac{\\Phi^{-1}(1-\\beta)+\\Phi^{-1}(1-\\alpha)}{\\theta_1}\\right)^2.\\] 2-sided testing, simply substitute \\(\\alpha/2\\) \\(\\alpha\\) two formulas.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/nNormal.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"Two-sample normal sample size","text":"consider two examples check formulas vs. nNormal(). confirm approximation working well simulating confirming power Type error approximations useful. Finally, provide simple group sequential design example.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/nNormal.html","id":"sample-size-1","dir":"Articles","previous_headings":"Examples","what":"Sample size","title":"Two-sample normal sample size","text":"consider example \\(\\sigma_2=1.25\\), \\(\\sigma_1=1.6\\), \\(\\delta=0.8\\) \\(\\delta_0=0\\). let sample size ratio 2 experimental group observations per control observation. compute sample size nNormal() assuming one-sided Type error \\(\\alpha=0.025\\) 90% power (\\(1-\\beta=0.9\\)). Checking using sample size formula , :","code":"r <- 2 sigma <- sqrt((1 + r) * (1.6^2 + 1.25^2 / r)) theta <- 0.8 / sigma ((qnorm(.9) + qnorm(.975)) / theta)^2 #> [1] 164.5684"},{"path":"https://keaven.github.io/gsDesign/articles/nNormal.html","id":"power","dir":"Articles","previous_headings":"Examples","what":"Power","title":"Two-sample normal sample size","text":"Now, assume let sample size 200 compute power scenario. power formula , duplicate : want plot power variety sample sizes, can input n vector:  Alternatively, fix sample size 200 plot power different treatment effect assumptions:","code":"nNormal(delta1 = 0.8, sd = 1.6, sd2 = 1.25, alpha = 0.025, n = 200, ratio = 2) #> [1] 0.9466825 pwr <- pnorm(qnorm(.975) - sqrt(200) * theta, lower.tail = FALSE) pwr #> [1] 0.9466825 n <- 100:200 pwrn <- nNormal(delta1 = 0.8, sd = 1.6, sd2 = 1.25, alpha = 0.025, n = n, ratio = 2) plot(n, pwrn, type = \"l\") delta1 <- seq(.5, 1, .025) pwrdelta1 <- nNormal(delta1 = delta1, sd = 1.6, sd2 = 1.25, alpha = 0.025, n = 200, ratio = 2) plot(delta1, pwrdelta1, type = \"l\")"},{"path":"https://keaven.github.io/gsDesign/articles/nNormal.html","id":"verification-with-simulation","dir":"Articles","previous_headings":"Examples","what":"Verification with simulation","title":"Two-sample normal sample size","text":"Rather simulate individual observations, take advantage fact \\(j=1,2\\) \\[\\bar X_j\\sim \\hbox{Normal}(\\mu_j,\\sigma_j^2/n_j)\\] \\[(n_j-1)s_j^2/\\sigma_j^2=\\sum_{=1}^{n_j} (X_{ij}-\\bar X_j)/\\sigma^2 \\sim \\chi ^2_{n_j-1}\\] independent. Thus, can simulate trial power \\(n=200\\) 1 million times t-statistic unequal variances quickly follows alternate hypothesis: standard error simulation power calculation approximately suggesting within less 0.001 actual power, suggests normal power approximation reasonable scenario.","code":"nsim <- 1000000 delta <- 0.8 sd1 <- 1.6 sd2 <- 1.25 n1 <- 67 n2 <- 133 deltahat <- rnorm(n = nsim, mean = delta, sd = sd1 / sqrt(n1)) -   rnorm(n = nsim, mean = 0, sd = sd2 / sqrt(n2)) s <- sqrt(   sd1^2 * rchisq(n = nsim, df = n1 - 1) / (n1 - 1) / n1 +     sd2^2 * rchisq(n = nsim, df = n2 - 1) / (n2 - 1) / n2 ) z <- deltahat / s mean(z >= qnorm(.975)) #> [1] 0.946474 sqrt(pwr * (1 - pwr) / nsim) #> [1] 0.0002246659"},{"path":"https://keaven.github.io/gsDesign/articles/nNormal.html","id":"group-sequential-design","dir":"Articles","previous_headings":"Examples","what":"Group sequential design","title":"Two-sample normal sample size","text":"Now derive group sequential design scenario. largely use default parameters show two methods. first, plug fixed sample size follows: textual summary design given : Asymmetric two-sided group sequential design non-binding futility bound, 2 analyses, sample size 172, 90 percent power, 2.5 percent (1-sided) Type error. Efficacy bounds derived using Hwang-Shih-DeCani spending function gamma = -4. Futility bounds derived using Hwang-Shih-DeCani spending function gamma = -2. can get answer plugging standardized effect size computed : leave reader verify properties design using simulation fixed design example.","code":"d <- gsDesign(   k = 2,   n.fix = nNormal(delta1 = 0.8, sd = 1.6, sd2 = 1.25, alpha = 0.025, beta = .1, ratio = 2),   delta1 = 0.8 ) d %>%   gsBoundSummary(deltaname = \"Mean difference\") %>%   kable(row.names = FALSE) cat(summary(d)) gsDesign(   k = 2,   delta = theta,   delta1 = 0.8 ) %>%   gsBoundSummary(deltaname = \"Mean difference\") %>%   kable(row.names = FALSE)"},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/toInteger.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Integer sample size and event counts","text":"gsDesign package originally designed continuous sample size planned rather integer-based sample size. Designs time--event outcomes also non-integer event counts times analysis. vignette documents capability convert integer sample sizes event counts. couple implications design characteristics: Information fraction output exactly input due rounding. Power output exactly input. document goes examples demonstrate calculations. new function July, 2023 toInteger() operates group sequential designs convert integer-based sample size event counts analyses. begin abbreviated example time--event endpoint design demonstrate basic concepts. follow extended example binary endpoint explain details.","code":""},{"path":"https://keaven.github.io/gsDesign/articles/toInteger.html","id":"time-to-event-endpoint-example","dir":"Articles","previous_headings":"","what":"Time-to-event endpoint example","title":"Integer sample size and event counts","text":"initial design time--event endpoint 2-arm trial integer sample size event counts. See comments code output summary() function understand inputs. can summarize textually : Asymmetric two-sided group sequential design non-binding futility bound, 3 analyses, time--event outcome sample size 726 540 events required, 90 percent power, 2.5 percent (1-sided) Type error detect hazard ratio 0.75. Enrollment total study durations assumed 12 36 months, respectively. Efficacy bounds derived using Lan-DeMets O’Brien-Fleming approximation spending function none = 1. Futility bounds derived using Hwang-Shih-DeCani spending function gamma = -2.2. now adapt design integer targeted events analysis well sample size per arm end trial. provide table summarizing bounds. Due rounding final event count, see slightly larger targeted 90% trial power last row efficacy column. now summarize sample size targeted events analyses.","code":"library(gsDesign)  x <- gsSurv(   k = 3, # Number of analyses   test.type = 4, # Asymmetric 2-sided design with non-binding futility bound   alpha = 0.025, # 1-sided Type I error   beta = 0.1, # Type II error (1 - power; 90% power)   timing = c(.25, .7), # Fraction of final planned events at interim analyses   sfu = sfLDOF, # O'Brien-Fleming-like spending for efficacy   sfl = sfHSD, # Hwang-Shih-DeCani spending for futility   sflpar = -2.2, # Futility spending parameter to customize bound   lambdaC = log(2) / 12, # 12 month median control survival   hr = 0.75, # Alternate hypothesis hazard ratio   eta = -log(.98) / 12, # 2% dropout rate per year   # Enrollment accelerates over 6 months to steady state   gamma = c(2.5, 5, 7.5, 10), # Relative enrollment rates   # Duration of relative enrollment rate   R = c(2, 2, 2, 100),   # Enrollment duration targeted to T - minfup = 12 months total   T = 36, # Trial duration   minfup = 24, # Minimum follow-up duration   ratio = 1 # Randomization ratio is 1:1 ) cat(summary(x)) # Adjust design to integer-based event counts at analyses # and even integer-based final event count xi <- toInteger(x) gsBoundSummary(xi) # Summarize design bounds ##     Analysis               Value Efficacy Futility ##    IA 1: 25%                   Z   4.3326  -0.6868 ##       N: 690         p (1-sided)   0.0000   0.7539 ##  Events: 136        ~HR at bound   0.4744   1.1255 ##    Month: 12    P(Cross) if HR=1   0.0000   0.2461 ##              P(Cross) if HR=0.75   0.0039   0.0091 ##    IA 2: 70%                   Z   2.4381   1.0548 ##       N: 726         p (1-sided)   0.0074   0.1458 ##  Events: 378        ~HR at bound   0.7782   0.8972 ##    Month: 22    P(Cross) if HR=1   0.0074   0.8580 ##              P(Cross) if HR=0.75   0.6406   0.0457 ##        Final                   Z   1.9999   1.9999 ##       N: 726         p (1-sided)   0.0228   0.0228 ##  Events: 540        ~HR at bound   0.8419   0.8419 ##    Month: 36    P(Cross) if HR=1   0.0233   0.9767 ##              P(Cross) if HR=0.75   0.9002   0.0998 # Integer event counts at analyses are integer xi$n.I ## [1] 135 378 540 # Control planned sample size at analyses # Final analysis is integer; interim analyses before enrollment completion # are continuous xi$eNC ##          [,1] ## [1,] 344.4354 ## [2,] 363.0000 ## [3,] 363.0000 # Experimental analysis planned sample size at analyses xi$eNE ##          [,1] ## [1,] 344.4354 ## [2,] 363.0000 ## [3,] 363.0000"},{"path":[]},{"path":"https://keaven.github.io/gsDesign/articles/toInteger.html","id":"fixed-sample-size","dir":"Articles","previous_headings":"Binomial endpoint designs","what":"Fixed sample size","title":"Integer sample size and event counts","text":"present simple example based comparing binomial rates interim analyses 50% 75% events. assume 2:1 experimental:control randomization ratio. Note sample size integer. replace beta argument integer sample size multiple 3 get desired 2:1 integer sample sizes per arm (432 = 144 control + 288 experimental targeted) get slightly larger thant targeted 80% power:","code":"n.fix <- nBinomial(p1 = .2, p2 = .1, alpha = .025, beta = .2, ratio = 2) n.fix ## [1] 429.8846 nBinomial(p1 = .2, p2 = .1, alpha = .025, n = 432, ratio = 2) ## [1] 0.801814"},{"path":"https://keaven.github.io/gsDesign/articles/toInteger.html","id":"sided-design","dir":"Articles","previous_headings":"Binomial endpoint designs","what":"1-sided design","title":"Integer sample size and event counts","text":"Now convert fixed sample size n.fix 1-sided group sequential design interims 50% 75% observations. , sample size analysis integer. use Lan-DeMets spending function approximating O’Brien-Fleming efficacy bound. Next convert integer sample sizes analysis. Interim sample sizes rounded nearest integer. default roundUpFinal = TRUE rounds final sample size nearest integer 1 + experimental:control randomization ratio. Thus, final sample size 441 multiple 3. Next examine efficacy bound 2 designs. differences associated slightly different timing analyses associated different sample sizes noted : differences also make difference cumulative Type error associated analysis shown . Finally, look cumulative boundary crossing probabilities alternate hypothesis design. Due rounding final sample size, integer-based design slightly higher total power specified 80% (Type II error beta = 0.2.). Interim power slightly lower integer-based design since sample size rounded nearest integer rather rounded final analysis.","code":"# 1-sided design (efficacy bound only; test.type = 1) x <- gsDesign(alpha = .025, beta = .2, n.fix = n.fix, test.type = 1, sfu = sfLDOF, timing = c(.5, .75)) # Continuous sample size (non-integer) at planned analyses x$n.I ## [1] 219.1621 328.7432 438.3243 # Convert to integer sample size with even multiple of ratio + 1 # i.e., multiple of 3 in this case at final analysis x_integer <- toInteger(x, ratio = 2) x_integer$n.I ## [1] 219 329 441 # Bound for continuous sample size design x$upper$bound ## [1] 2.962588 2.359018 2.014084 # Bound for integer sample size design x_integer$upper$bound ## [1] 2.974067 2.366106 2.012987 # Continuous design sample size fractions at analyses x$timing ## [1] 0.50 0.75 1.00 # Integer design sample size fractions at analyses x_integer$timing ## [1] 0.4965986 0.7460317 1.0000000 # Continuous sample size design cumsum(x$upper$prob[, 1]) ## [1] 0.001525323 0.009649325 0.025000000 # Specified spending based on the spending function x$upper$sf(alpha = x$alpha, t = x$timing, x$upper$param)$spend ## [1] 0.001525323 0.009649325 0.025000000 # Integer sample size design cumsum(x_integer$upper$prob[, 1]) ## [1] 0.001469404 0.009458454 0.025000000 # Specified spending based on the spending function # Slightly different from continuous design due to slightly different information fraction x$upper$sf(alpha = x_integer$alpha, t = x_integer$timing, x_integer$upper$param)$spend ## [1] 0.001469404 0.009458454 0.025000000 # Cumulative upper boundary crossing probability under alternate by analysis # under alternate hypothesis for continuous sample size cumsum(x$upper$prob[, 2]) ## [1] 0.1679704 0.5399906 0.8000000 # Same for integer sample sizes at each analysis cumsum(x_integer$upper$prob[, 2]) ## [1] 0.1649201 0.5374791 0.8025140"},{"path":"https://keaven.github.io/gsDesign/articles/toInteger.html","id":"non-binding-design","dir":"Articles","previous_headings":"Binomial endpoint designs","what":"Non-binding design","title":"Integer sample size and event counts","text":"default test.type = 4 non-binding futility bound. examine behavior design next. futility bound moderately aggressive , thus, compensatory increase sample size retain power. parameter delta1 natural parameter denoting difference response (failure) rates 0.2 vs. 0.1 specified call nBinomial() . , convert integer sample sizes analysis see slight deviations interim timing 0.5 0.75. differences also make difference Type error associated analysis Type error ignoring futility bounds just shown use full targeted 0.025 calculations assume trial stops futility interim futility bound crossed. non-binding Type error assuming trial stop futility : Finally, look cumulative lower boundary crossing probabilities alternate hypothesis integer-based design compare planned \\(\\beta\\)-spending. note final Type II error spending slightly lower targeted 0.2 due rounding final sample size. \\(\\beta\\)-spending lower 0.2 first row due final sample size powering trial greater 0.8 seen .","code":"# 2-sided asymmetric design with non-binding futility bound (test.type = 4) xnb <- gsDesign(   alpha = .025, beta = .2, n.fix = n.fix, test.type = 4,   sfu = sfLDOF, sfl = sfHSD, sflpar = -2,   timing = c(.5, .75), delta1 = .1 ) # Continuous sample size for non-binding design xnb$n.I ## [1] 231.9610 347.9415 463.9219 xnbi <- toInteger(xnb, ratio = 2) # Integer design sample size at each analysis xnbi$n.I ## [1] 232 348 465 # Information fraction based on integer sample sizes xnbi$timing ## [1] 0.4989247 0.7483871 1.0000000 # Type I error, continuous design cumsum(xnb$upper$prob[, 1]) ## [1] 0.001525323 0.009630324 0.023013764 # Type I error, integer design cumsum(xnbi$upper$prob[, 1]) ## [1] 0.001507499 0.009553042 0.022999870 # Type I error for integer design ignoring futility bound cumsum(xnbi$falseposnb) ## [1] 0.001507499 0.009571518 0.025000000 # Actual cumulative beta spent at each analysis cumsum(xnbi$lower$prob[, 2]) ## [1] 0.05360549 0.10853733 0.19921266 # Spending function target is the same at interims, but larger at final xnbi$lower$sf(alpha = xnbi$beta, t = xnbi$n.I / max(xnbi$n.I), param = xnbi$lower$param)$spend ## [1] 0.05360549 0.10853733 0.20000000 # beta-spending sum(xnbi$upper$prob[, 2]) ## [1] 0.8007874"},{"path":[]},{"path":"https://keaven.github.io/gsDesign/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Keaven Anderson. Author, maintainer.","code":""},{"path":"https://keaven.github.io/gsDesign/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Anderson K (2023). gsDesign: Group Sequential Design. https://keaven.github.io/gsDesign/, https://github.com/keaven/gsDesign.","code":"@Manual{,   title = {gsDesign: Group Sequential Design},   author = {Keaven Anderson},   year = {2023},   note = {https://keaven.github.io/gsDesign/, https://github.com/keaven/gsDesign}, }"},{"path":"https://keaven.github.io/gsDesign/index.html","id":"gsdesign-","dir":"","previous_headings":"","what":"Group Sequential Design","title":"Group Sequential Design","text":"gsDesign package supports group sequential clinical trial design, largely presented book Group Sequential Methods Applications Clinical Trials Christopher Jennison Bruce Turnbull (Chapman Hall/CRC, 2000). easy--use web interface enable usage without coding generate code able reproduce design; enhanced support features ongoing basis. See talk presented R/Pharma Conference get started web interface.","code":""},{"path":"https://keaven.github.io/gsDesign/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Group Sequential Design","text":"","code":"# The easiest way to get gsDesign is to install: install.packages(\"gsDesign\")  # Alternatively, install development version from GitHub: # install.packages(\"remotes\") remotes::install_github(\"keaven/gsDesign\")"},{"path":"https://keaven.github.io/gsDesign/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Group Sequential Design","text":"strong focus designs using α β spending functions, Wang-Tsiatis designs, including O’Brien-Fleming Pocock designs, also available. ability design non-binding futility rules allows control Type error manner acceptable regulatory authorities futility bounds employed. Particular effort gone designs time--event endpoints. routines designed provide simple access commonly used designs using default arguments. Standard, published spending functions supported well ability write custom spending functions. plot function provides wide variety plots summarizing designs: boundaries, power, estimated treatment effect boundaries, conditional power boundaries, spending function plots, expected sample size plot, B-values boundaries. main design functions, gsDesign() gsSurv() complex output, function gsBoundSummary() provides simple summary design data frame can useful printing document. Thus, intent gsDesign package easily create, fully characterize even optimize routine group sequential trial designs well provide tool evaluate innovative designs.","code":""},{"path":"https://keaven.github.io/gsDesign/index.html","id":"a-little-history","dir":"","previous_headings":"","what":"A little history","title":"Group Sequential Design","text":"Updates late 2018 early 2019 largely enabled Metrum Research Group (Devin Pastoor, Harsh Baid, Jonathan Sidi). include, limited , converting unit testing use testthat package well developing github web pages implementing covrpage document unit testing. Yilong Zhang implemented 3.1.1 continuous integration github. 2020 collaborations Cytel, Inc. increased unit testing coverage > 80% version 3.2.0 essential unit testing done long ago. Much earlier development, testing documentation help lead largely Bill Constantine Rich Calaway Revolution Computing. Thanks John Lueders excellent extensive collaboration building Shiny app; recent Shiny development done Nan Xiao adds significant features saving reloading designs creating default Rmarkdown reports.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/Spending_Function_Overview.html","id":null,"dir":"Reference","previous_headings":"","what":"4.0: Spending function overview — Spending_Function_Overview","title":"4.0: Spending function overview — Spending_Function_Overview","text":"Spending functions used set boundaries group sequential designs. Using spending function approach design offers natural way provide interim testing boundaries unplanned interim analyses added timing interim analysis changes. Many standard investigational spending functions provided gsDesign package. offer great deal flexibility setting stopping boundaries design.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/Spending_Function_Overview.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"4.0: Spending function overview — Spending_Function_Overview","text":"alpha Real value \\(> 0\\) 1. Defaults calls gsDesign() alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 , descriptive purposes, wish see proportion spending function proportion sample size/information. t vector points increasing values 0 1, inclusive. Values proportion sample size/information spending function computed. param single real value vector real values specifying spending function parameter(s); must appropriately matched spending function specified. object spendfn object summarized. ... currently used.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/Spending_Function_Overview.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"4.0: Spending function overview — Spending_Function_Overview","text":"spendingFunction spending functions general produce object type spendfn. name character string name spending function. param parameters used spending function. parname character string strings name(s) parameter(s) param. sf spending function specified. spend vector cumulative spending values corresponding input values t. bound null returned spending function, set gsDesign() spending function called .  Contains z-values bounds design. prob null returned spending function, set gsDesign() spending function called .  Contains probabilities boundary crossing -th analysis j-th theta value input gsDesign() prob[,j].","code":""},{"path":"https://keaven.github.io/gsDesign/reference/Spending_Function_Overview.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"4.0: Spending function overview — Spending_Function_Overview","text":"summary() function spendfn objects provides brief textual summary spending function boundary used design. Spending functions three arguments noted return object type spendfn. Normally spending function passed gsDesign() parameter sfu upper bound sfl lower bound specify spending function family design. case, user need know calling sequence - specify parameter(s) spending function. calling sequence useful user wishes plot spending function demonstrated examples. addition using supplied spending functions, user can write code spending function. See examples.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/Spending_Function_Overview.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"4.0: Spending function overview — Spending_Function_Overview","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/Spending_Function_Overview.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"4.0: Spending function overview — Spending_Function_Overview","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/Spending_Function_Overview.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"4.0: Spending function overview — Spending_Function_Overview","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/Spending_Function_Overview.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"4.0: Spending function overview — Spending_Function_Overview","text":"","code":"library(ggplot2) # Example 1: simple example showing what mose users need to know  # design a 4-analysis trial using a Hwang-Shih-DeCani spending function  # for both lower and upper bounds  x <- gsDesign(k=4, sfu=sfHSD, sfupar=-2, sfl=sfHSD, sflpar=1)  # print the design x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size   ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*  Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.324 0.03    0.5136 0.0350 2.80    0.0025  0.0025 #>          2  0.649 0.88    0.8096 0.0273 2.58    0.0049  0.0042 #>          3  0.973 1.51    0.9349 0.0212 2.34    0.0096  0.0069 #>          4  1.297 2.09    0.9817 0.0165 2.09    0.0183  0.0114 #>      Total                       0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Hwang-Shih-DeCani spending function with gamma = 1. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -2. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4  Total   E{N} #>   0.0000 0.0025 0.0042 0.0065 0.0072 0.0203 0.5477 #>   3.2415 0.1695 0.3553 0.2774 0.0978 0.9000 0.7533 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4  Total #>   0.0000 0.5136 0.3156 0.1169 0.0336 0.9797 #>   3.2415 0.0350 0.0273 0.0212 0.0165 0.1000 # summarize the spending functions summary(x$upper) #> [1] \"Hwang-Shih-DeCani spending function with gamma = -2\" summary(x$lower) #> [1] \"Hwang-Shih-DeCani spending function with gamma = 1\"  # plot the alpha- and beta-spending functions plot(x, plottype=5)   # what happens to summary if we used a boundary function design x <- gsDesign(test.type=2,sfu=\"OF\") y <- gsDesign(test.type=1,sfu=\"WT\",sfupar=.25) summary(x$upper) #> [1] \"O'Brien-Fleming boundary\" summary(y$upper) #> [1] \"Wang-Tsiatis boundary with Delta = 0.25\"  # Example 2: advanced example: writing a new spending function   # Most users may ignore this!  # implementation of 2-parameter version of # beta distribution spending function # assumes t and alpha are appropriately specified (does not check!)  sfbdist <- function(alpha,  t,  param) {      # check inputs    checkVector(param, \"numeric\", c(0, Inf), c(FALSE, TRUE))    if (length(param) !=2) stop(    \"b-dist example spending function parameter must be of length 2\")     # set spending using cumulative beta distribution and return    x <- list(name=\"B-dist example\", param=param, parname=c(\"a\", \"b\"),               sf=sfbdist, spend=alpha *             pbeta(t, param[1], param[2]), bound=NULL, prob=NULL)                  class(x) <- \"spendfn\"        x }  # now try it out! # plot some example beta (lower bound) spending functions using  # the beta distribution spending function  t <- 0:100/100 plot(t, sfbdist(1, t, c(2, 1))$spend, type=\"l\",      xlab=\"Proportion of information\",      ylab=\"Cumulative proportion of total spending\",      main=\"Beta distribution Spending Function Example\") lines(t, sfbdist(1, t, c(6, 4))$spend, lty=2) lines(t, sfbdist(1, t, c(.5, .5))$spend, lty=3) lines(t, sfbdist(1, t, c(.6, 2))$spend, lty=4) legend(x=c(.65, 1), y=1 * c(0, .25), lty=1:4,      legend=c(\"a=2, b=1\",\"a=6, b=4\",\"a=0.5, b=0.5\",\"a=0.6, b=2\"))"},{"path":"https://keaven.github.io/gsDesign/reference/as_gt.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a summary table using gt — as_gt","title":"Print a summary table using gt — as_gt","text":"Create print table created as_table summarize object print using gt; currently implemented gsBinomialExact.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/as_gt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a summary table using gt — as_gt","text":"","code":"as_gt(x, ...)  # S3 method for gsBinomialExactTable as_gt(   x,   title = \"Operating Characteristics for the Truncated SPRT Design\",   subtitle = \"Assumes trial evaluated sequentially after each response\",   theta_label = html(\"Underlying<br>response rate\"),   bound_label = c(\"Futility bound\", \"Efficacy bound\"),   prob_decimals = 2,   en_decimals = 1,   rr_decimals = 0,   ... )"},{"path":"https://keaven.github.io/gsDesign/reference/as_gt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a summary table using gt — as_gt","text":"x Object printed using gt. ... parameters may specific object. title Table title. subtitle Table subtitle. theta_label Label theta. bound_label Label bounds. prob_decimals Number decimal places probability crossing. en_decimals Number decimal places expected number observations bound crossed trial ends without crossing. rr_decimals Number decimal places response rates.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/as_gt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a summary table using gt — as_gt","text":"`gt` object may extended overloaded versions  as_gt.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/as_gt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print a summary table using gt — as_gt","text":"Currently implemented gsBinomialExact objects. Creates table summarize object. gsBinomialExact, summarized operating characteristics across range effect sizes.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/as_gt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a summary table using gt — as_gt","text":"","code":"safety_design <- binomialSPRT(p0 = .04, p1 = .1, alpha = .04, beta = .2, minn = 4, maxn = 75) safety_power <- gsBinomialExact(   k = length(safety_design$n.I),   theta = seq(.02, .16, .02),   n.I = safety_design$n.I,   a = safety_design$lower$bound,   b = safety_design$upper$bound ) safety_power %>%   as_table() %>%   as_gt(     theta_label = gt::html(\"Underlying<br>AE rate\"),     prob_decimals = 3,     bound_label = c(\"low rate\", \"high rate\")   ) #> <div id=\"wmfxwlvhpe\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"> #>   <style>#wmfxwlvhpe table { #>   font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; #>   -webkit-font-smoothing: antialiased; #>   -moz-osx-font-smoothing: grayscale; #> } #>  #> #wmfxwlvhpe thead, #wmfxwlvhpe tbody, #wmfxwlvhpe tfoot, #wmfxwlvhpe tr, #wmfxwlvhpe td, #wmfxwlvhpe th { #>   border-style: none; #> } #>  #> #wmfxwlvhpe p { #>   margin: 0; #>   padding: 0; #> } #>  #> #wmfxwlvhpe .gt_table { #>   display: table; #>   border-collapse: collapse; #>   line-height: normal; #>   margin-left: auto; #>   margin-right: auto; #>   color: #333333; #>   font-size: 16px; #>   font-weight: normal; #>   font-style: normal; #>   background-color: #FFFFFF; #>   width: auto; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #A8A8A8; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #A8A8A8; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_caption { #>   padding-top: 4px; #>   padding-bottom: 4px; #> } #>  #> #wmfxwlvhpe .gt_title { #>   color: #333333; #>   font-size: 125%; #>   font-weight: initial; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-color: #FFFFFF; #>   border-bottom-width: 0; #> } #>  #> #wmfxwlvhpe .gt_subtitle { #>   color: #333333; #>   font-size: 85%; #>   font-weight: initial; #>   padding-top: 3px; #>   padding-bottom: 5px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-top-color: #FFFFFF; #>   border-top-width: 0; #> } #>  #> #wmfxwlvhpe .gt_heading { #>   background-color: #FFFFFF; #>   text-align: center; #>   border-bottom-color: #FFFFFF; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_bottom_border { #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_col_headings { #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_col_heading { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: normal; #>   text-transform: inherit; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: bottom; #>   padding-top: 5px; #>   padding-bottom: 6px; #>   padding-left: 5px; #>   padding-right: 5px; #>   overflow-x: hidden; #> } #>  #> #wmfxwlvhpe .gt_column_spanner_outer { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: normal; #>   text-transform: inherit; #>   padding-top: 0; #>   padding-bottom: 0; #>   padding-left: 4px; #>   padding-right: 4px; #> } #>  #> #wmfxwlvhpe .gt_column_spanner_outer:first-child { #>   padding-left: 0; #> } #>  #> #wmfxwlvhpe .gt_column_spanner_outer:last-child { #>   padding-right: 0; #> } #>  #> #wmfxwlvhpe .gt_column_spanner { #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   vertical-align: bottom; #>   padding-top: 5px; #>   padding-bottom: 5px; #>   overflow-x: hidden; #>   display: inline-block; #>   width: 100%; #> } #>  #> #wmfxwlvhpe .gt_spanner_row { #>   border-bottom-style: hidden; #> } #>  #> #wmfxwlvhpe .gt_group_heading { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: middle; #>   text-align: left; #> } #>  #> #wmfxwlvhpe .gt_empty_group_heading { #>   padding: 0.5px; #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   vertical-align: middle; #> } #>  #> #wmfxwlvhpe .gt_from_md > :first-child { #>   margin-top: 0; #> } #>  #> #wmfxwlvhpe .gt_from_md > :last-child { #>   margin-bottom: 0; #> } #>  #> #wmfxwlvhpe .gt_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   margin: 10px; #>   border-top-style: solid; #>   border-top-width: 1px; #>   border-top-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: middle; #>   overflow-x: hidden; #> } #>  #> #wmfxwlvhpe .gt_stub { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-right-style: solid; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #wmfxwlvhpe .gt_stub_row_group { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-right-style: solid; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   padding-left: 5px; #>   padding-right: 5px; #>   vertical-align: top; #> } #>  #> #wmfxwlvhpe .gt_row_group_first td { #>   border-top-width: 2px; #> } #>  #> #wmfxwlvhpe .gt_row_group_first th { #>   border-top-width: 2px; #> } #>  #> #wmfxwlvhpe .gt_summary_row { #>   color: #333333; #>   background-color: #FFFFFF; #>   text-transform: inherit; #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #wmfxwlvhpe .gt_first_summary_row { #>   border-top-style: solid; #>   border-top-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_first_summary_row.thick { #>   border-top-width: 2px; #> } #>  #> #wmfxwlvhpe .gt_last_summary_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_grand_summary_row { #>   color: #333333; #>   background-color: #FFFFFF; #>   text-transform: inherit; #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #wmfxwlvhpe .gt_first_grand_summary_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-top-style: double; #>   border-top-width: 6px; #>   border-top-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_last_grand_summary_row_top { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-style: double; #>   border-bottom-width: 6px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_striped { #>   background-color: rgba(128, 128, 128, 0.05); #> } #>  #> #wmfxwlvhpe .gt_table_body { #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_footnotes { #>   color: #333333; #>   background-color: #FFFFFF; #>   border-bottom-style: none; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_footnote { #>   margin: 0px; #>   font-size: 90%; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #wmfxwlvhpe .gt_sourcenotes { #>   color: #333333; #>   background-color: #FFFFFF; #>   border-bottom-style: none; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #> } #>  #> #wmfxwlvhpe .gt_sourcenote { #>   font-size: 90%; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #wmfxwlvhpe .gt_left { #>   text-align: left; #> } #>  #> #wmfxwlvhpe .gt_center { #>   text-align: center; #> } #>  #> #wmfxwlvhpe .gt_right { #>   text-align: right; #>   font-variant-numeric: tabular-nums; #> } #>  #> #wmfxwlvhpe .gt_font_normal { #>   font-weight: normal; #> } #>  #> #wmfxwlvhpe .gt_font_bold { #>   font-weight: bold; #> } #>  #> #wmfxwlvhpe .gt_font_italic { #>   font-style: italic; #> } #>  #> #wmfxwlvhpe .gt_super { #>   font-size: 65%; #> } #>  #> #wmfxwlvhpe .gt_footnote_marks { #>   font-size: 75%; #>   vertical-align: 0.4em; #>   position: initial; #> } #>  #> #wmfxwlvhpe .gt_asterisk { #>   font-size: 100%; #>   vertical-align: 0; #> } #>  #> #wmfxwlvhpe .gt_indent_1 { #>   text-indent: 5px; #> } #>  #> #wmfxwlvhpe .gt_indent_2 { #>   text-indent: 10px; #> } #>  #> #wmfxwlvhpe .gt_indent_3 { #>   text-indent: 15px; #> } #>  #> #wmfxwlvhpe .gt_indent_4 { #>   text-indent: 20px; #> } #>  #> #wmfxwlvhpe .gt_indent_5 { #>   text-indent: 25px; #> } #> <\/style> #>   <table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"> #>   <thead> #>     <tr class=\"gt_heading\"> #>       <td colspan=\"4\" class=\"gt_heading gt_title gt_font_normal\" style>Operating Characteristics for the Truncated SPRT Design<\/td> #>     <\/tr> #>     <tr class=\"gt_heading\"> #>       <td colspan=\"4\" class=\"gt_heading gt_subtitle gt_font_normal gt_bottom_border\" style>Assumes trial evaluated sequentially after each response<\/td> #>     <\/tr> #>     <tr class=\"gt_col_headings gt_spanner_row\"> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"Underlying&lt;br&gt;AE rate\">Underlying<br>AE rate<\/th> #>       <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Probability of crossing\"> #>         <span class=\"gt_column_spanner\">Probability of crossing<\/span> #>       <\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"Average&lt;br&gt;sample size\">Average<br>sample size<\/th> #>     <\/tr> #>     <tr class=\"gt_col_headings\"> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"low rate\">low rate<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"high rate\">high rate<\/th> #>     <\/tr> #>   <\/thead> #>   <tbody class=\"gt_table_body\"> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">2%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.964<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.001<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">34.8<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">4%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.769<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.019<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">46.4<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">6%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.506<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.108<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">54.3<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">8%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.291<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.290<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">56.1<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">10%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.155<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.516<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">52.8<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">12%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.079<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.714<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">46.8<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">14%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.039<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.851<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">40.2<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">16%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.020<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.930<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">34.2<\/td><\/tr> #>   <\/tbody> #>    #>    #> <\/table> #> <\/div>"},{"path":"https://keaven.github.io/gsDesign/reference/as_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a summary table — as_table","title":"Create a summary table — as_table","text":"Create tibble summarize object; currently implemented gsBinomialExact.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/as_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a summary table — as_table","text":"","code":"as_table(x, ...)  # S3 method for gsBinomialExact as_table(x, ...)"},{"path":"https://keaven.github.io/gsDesign/reference/as_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a summary table — as_table","text":"x Object summarized. ... parameters may specific object.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/as_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a summary table — as_table","text":"tibble may extended class enable output processing.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/as_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a summary table — as_table","text":"Currently implemented gsBinomialExact objects. Creates table summarize object. gsBinomialExact, summarized operating characteristics across range effect sizes.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/as_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a summary table — as_table","text":"","code":"b <- binomialSPRT(p0 = .1, p1 = .35, alpha = .08, beta = .2, minn = 10, maxn = 25) b_power <- gsBinomialExact(   k = length(b$n.I), theta = seq(.1, .45, .05), n.I = b$n.I,   a = b$lower$bound, b = b$upper$bound ) b_power %>%   as_table() %>%   as_gt() #> <div id=\"xsaowjiuig\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"> #>   <style>#xsaowjiuig table { #>   font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; #>   -webkit-font-smoothing: antialiased; #>   -moz-osx-font-smoothing: grayscale; #> } #>  #> #xsaowjiuig thead, #xsaowjiuig tbody, #xsaowjiuig tfoot, #xsaowjiuig tr, #xsaowjiuig td, #xsaowjiuig th { #>   border-style: none; #> } #>  #> #xsaowjiuig p { #>   margin: 0; #>   padding: 0; #> } #>  #> #xsaowjiuig .gt_table { #>   display: table; #>   border-collapse: collapse; #>   line-height: normal; #>   margin-left: auto; #>   margin-right: auto; #>   color: #333333; #>   font-size: 16px; #>   font-weight: normal; #>   font-style: normal; #>   background-color: #FFFFFF; #>   width: auto; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #A8A8A8; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #A8A8A8; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_caption { #>   padding-top: 4px; #>   padding-bottom: 4px; #> } #>  #> #xsaowjiuig .gt_title { #>   color: #333333; #>   font-size: 125%; #>   font-weight: initial; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-color: #FFFFFF; #>   border-bottom-width: 0; #> } #>  #> #xsaowjiuig .gt_subtitle { #>   color: #333333; #>   font-size: 85%; #>   font-weight: initial; #>   padding-top: 3px; #>   padding-bottom: 5px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-top-color: #FFFFFF; #>   border-top-width: 0; #> } #>  #> #xsaowjiuig .gt_heading { #>   background-color: #FFFFFF; #>   text-align: center; #>   border-bottom-color: #FFFFFF; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_bottom_border { #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_col_headings { #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_col_heading { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: normal; #>   text-transform: inherit; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: bottom; #>   padding-top: 5px; #>   padding-bottom: 6px; #>   padding-left: 5px; #>   padding-right: 5px; #>   overflow-x: hidden; #> } #>  #> #xsaowjiuig .gt_column_spanner_outer { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: normal; #>   text-transform: inherit; #>   padding-top: 0; #>   padding-bottom: 0; #>   padding-left: 4px; #>   padding-right: 4px; #> } #>  #> #xsaowjiuig .gt_column_spanner_outer:first-child { #>   padding-left: 0; #> } #>  #> #xsaowjiuig .gt_column_spanner_outer:last-child { #>   padding-right: 0; #> } #>  #> #xsaowjiuig .gt_column_spanner { #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   vertical-align: bottom; #>   padding-top: 5px; #>   padding-bottom: 5px; #>   overflow-x: hidden; #>   display: inline-block; #>   width: 100%; #> } #>  #> #xsaowjiuig .gt_spanner_row { #>   border-bottom-style: hidden; #> } #>  #> #xsaowjiuig .gt_group_heading { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: middle; #>   text-align: left; #> } #>  #> #xsaowjiuig .gt_empty_group_heading { #>   padding: 0.5px; #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   vertical-align: middle; #> } #>  #> #xsaowjiuig .gt_from_md > :first-child { #>   margin-top: 0; #> } #>  #> #xsaowjiuig .gt_from_md > :last-child { #>   margin-bottom: 0; #> } #>  #> #xsaowjiuig .gt_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   margin: 10px; #>   border-top-style: solid; #>   border-top-width: 1px; #>   border-top-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: middle; #>   overflow-x: hidden; #> } #>  #> #xsaowjiuig .gt_stub { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-right-style: solid; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #xsaowjiuig .gt_stub_row_group { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-right-style: solid; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   padding-left: 5px; #>   padding-right: 5px; #>   vertical-align: top; #> } #>  #> #xsaowjiuig .gt_row_group_first td { #>   border-top-width: 2px; #> } #>  #> #xsaowjiuig .gt_row_group_first th { #>   border-top-width: 2px; #> } #>  #> #xsaowjiuig .gt_summary_row { #>   color: #333333; #>   background-color: #FFFFFF; #>   text-transform: inherit; #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #xsaowjiuig .gt_first_summary_row { #>   border-top-style: solid; #>   border-top-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_first_summary_row.thick { #>   border-top-width: 2px; #> } #>  #> #xsaowjiuig .gt_last_summary_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_grand_summary_row { #>   color: #333333; #>   background-color: #FFFFFF; #>   text-transform: inherit; #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #xsaowjiuig .gt_first_grand_summary_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-top-style: double; #>   border-top-width: 6px; #>   border-top-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_last_grand_summary_row_top { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-style: double; #>   border-bottom-width: 6px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_striped { #>   background-color: rgba(128, 128, 128, 0.05); #> } #>  #> #xsaowjiuig .gt_table_body { #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_footnotes { #>   color: #333333; #>   background-color: #FFFFFF; #>   border-bottom-style: none; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_footnote { #>   margin: 0px; #>   font-size: 90%; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #xsaowjiuig .gt_sourcenotes { #>   color: #333333; #>   background-color: #FFFFFF; #>   border-bottom-style: none; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #> } #>  #> #xsaowjiuig .gt_sourcenote { #>   font-size: 90%; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #xsaowjiuig .gt_left { #>   text-align: left; #> } #>  #> #xsaowjiuig .gt_center { #>   text-align: center; #> } #>  #> #xsaowjiuig .gt_right { #>   text-align: right; #>   font-variant-numeric: tabular-nums; #> } #>  #> #xsaowjiuig .gt_font_normal { #>   font-weight: normal; #> } #>  #> #xsaowjiuig .gt_font_bold { #>   font-weight: bold; #> } #>  #> #xsaowjiuig .gt_font_italic { #>   font-style: italic; #> } #>  #> #xsaowjiuig .gt_super { #>   font-size: 65%; #> } #>  #> #xsaowjiuig .gt_footnote_marks { #>   font-size: 75%; #>   vertical-align: 0.4em; #>   position: initial; #> } #>  #> #xsaowjiuig .gt_asterisk { #>   font-size: 100%; #>   vertical-align: 0; #> } #>  #> #xsaowjiuig .gt_indent_1 { #>   text-indent: 5px; #> } #>  #> #xsaowjiuig .gt_indent_2 { #>   text-indent: 10px; #> } #>  #> #xsaowjiuig .gt_indent_3 { #>   text-indent: 15px; #> } #>  #> #xsaowjiuig .gt_indent_4 { #>   text-indent: 20px; #> } #>  #> #xsaowjiuig .gt_indent_5 { #>   text-indent: 25px; #> } #> <\/style> #>   <table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\"> #>   <thead> #>     <tr class=\"gt_heading\"> #>       <td colspan=\"4\" class=\"gt_heading gt_title gt_font_normal\" style>Operating Characteristics for the Truncated SPRT Design<\/td> #>     <\/tr> #>     <tr class=\"gt_heading\"> #>       <td colspan=\"4\" class=\"gt_heading gt_subtitle gt_font_normal gt_bottom_border\" style>Assumes trial evaluated sequentially after each response<\/td> #>     <\/tr> #>     <tr class=\"gt_col_headings gt_spanner_row\"> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"Underlying&lt;br&gt;response rate\">Underlying<br>response rate<\/th> #>       <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Probability of crossing\"> #>         <span class=\"gt_column_spanner\">Probability of crossing<\/span> #>       <\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"Average&lt;br&gt;sample size\">Average<br>sample size<\/th> #>     <\/tr> #>     <tr class=\"gt_col_headings\"> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Futility bound\">Futility bound<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Efficacy bound\">Efficacy bound<\/th> #>     <\/tr> #>   <\/thead> #>   <tbody class=\"gt_table_body\"> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">10%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.94<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.04<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">12.1<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">15%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.78<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.15<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">13.6<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">20%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.57<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.32<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">14.3<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">25%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.37<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.53<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">14.2<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">30%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.22<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.71<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">13.4<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">35%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.12<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.84<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">12.5<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">40%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.06<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.92<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">11.6<\/td><\/tr> #>     <tr><td headers=\"theta\" class=\"gt_row gt_right\">45%<\/td> #> <td headers=\"Lower\" class=\"gt_row gt_right\">0.03<\/td> #> <td headers=\"Upper\" class=\"gt_row gt_right\">0.97<\/td> #> <td headers=\"en\" class=\"gt_row gt_right\">11.0<\/td><\/tr> #>   <\/tbody> #>    #>    #> <\/table> #> <\/div>"},{"path":"https://keaven.github.io/gsDesign/reference/checkScalar.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility functions to verify variable properties — checkLengths","title":"Utility functions to verify variable properties — checkLengths","text":"Utility functions verify objects's properties including whether scalar vector, class, length, (numeric) whether range values specified interval. Additionally, checkLengths function can used ensure supplied inputs equal lengths. isInteger similar .integer except isInteger(1) returns TRUE whereas .integer(1) returns FALSE. checkScalar used verify input object scalar well properties specified . checkVector used verify input object atomic vector well properties defined . checkRange used check whether numeric input object's values reside specified interval.  values outside specified interval, FALSE returned. checkLength used check whether supplied inputs equal lengths.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/checkScalar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility functions to verify variable properties — checkLengths","text":"","code":"checkLengths(..., allowSingle = FALSE)  checkRange(   x,   interval = 0:1,   inclusion = c(TRUE, TRUE),   varname = deparse(substitute(x)),   tol = 0 )  checkScalar(x, isType = \"numeric\", ...)  checkVector(x, isType = \"numeric\", ..., length = NULL)  isInteger(x)"},{"path":"https://keaven.github.io/gsDesign/reference/checkScalar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility functions to verify variable properties — checkLengths","text":"... checkScalar checkVector functions, input represents additional arguments sent directly checkRange function. checkLengths function, input represents arguments check equal lengths. allowSingle logical flag. TRUE, arguments vectors comprised single element included comparative length test checkLengths function. Partial matching name argument performed must specify 'allowSingle' entirety call. x object. interval two-element numeric vector defining interval input object expected contained.  Use inclusion argument define boundary behavior. inclusion two-element logical vector defining boundary behavior specified interval. TRUE value denotes inclusion corresponding boundary. example, interval=c(3,6) inclusion=c(FALSE,TRUE), values input object verified interval (3,6]. varname character string defining name input variable sent function caller.  used primarily mechanism specify name variable tested checkRange called within function. tol numeric scalar defining tolerance use testing intervals checkRange function. isType character string defining class input object expected . length integer specifying expected length object case vector. length=NULL, default, length check performed.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/checkScalar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility functions to verify variable properties — checkLengths","text":"isInteger: Boolean value checking result functions return value, called side effects","code":""},{"path":"https://keaven.github.io/gsDesign/reference/checkScalar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility functions to verify variable properties — checkLengths","text":"","code":"# check whether input is an integer isInteger(1) #> [1] TRUE isInteger(1:5) #> [1] TRUE try(isInteger(\"abc\")) # expect error #> [1] FALSE  # check whether input is an integer scalar checkScalar(3, \"integer\")  # check whether input is an integer scalar that resides # on the interval on [3, 6]. Then test for interval (3, 6]. checkScalar(3, \"integer\", c(3, 6)) try(checkScalar(3, \"integer\", c(3, 6), c(FALSE, TRUE))) # expect error #> Error in checkRange(x, ..., varname = deparse(substitute(x))) :  #>   3 not on interval (3, 6]  # check whether the input is an atomic vector of class numeric, # of length 3, and whose value all reside on the interval [1, 10) x <- c(3, pi, exp(1)) checkVector(x, \"numeric\", c(1, 10), c(TRUE, FALSE), length = 3)  # do the same but change the expected length; expect error try(checkVector(x, \"numeric\", c(1, 10), c(TRUE, FALSE), length = 2)) #> Error in checkVector(x, \"numeric\", c(1, 10), c(TRUE, FALSE), length = 2) :  #>   object 'varstr' not found  # create faux function to check input variable foo <- function(moo) checkVector(moo, \"character\") foo(letters) try(foo(1:5)) # expect error with function and argument name in message #> Error in checkVector(moo, \"character\") :  #>   In function foo : variable moo  must be vector of class  character  # check for equal lengths of various inputs checkLengths(1:2, 2:3, 3:4) try(checkLengths(1, 2, 3, 4:5)) # expect error #> Error in checkLengths(1, 2, 3, 4:5) :  #>   In function doTryCatch :lengths of inputs are not all equal  # check for equal length inputs but ignore single element vectors checkLengths(1, 2, 3, 4:5, 7:8, allowSingle = TRUE)"},{"path":"https://keaven.github.io/gsDesign/reference/eEvents.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected number of events for a time-to-event study — eEvents","title":"Expected number of events for a time-to-event study — eEvents","text":"eEvents() used calculate expected number events population time--event endpoint.  based calculations demonstrated Lachin Foulkes (1986) fundamental computations sample size method propose. Piecewise exponential survival dropout rates supported well piecewise uniform enrollment. stratified population allowed. Output expected number events observed given trial duration rate parameters. eEvents() produces object class eEvents number subjects events set pre-specified trial parameters, accrual duration follow-period. underlying power calculation based Lachin Foulkes (1986) method proportional hazards assuming fixed underlying hazard ratio 2 treatment groups. method extended enable designs test non-inferiority. Piecewise constant enrollment failure rates assumed stratified population allowed. See also nSurvival Lachin Foulkes (1986) methods assuming constant hazard difference exponential enrollment rate. print.eEvents() formats output object class eEvents returns input value.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/eEvents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected number of events for a time-to-event study — eEvents","text":"","code":"eEvents(   lambda = 1,   eta = 0,   gamma = 1,   R = 1,   S = NULL,   T = 2,   Tfinal = NULL,   minfup = 0,   digits = 4 )  # S3 method for eEvents print(x, digits = 4, ...)"},{"path":"https://keaven.github.io/gsDesign/reference/eEvents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected number of events for a time-to-event study — eEvents","text":"lambda scalar, vector matrix event hazard rates; rows represent time periods columns represent strata; vector implies single stratum. eta scalar, vector matrix dropout hazard rates; rows represent time periods columns represent strata; entered scalar, rate constant across strata time periods; entered vector, rates constant across strata. gamma scalar, vector matrix rates entry time period (rows) strata (columns); entered scalar, rate constant across strata time periods; entered vector, rates constant across strata. R scalar vector durations time periods recruitment rates specified rows gamma. Length number rows gamma. Note final enrollment period extended long needed. S scalar vector durations piecewise constant event rates specified rows lambda, eta etaE; NULL single event rate per stratum (exponential failure) length number rows lambda minus 1, otherwise. T time analysis; Tfinal=NULL, also study duration. Tfinal Study duration; NULL, replaced T output. minfup time end planned enrollment (sum(R) output value R) Tfinal. digits controls number digits printing. x object class eEvents returned eEvents(). ... arguments may passed generic print function.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/eEvents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected number of events for a time-to-event study — eEvents","text":"eEvents() print.eEvents() return object class eEvents contains following items: lambda input; converted matrix output. eta input; converted matrix output. gamma input. R input. S input. T input. Tfinal planned duration study. minfup input. d expected number events. n expected sample size. digits input.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/eEvents.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Expected number of events for a time-to-event study — eEvents","text":"Lachin JM Foulkes MA (1986), Evaluation Sample Size Power Analyses Survival Allowance Nonuniform Patient Entry, Losses Follow-, Noncompliance, Stratification. Biometrics, 42, 507-519. Bernstein D Lagakos S (1978), Sample size power determination stratified clinical trials. Journal Statistical Computation Simulation, 8:65-73.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/eEvents.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Expected number of events for a time-to-event study — eEvents","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/eEvents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expected number of events for a time-to-event study — eEvents","text":"","code":"# 3 enrollment periods, 3 piecewise exponential failure rates str(eEvents(   lambda = c(.05, .02, .01), eta = .01, gamma = c(5, 10, 20),   R = c(2, 1, 2), S = c(1, 1), T = 20 )) #> List of 11 #>  $ lambda: num [1:3, 1] 0.05 0.02 0.01 #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:3] \"0-1\" \"1-2\" \"2-20\" #>   .. ..$ : chr \"Stratum 1\" #>  $ eta   : num [1:3, 1] 0.01 0.01 0.01 #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:3] \"0-1\" \"1-2\" \"2-20\" #>   .. ..$ : chr \"Stratum 1\" #>  $ gamma : num [1:3, 1] 5 10 20 #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:3] \"0-2\" \"2-3\" \"3-5\" #>   .. ..$ : chr \"Stratum 1\" #>  $ R     : num [1:3] 2 1 2 #>  $ S     : num [1:2] 1 1 #>  $ T     : num 20 #>  $ Tfinal: num 20 #>  $ minfup: num 0 #>  $ d     : num 11 #>  $ n     : num 60 #>  $ digits: num 4 #>  - attr(*, \"class\")= chr \"eEvents\"  # control group for example from Bernstein and Lagakos (1978) lamC <- c(1, .8, .5) n <- eEvents(   lambda = matrix(c(lamC, lamC * 2 / 3), ncol = 6), eta = 0,   gamma = matrix(.5, ncol = 6), R = 2, T = 4 )"},{"path":"https://keaven.github.io/gsDesign/reference/gsBinomialExact.html","id":null,"dir":"Reference","previous_headings":"","what":"One-Sample Binomial Routines — gsBinomialExact","title":"One-Sample Binomial Routines — gsBinomialExact","text":"gsBinomialExact computes power/Type error expected sample size group sequential design single-arm trial binary outcome. can also used compare event rates two-arm studies. print function extended using print.gsBinomialExact print gsBinomialExact objects. Similarly, plot function extended using plot.gsBinomialExact plot gsBinomialExact objects. binomialSPRT computes truncated binomial sequential probability ratio test (SPRT) specific instance exact binomial group sequential design single arm trial binary outcome. gsBinomialPP computes truncated binomial (group) sequential design based predictive probability. nBinomial1Sample uses exact binomial calculations compute power sample size single arm binomial experiments. gsBinomialExact based book \"Group Sequential Methods Applications Clinical Trials,\" Christopher Jennison Bruce W. Turnbull, Chapter 12, Section 12.1.2 Exact Calculations Binary Data. computation often used approximation distribution number events one treatment group events probability event small sample size large. object class gsBinomialExact returned. output, values theta input gsBinomialExact parameter values boundary crossing probabilities expected sample sizes computed. Note [1] equal -1 lower bound n.[1] means 0 successes continues interim 1; [2]==0 interim 2 means 0 successes stops trial futility 2nd analysis.  final analysis, set [k] equal b[k]-1 incorporate possibilities non-positive trial; see example. sequential probability ratio test (SPRT) sequential testing scheme allowing testing observation. likelihood ratio used determine upper lower cutoffs linear parallel number responses function sample size.  binomialSPRT produces variation SPRT tests within range sample sizes. linear SPRT bounds continuous, actual bounds integer number response beyond linear bound sample size testing performed. truncation discretization bounds, power Type error achieve lower nominal levels specified alpha beta can altered produce desired values achieved planned sample size. See also example shows computation Type error futility bound considered non-binding. Note objective design demonstrate rate (e.g., failure rate) lower certain level, two approaches can taken. First, 1 minus failure rate success rate can used planning. Second, role beta becomes express Type error alpha used express Type II error. Plots produced include boundary plots, expected sample size, response rate boundary power. gsBinomial1Sample uses exact binomial computations based base R functions qbinom() pbinom(). tabular output may convenient plotting. Note input variables largely checked, user largely responsible results; good idea run outtype=3 check done things appropriately. n ordered (bad idea) sequential (maybe OK), aware possible consequences. nBinomial1Sample based code Marc Schwartz marc_schwartz@.com.  possible sample size vector n needs selected fashion covers possible range values include true minimum.  NOTE: one-sided evaluation significance conservative using 2-sided exact test binom.test.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBinomialExact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One-Sample Binomial Routines — gsBinomialExact","text":"","code":"gsBinomialExact(   k = 2,   theta = c(0.1, 0.2),   n.I = c(50, 100),   a = c(3, 7),   b = c(20, 30) )  binomialSPRT(   p0 = 0.05,   p1 = 0.25,   alpha = 0.1,   beta = 0.15,   minn = 10,   maxn = 35 )  # S3 method for gsBinomialExact plot(x, plottype = 1, ...)  # S3 method for binomialSPRT plot(x, plottype = 1, ...)  nBinomial1Sample(   p0 = 0.9,   p1 = 0.95,   alpha = 0.025,   beta = NULL,   n = 200:250,   outtype = 1,   conservative = FALSE )"},{"path":"https://keaven.github.io/gsDesign/reference/gsBinomialExact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One-Sample Binomial Routines — gsBinomialExact","text":"k Number analyses planned, including interim final. theta Vector possible underling binomial probabilities single binomial sample. n.Sample size analyses (increasing positive integers); vector length k. Number \"successes\" required cross lower bound cutoffs reject p1 favor p0 analysis; vector length k; -1 means lower bound. b Number \"successes\" required cross upper bound cutoffs rejecting p0 favor p1 analysis; vector length k. p0 Lower two response (event) rates hypothesized. p1 Higher two response (event) rates hypothesized. alpha Nominal probability rejecting response (event) rate p0 true. beta Nominal probability rejecting response (event) rate p1 true. NULL, Type II error computed input values  n output data frame. minn Minimum sample size sequential testing begins. maxn Maximum sample size. x Item class gsBinomialExact binomialSPRT print.gsBinomialExact. Item class gsBinomialExact plot.gsBinomialExact. Item class binomialSPRT item class plot.binomialSPRT. plottype 1 produces plot counts response bounds (binomialSPRT, also produces linear SPRT bounds); 2 produces plot power reject null alternate response rates well probability crossing bound maximum sample size; 3 produces plot response rate boundary function sample size boundary crossed; 6 produces plot expected sample size underlying event rate (assumes enrollment beyond sample size boundary crossed). ... arguments passed ggplot. n sample sizes considered nBinomial1Sample. ordered smallest largest > 0. outtype Operative beta != NULL. 1 means routine return single integer sample size output=2a data frame  returned (see Value); note operative beta NULL  case data table returned Type II error power input  value n. conservative operative outtype=1 2 beta != NULL. Default FALSE selects minimum sample size power least 1-beta. conservative=TRUE, minimum sample sample size power least 1-beta larger sample size input n power less 1-beta.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBinomialExact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"One-Sample Binomial Routines — gsBinomialExact","text":"gsBinomialExact() returns list class gsBinomialExact gsProbability (see example); displaying one objects, default function print print.gsProbability().  object returned gsBinomialExact() contains following elements: k input. theta input. n.input. lower list containing two elements: bound input prob matrix boundary crossing probabilities. Element ,j contains boundary crossing probability analysis j-th element theta input. boundary crossing assumed binding computation; , trial must stop boundary crossed. upper list form lower containing upper bound upper boundary crossing probabilities. en vector length theta containing expected sample sizes trial design corresponding value vector theta. binomialSPRT produces object class binomialSPRT extension gsBinomialExact class. values returned addition returned gsBinomialExact : intercept vector length 2 intercepts two SPRT bounds. slope scalar common slope SPRT bounds. alpha input. Note exceed actual Type error achieved design returned. beta input. Note exceed actual Type II error achieved design returned. p0 input. p1 input. nBinomial1Sample produces data frame power input value n beta=NULL. Otherwise, sample size achieving desired power returned unless  minimum power values input n greater equal target  maximum yields power less target, case error message shown.  input variable outtype effect beta=NULL.  Otherwise, outtype=1 results return integer sample size outtype=2 results data frame one record includes desired sample size. data frame returned, variables include: p0 Input null hypothesis event (response) rate. p1 Input alternative hypothesis (response) rate; must > p0. alpha Input Type error. beta Input Type II error except input NULL case realized Type II error computed. n sample size. b cutoff given n control Type error; value NULL value exists. alphaR Type error achieved  output value n; less equal input value alpha. Power Power achieved  output value n.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBinomialExact.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"One-Sample Binomial Routines — gsBinomialExact","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBinomialExact.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"One-Sample Binomial Routines — gsBinomialExact","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Code nBinomial1Sample based code developed marc_schwartz@.com.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsBinomialExact.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"One-Sample Binomial Routines — gsBinomialExact","text":"Jon Hartzel, Yevgen Tymofyeyev Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBinomialExact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"One-Sample Binomial Routines — gsBinomialExact","text":"","code":"library(ggplot2)  zz <- gsBinomialExact(   k = 3, theta = seq(0, 1, 0.1), n.I = c(12, 24, 36),   a = c(-1, 0, 11), b = c(5, 9, 12) )  # let's see what class this is class(zz) #> [1] \"gsBinomialExact\" \"gsProbability\"    # because of \"gsProbability\" class above, following is equivalent to # \\code{print.gsProbability(zz)} zz #>               Bounds #>   Analysis   N   a   b #>          1  12  -1   5 #>          2  24   0   9 #>          3  36  11  12 #>  #> Boundary crossing probabilities and expected sample size assume #> any cross stops the trial #>  #> Upper boundary #>           Analysis #>   Theta      1      2      3  Total E{N} #>     0.0 0.0000 0.0000 0.0000 0.0000 24.0 #>     0.1 0.0043 0.0002 0.0001 0.0045 34.9 #>     0.2 0.0726 0.0155 0.0168 0.1048 34.0 #>     0.3 0.2763 0.0993 0.1164 0.4921 28.2 #>     0.4 0.5618 0.1782 0.1362 0.8762 20.4 #>     0.5 0.8062 0.1372 0.0463 0.9896 15.0 #>     0.6 0.9427 0.0519 0.0052 0.9998 12.8 #>     0.7 0.9905 0.0093 0.0002 1.0000 12.1 #>     0.8 0.9994 0.0006 0.0000 1.0000 12.0 #>     0.9 1.0000 0.0000 0.0000 1.0000 12.0 #>     1.0 1.0000 0.0000 0.0000 1.0000 12.0 #>  #> Lower boundary #>           Analysis #>   Theta 1      2      3  Total #>     0.0 0 1.0000 0.0000 1.0000 #>     0.1 0 0.0798 0.9157 0.9955 #>     0.2 0 0.0047 0.8905 0.8952 #>     0.3 0 0.0002 0.5077 0.5079 #>     0.4 0 0.0000 0.1238 0.1238 #>     0.5 0 0.0000 0.0104 0.0104 #>     0.6 0 0.0000 0.0002 0.0002 #>     0.7 0 0.0000 0.0000 0.0000 #>     0.8 0 0.0000 0.0000 0.0000 #>     0.9 0 0.0000 0.0000 0.0000 #>     1.0 0 0.0000 0.0000 0.0000  # also plot (see also plots below for \\code{binomialSPRT}) # add lines using geom_line() plot(zz) +  ggplot2::geom_line()   # now for SPRT examples x <- binomialSPRT(p0 = .05, p1 = .25, alpha = .1, beta = .2) # boundary plot plot(x)  # power plot plot(x, plottype = 2)  # Response (event) rate at boundary plot(x, plottype = 3)  # Expected sample size at boundary crossing or end of trial plot(x, plottype = 6)   # sample size for single arm exact binomial  # plot of table of power by sample size # note that outtype need no be specified if beta is NULL nb1 <- nBinomial1Sample(p0 = 0.05, p1=0.2,alpha = 0.025, beta=NULL, n = 25:40) nb1 #>      p0  p1 alpha      beta  n b      alphaR     Power #> 1  0.05 0.2 0.025 0.4206743 25 5 0.007164948 0.5793257 #> 2  0.05 0.2 0.025 0.3833381 26 5 0.008511231 0.6166619 #> 3  0.05 0.2 0.025 0.3480384 27 5 0.010022739 0.6519616 #> 4  0.05 0.2 0.025 0.3148874 28 5 0.011708399 0.6851126 #> 5  0.05 0.2 0.025 0.2839465 29 5 0.013576673 0.7160535 #> 6  0.05 0.2 0.025 0.2552333 30 5 0.015635510 0.7447667 #> 7  0.05 0.2 0.025 0.2287288 31 5 0.017892313 0.7712712 #> 8  0.05 0.2 0.025 0.2043839 32 5 0.020353899 0.7956161 #> 9  0.05 0.2 0.025 0.1821257 33 5 0.023026479 0.8178743 #> 10 0.05 0.2 0.025 0.2996488 34 6 0.006269405 0.7003512 #> 11 0.05 0.2 0.025 0.2720917 35 6 0.007251716 0.7279083 #> 12 0.05 0.2 0.025 0.2463717 36 6 0.008340444 0.7536283 #> 13 0.05 0.2 0.025 0.2224770 37 6 0.009541557 0.7775230 #> 14 0.05 0.2 0.025 0.2003744 38 6 0.010860905 0.7996256 #> 15 0.05 0.2 0.025 0.1800132 39 6 0.012304191 0.8199868 #> 16 0.05 0.2 0.025 0.1613288 40 6 0.013876949 0.8386712 library(scales) ggplot2::ggplot(nb1, ggplot2::aes(x = n, y = Power)) +  ggplot2::geom_line() +  ggplot2::geom_point() +  ggplot2::scale_y_continuous(labels = percent)   # simple call with same parameters to get minimum sample size yielding desired power nBinomial1Sample(p0 = 0.05, p1 = 0.2, alpha = 0.025, beta = .2, n = 25:40) #> [1] 33  # change to 'conservative' if you want all larger sample # sizes to also provide adequate power nBinomial1Sample(p0 = 0.05, p1 = 0.2, alpha = 0.025, beta = .2, n = 25:40, conservative = TRUE) #> [1] 39  # print out more information for the selected derived sample size nBinomial1Sample(p0 = 0.05, p1 = 0.2, alpha = 0.025, beta = .2, n = 25:40, conservative = TRUE,  outtype = 2) #>     p0  p1 alpha beta  n b     alphaR     Power #> 1 0.05 0.2 0.025  0.2 39 6 0.01230419 0.8199868  # what happens if input sample sizes not sufficient? if (FALSE) {    nBinomial1Sample(p0 = 0.05, p1 = 0.2, alpha = 0.025, beta = .2, n = 25:30) }"},{"path":"https://keaven.github.io/gsDesign/reference/gsBound.html","id":null,"dir":"Reference","previous_headings":"","what":"Boundary derivation - low level — gsBound","title":"Boundary derivation - low level — gsBound","text":"gsBound() gsBound1() lower-level functions used find boundaries group sequential design. recommended (especially gsBound1()) casual users. functions adjust sample size gsDesign() ensure appropriate power design. gsBound() computes upper lower bounds given boundary crossing probabilities assuming mean 0, usual null hypothesis. gsBound1() computes upper bound given lower boundary, upper boundary crossing probabilities arbitrary mean (theta). function gsBound1() requires special attention detail knowledge behavior design corresponding input parameters exist.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Boundary derivation - low level — gsBound","text":"","code":"gsBound(I, trueneg, falsepos, tol = 1e-06, r = 18, printerr = 0)  gsBound1(theta, I, a, probhi, tol = 1e-06, r = 18, printerr = 0)"},{"path":"https://keaven.github.io/gsDesign/reference/gsBound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boundary derivation - low level — gsBound","text":"Vector containing statistical information planned analysis. trueneg Vector desired probabilities crossing upper bound assuming mean 0. falsepos Vector desired probabilities crossing lower bound assuming mean 0. tol Tolerance error (scalar; default 0.000001). Normally changed user.  translate directly number digits accuracy, use extra decimal places. r Single integer value controlling grid numerical integration Jennison Turnbull (2000); default 18, range 1 80.  Larger values provide larger number grid points greater accuracy.  Normally r changed user. printerr scalar argument set 1, print messages underlying C program.  Mainly intended notify user output solution match input specifications.  intended stop execution often occurs deriving design gsDesign uses beta-spending. theta Scalar containing mean (drift) per unit statistical information. Vector containing lower bound fixed use gsBound1. probhi Vector desired probabilities crossing upper bound assuming mean theta.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Boundary derivation - low level — gsBound","text":"routines return list. Common items returned two routines : k length vectors input; scalar. theta input gsBound1(); 0 gsBound(). input. gsbound1, input. gsbound derived lower boundary required yield input boundary crossing probabilities null hypothesis. b derived upper boundary required yield input boundary crossing probabilities null hypothesis. tol input. r input. error Error code. 0 error; greater 0 otherwise. gsBound() also returns following items: rates list containing two items: falsepos vector upper boundary crossing probabilities input. trueneg vector lower boundary crossing probabilities input. gsBound1() also returns following items: problo vector lower boundary crossing probabilities; computed using input lower bound derived upper bound. probhi vector upper boundary crossing probabilities input.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBound.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Boundary derivation - low level — gsBound","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBound.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Boundary derivation - low level — gsBound","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsBound.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Boundary derivation - low level — gsBound","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBound.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Boundary derivation - low level — gsBound","text":"","code":"# set boundaries so that probability is .01 of first crossing # each upper boundary and .02 of crossing each lower boundary # under the null hypothesis x <- gsBound(   I = c(1, 2, 3) / 3, trueneg = rep(.02, 3),   falsepos = rep(.01, 3) ) x #> $k #> [1] 3 #>  #> $theta #> [1] 0 #>  #> $I #> [1] 0.3333333 0.6666667 1.0000000 #>  #> $a #> [1] -2.053749 -1.914183 -1.789206 #>  #> $b #> [1] 2.326348 2.219299 2.120127 #>  #> $rates #> $rates$falsepos #> [1] 0.01 0.01 0.01 #>  #> $rates$trueneg #> [1] 0.02 0.02 0.02 #>  #>  #> $tol #> [1] 1e-06 #>  #> $r #> [1] 18 #>  #> $error #> [1] 0 #>   #  use gsBound1 to set up boundary for a 1-sided test x <- gsBound1(   theta = 0, I = c(1, 2, 3) / 3, a = rep(-20, 3),   probhi = c(.001, .009, .015) ) x$b #> [1] 3.090232 2.344824 2.039501  # check boundary crossing probabilities with gsProbability y <- gsProbability(k = 3, theta = 0, n.I = x$I, a = x$a, b = x$b)$upper$prob  #  Note that gsBound1 only computes upper bound #  To get a lower bound under a parameter value theta: #      use minus the upper bound as a lower bound #      replace theta with -theta #      set probhi as desired lower boundary crossing probabilities #  Here we let set lower boundary crossing at 0.05 at each analysis #  assuming theta=2.2 y <- gsBound1(   theta = -2.2, I = c(1, 2, 3) / 3, a = -x$b,   probhi = rep(.05, 3) ) y$b #> [1]  0.3746830 -0.3594403 -0.9470061  #  Now use gsProbability to look at design #  Note that lower boundary crossing probabilities are as #  specified for theta=2.2, but for theta=0 the upper boundary #  crossing probabilities are smaller than originally specified #  above after first interim analysis gsProbability(k = length(x$b), theta = c(0, 2.2), n.I = x$I, b = x$b, a = -y$b) #>                Lower bounds   Upper bounds #>   Analysis N    Z   Nominal p  Z   Nominal p #>          1  1 -0.37    0.3539 3.09    0.0010 #>          2  1  0.36    0.6404 2.34    0.0095 #>          3  1  0.95    0.8282 2.04    0.0207 #>  #> Boundary crossing probabilities and expected sample size assume #> any cross stops the trial #>  #> Upper boundary #>           Analysis #>   Theta      1      2      3  Total E{N} #>     0.0 0.0010 0.0090 0.0146 0.0246  0.7 #>     2.2 0.0344 0.2601 0.2783 0.5728  0.8 #>  #> Lower boundary #>           Analysis #>   Theta      1      2     3  Total #>     0.0 0.3539 0.3153 0.184 0.8532 #>     2.2 0.0500 0.0500 0.050 0.1500"},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundCP.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Power at Interim Boundaries — gsBoundCP","title":"Conditional Power at Interim Boundaries — gsBoundCP","text":"gsBoundCP() computes total probability crossing future upper bounds given interim test statistic interim bound. interim boundary, assumes interim test statistic boundary computes probability crossing later upper boundaries. See Conditional power section manual clarification. See also Muller Schaffer (2001) background theory.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundCP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Power at Interim Boundaries — gsBoundCP","text":"","code":"gsBoundCP(x, theta = \"thetahat\", r = 18)"},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundCP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Power at Interim Boundaries — gsBoundCP","text":"x object type gsDesign gsProbability theta \"thetahat\" class(x)!=\"gsDesign\", conditional power computations boundary value computed using estimated treatment effect assuming test statistic boundary (zi/sqrt(x$n.[]) analysis , interim test statistic zi interim sample size/statistical information x$n.[]). Otherwise, conditional power computed assuming input scalar value theta. r Integer value controlling grid numerical integration Jennison Turnbull (2000); default 18, range 1 80.  Larger values provide larger number grid points greater accuracy.  Normally r changed user.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundCP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Power at Interim Boundaries — gsBoundCP","text":"list containing two vectors, CPlo CPhi. CPlo vector length x$k-1 conditional powers crossing upper bounds given interim test statistics lower bound CPhi vector length x$k-1 conditional powers crossing upper bounds given interim test statistics upper bound.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundCP.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Conditional Power at Interim Boundaries — gsBoundCP","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundCP.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditional Power at Interim Boundaries — gsBoundCP","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Muller, Hans-Helge Schaffer, Helmut (2001), Adaptive group sequential designs clinical trials: combining advantages adaptive classical group sequential approaches. Biometrics;57:886-891.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundCP.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Conditional Power at Interim Boundaries — gsBoundCP","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundCP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Power at Interim Boundaries — gsBoundCP","text":"","code":"# set up a group sequential design x <- gsDesign(k = 5) x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.220 -0.90    0.1836 0.0077 3.25    0.0006  0.0006 #>          2  0.441 -0.04    0.4853 0.0115 2.99    0.0014  0.0013 #>          3  0.661  0.69    0.7563 0.0171 2.69    0.0036  0.0028 #>          4  0.881  1.36    0.9131 0.0256 2.37    0.0088  0.0063 #>          5  1.101  2.03    0.9786 0.0381 2.03    0.0214  0.0140 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Hwang-Shih-DeCani spending function with gamma = -2. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4      5  Total   E{N} #>   0.0000 0.0006 0.0013 0.0028 0.0062 0.0117 0.0226 0.5726 #>   3.2415 0.0417 0.1679 0.2806 0.2654 0.1444 0.9000 0.7440 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4      5  Total #>   0.0000 0.1836 0.3201 0.2700 0.1477 0.0559 0.9774 #>   3.2415 0.0077 0.0115 0.0171 0.0256 0.0381 0.1000  # compute conditional power based on interim treatment effects gsBoundCP(x) #>              CPlo      CPhi #> [1,] 2.294534e-06 1.0000001 #> [2,] 2.238566e-03 0.9998352 #> [3,] 2.669114e-02 0.9922459 #> [4,] 1.296705e-01 0.9200502  # compute conditional power based on original x$delta gsBoundCP(x, theta = x$delta) #>           CPlo      CPhi #> [1,] 0.4936972 0.9940265 #> [2,] 0.3676577 0.9954019 #> [3,] 0.3331896 0.9912361 #> [4,] 0.3871332 0.9590607"},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Bound Summary and Z-transformations — summary.gsDesign","title":"Bound Summary and Z-transformations — summary.gsDesign","text":"tabular summary group sequential design's bounds properties often useful. 'vintage' print.gsDesign() function provides complete minimally formatted summary group sequential design derived gsDesign(). brief description overall design can also useful (summary.gsDesign().  tabular summary boundary characteristics oriented towards LaTeX output produced xtable.gsSurv. flexibility provided gsBoundSummary() produces tabular summary user-specifiable set package-provided boundary properties data frame.  can also used along functions print.data.frame(), write.table(), write.csv(), write.csv2() , RTF package, addTable.RTF() (rtf package) produce console R Markdown output output variety file types. xprint() provided LaTeX output setting default options print.xtable() producing tables summarizing design bounds. Individual transformation z-value test statistics interim final analyses obtained gsBValue(), gsDelta(), gsHR() gsCPz() B-values, approximate treatment effect (see details), approximate hazard ratio conditional power, respectively. print.gsDesign function intended provide easier output review available simple list output components. gsBoundSummary function intended provide summary boundary characteristics often useful evaluating boundary selection; outputs extension data.frame class sets default printing without row names using print.gsBoundSummary. summary.gsDesign, hand, provides summary overall design higher level; provides characteristics included gsBoundSummary summary detail concerning interim analysis bounds. brief, computed descriptions group sequential design bounds follows: Z: Standardized normal test statistic design bound. p (1-sided): 1-sided p-value Z. computed probability greater EXCEPT lower bound 2-sided design summarized. delta bound: Approximate value natural parameter bound. approximate standardized effect size bound generally computed Z/sqrt(n). Calling theta, translated delta using values delta0 delta1 input x formula delta0 + (delta1-delta0)/theta1*theta theta1 alternate hypothesis value standardized parameter. Note value exponentiated case relative risks, hazard ratios user specifies logdelta=TRUE. case hazard ratios, value computed instead gsHR() consistent plot.gsDesign(). Similarly, value computed gsRR() relative risk natural parameter. Spending: Incremental error spending given analysis. asymmetric designs, futility bound beta-spending summarized. Efficacy bound always alpha-spending summarized. B-value: sqrt(t)*Z t proportion information analysis divided final analysis planned information. expected value B-values directly proportional t. CP: Conditional power estimated treatment difference assuming interim Z-statistic study bound CP H1: Conditional power alternate hypothesis treatment effect assuming interim test statistic study bound. PP: Predictive power assuming interim test statistic study bound input prior distribution standardized effect size. conditional power averaged across posterior distribution treatment effect given interim test statistic value. P{Cross delta=xx}: parameter values x, probability crossing either bound given treatment effect computed. value cumulative bound. example, probability crossing efficacy bound analysis interest.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bound Summary and Z-transformations — summary.gsDesign","text":"","code":"# S3 method for gsDesign summary(object, information = FALSE, timeunit = \"months\", ...)  # S3 method for gsDesign print(x, ...)  gsBoundSummary(   x,   deltaname = NULL,   logdelta = FALSE,   Nname = NULL,   digits = 4,   ddigits = 2,   tdigits = 0,   timename = \"Month\",   prior = normalGrid(mu = x$delta/2, sigma = 10/sqrt(x$n.fix)),   POS = FALSE,   ratio = NULL,   exclude = c(\"B-value\", \"Spending\", \"CP\", \"CP H1\", \"PP\"),   r = 18,   ... )  xprint(   x,   include.rownames = FALSE,   hline.after = c(-1, which(x$Value == x[1, ]$Value) - 1, nrow(x)),   ... )  # S3 method for gsBoundSummary print(x, row.names = FALSE, digits = 4, ...)  gsBValue(z, i, x, ylab = \"B-value\", ...)  gsDelta(z, i, x, ylab = NULL, ...)  gsRR(z, i, x, ratio = 1, ylab = \"Approximate risk ratio\", ...)  gsHR(z, i, x, ratio = 1, ylab = \"Approximate hazard ratio\", ...)  gsCPz(z, i, x, theta = NULL, ylab = NULL, ...)"},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bound Summary and Z-transformations — summary.gsDesign","text":"object item class gsDesign gsSurv information indicator whether n.object represents statistical information rather sample size event counts. timeunit Text string time units used time--event designs created gsSurv() ... allows many optional arguments standard calling plot gsBValue, gsDelta, gsHR, gsRR gsCPz x item class gsDesign gsSurv, except print.gsBoundSummary() x object created gsBoundSummary() xprint() used xtable (see examples) deltaname Natural parameter name. default NULL used, routine default \"HR\" class gsSurv nFixSurv input creating x gsDesign(). logdelta Indicates whether natural parameter natural logarithm actual parameter. example, relative risk odds-ratio put logarithmic scale since asymptotic behavior 'normal' non-transformed value. deltaname, default changed true x class gsDesign nFixSurv>0 input x created gsDesign(); , natural parameter time--event endpoint logarithmic scale. Nname normally changed \"N\" , time--event endpoint used, \"Events\". immediate possibility \"Deaths\" \"Information\". digits Number digits past decimal printed body table. ddigits Number digits past decimal printed natural parameter delta. tdigits Number digits past decimal point shown estimated timing analysis. timename Text string indicating time unit. prior prior distribution standardized effect size. Must format produced normalGrid(), can reflect arbitrary prior distribution. default reflects normal prior centered half-way null alternate hypothesis variance equivalent treatment effect estimate 1 percent sample size fixed design sampled. prior intended relatively uninformative. input applied POS=TRUE input. POS indicator whether probability success (POS) estimated baseline interim based prior distribution input prior. prior probability success trial starts power study averaged prior distribution standardized effect size. POS interim analysis assumes interim test statistic unknown value futility efficacy bounds. Based , posterior distribution standardized parameter computed conditional power trial averaged posterior distribution. ratio Sample size ratio assumed experimental control treatment group sample sizes. matters x binomial time--event endpoint gsRR gsHR used approximating treatment effect test statistic falls study bound. exclude list test statistics excluded design boundary summary produced; see details examples list possible output values. value NULL produces available summaries. r See gsDesign. integer used control degree accuracy group sequential calculations normally changed. include.rownames indicator whether include row names output. hline.table lines horizontal separation lines set; default put lines analysis well top bottom table. row.names indicator whether print row names z vector z-statistics vector containing analysis element z; element must 1 x$k, inclusive ylab Used functions passed plot.gsDesign establish default y-axis labels theta scalar value representing standardized effect size used conditional power calculations; see gsDesign; NULL, conditional power computed estimated interim treatment effect based z","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bound Summary and Z-transformations — summary.gsDesign","text":"gsBValue(), gsDelta(), gsHR() gsCPz() returns vector containing B-values, approximate treatment effect (see details), approximate hazard ratio conditional power, respectively, value specified interim test statistics z interim analyses specified . summary returns text string summarizing design high level. may used gsBoundSummary nicely formatted, concise group sequential design description. gsBoundSummary returns table data frame providing variety boundary characteristics. tabular format makes formatting particularly amenable place documents either direct creation readable Word (see rtf package) csv format readable spreadsheet software using write.csv. print.gsDesign prints overall summary group sequential design. design description complete, format `document friendly' gsBoundSummary. print.gsBoundSummary simple extension print.data.frame intended objects created gsBoundSummary. extension make default print row names. probably `good R style' may helpful many lazy R programmers like author.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundSummary.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Bound Summary and Z-transformations — summary.gsDesign","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundSummary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bound Summary and Z-transformations — summary.gsDesign","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundSummary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bound Summary and Z-transformations — summary.gsDesign","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsBoundSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bound Summary and Z-transformations — summary.gsDesign","text":"","code":"library(ggplot2) # survival endpoint using gsSurv # generally preferred over nSurv since time computations are shown xgs <- gsSurv(lambdaC = .2, hr = .5, eta = .1, T = 2, minfup = 1.5) gsBoundSummary(xgs, timename = \"Year\", tdigits = 1) #>    Analysis              Value Efficacy Futility #>   IA 1: 33%                  Z   3.0107  -0.2388 #>      N: 460        p (1-sided)   0.0013   0.5944 #>  Events: 33       ~HR at bound   0.3457   1.0879 #>   Year: 0.8   P(Cross) if HR=1   0.0013   0.4056 #>             P(Cross) if HR=0.5   0.1412   0.0148 #>   IA 2: 67%                  Z   2.5465   0.9410 #>      N: 460        p (1-sided)   0.0054   0.1733 #>  Events: 65       ~HR at bound   0.5298   0.7907 #>   Year: 1.3   P(Cross) if HR=1   0.0062   0.8347 #>             P(Cross) if HR=0.5   0.5815   0.0437 #>       Final                  Z   1.9992   1.9992 #>      N: 460        p (1-sided)   0.0228   0.0228 #>  Events: 97       ~HR at bound   0.6655   0.6655 #>     Year: 2   P(Cross) if HR=1   0.0233   0.9767 #>             P(Cross) if HR=0.5   0.9000   0.1000 summary(xgs) #> [1] \"Asymmetric two-sided group sequential design with non-binding futility bound, 3 analyses, time-to-event outcome with sample size 460 and 97 events required, 90 percent power, 2.5 percent (1-sided) Type I error to detect a hazard ratio of 0.5. Enrollment and total study durations are assumed to be 0.5 and 2 months, respectively. Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4. Futility bounds derived using a Hwang-Shih-DeCani spending function with gamma = -2.\"  # survival endpoint using nSurvival # NOTE: generally recommend gsSurv above for this! ss <- nSurvival(   lambda1 = .2, lambda2 = .1, eta = .1, Ts = 2, Tr = .5,   sided = 1, alpha = .025, ratio = 2 ) xs <- gsDesign(nFixSurv = ss$n, n.fix = ss$nEvents, delta1 = log(ss$lambda2 / ss$lambda1)) gsBoundSummary(xs, logdelta = TRUE, ratio = ss$ratio) #>   Analysis              Value Efficacy Futility #>  IA 1: 33%                  Z   3.0107  -0.2387 #>      N: 34        p (1-sided)   0.0013   0.5943 #>                  ~HR at bound   0.3306   1.0917 #>              P(Cross) if HR=1   0.0013   0.4057 #>            P(Cross) if HR=0.5   0.1412   0.0148 #>  IA 2: 67%                  Z   2.5465   0.9411 #>      N: 67        p (1-sided)   0.0054   0.1733 #>                  ~HR at bound   0.5158   0.7830 #>              P(Cross) if HR=1   0.0062   0.8347 #>            P(Cross) if HR=0.5   0.5815   0.0437 #>      Final                  Z   1.9992   1.9992 #>     N: 100        p (1-sided)   0.0228   0.0228 #>                  ~HR at bound   0.6542   0.6542 #>              P(Cross) if HR=1   0.0233   0.9767 #>            P(Cross) if HR=0.5   0.9000   0.1000 # generate some of the above summary statistics for the upper bound z <- xs$upper$bound # B-values gsBValue(z = z, i = 1:3, x = xs) #> [1] 1.738251 2.079233 1.999226 # hazard ratio gsHR(z = z, i = 1:3, x = xs) #> [1] 0.3521851 0.5357126 0.6702573 # conditional power at observed treatment effect gsCPz(z = z[1:2], i = 1:2, x = xs) #> [1] 0.9999676 0.9737643 # conditional power at H1 treatment effect gsCPz(z = z[1:2], i = 1:2, x = xs, theta = xs$delta) #> [1] 0.9937804 0.9809768  # information-based design xinfo <- gsDesign(delta = .3, delta1 = .3) gsBoundSummary(xinfo, Nname = \"Information\") #>             Analysis                 Value Efficacy Futility #>            IA 1: 33%                     Z   3.0107  -0.2387 #>   Information: 41.64           p (1-sided)   0.0013   0.5943 #>                            ~delta at bound   0.4666  -0.0370 #>                        P(Cross) if delta=0   0.0013   0.4057 #>                      P(Cross) if delta=0.3   0.1412   0.0148 #>            IA 2: 67%                     Z   2.5465   0.9411 #>   Information: 83.27           p (1-sided)   0.0054   0.1733 #>                            ~delta at bound   0.2791   0.1031 #>                        P(Cross) if delta=0   0.0062   0.8347 #>                      P(Cross) if delta=0.3   0.5815   0.0437 #>                Final                     Z   1.9992   1.9992 #>  Information: 124.91           p (1-sided)   0.0228   0.0228 #>                            ~delta at bound   0.1789   0.1789 #>                        P(Cross) if delta=0   0.0233   0.9767 #>                      P(Cross) if delta=0.3   0.9000   0.1000  # show all available boundary descriptions gsBoundSummary(xinfo, Nname = \"Information\", exclude = NULL) #>             Analysis                 Value Efficacy Futility #>            IA 1: 33%                     Z   3.0107  -0.2387 #>   Information: 41.64           p (1-sided)   0.0013   0.5943 #>                            ~delta at bound   0.4666  -0.0370 #>                                   Spending   0.0013   0.0148 #>                                    B-value   1.7383  -0.1378 #>                                         CP   1.0000   0.0012 #>                                      CP H1   0.9938   0.4689 #>                                         PP   0.9897   0.0373 #>                        P(Cross) if delta=0   0.0013   0.4057 #>                      P(Cross) if delta=0.3   0.1412   0.0148 #>            IA 2: 67%                     Z   2.5465   0.9411 #>   Information: 83.27           p (1-sided)   0.0054   0.1733 #>                            ~delta at bound   0.2791   0.1031 #>                                   Spending   0.0049   0.0289 #>                                    B-value   2.0792   0.7684 #>                                         CP   0.9738   0.0713 #>                                      CP H1   0.9810   0.4223 #>                                         PP   0.9427   0.1157 #>                        P(Cross) if delta=0   0.0062   0.8347 #>                      P(Cross) if delta=0.3   0.5815   0.0437 #>                Final                     Z   1.9992   1.9992 #>  Information: 124.91           p (1-sided)   0.0228   0.0228 #>                            ~delta at bound   0.1789   0.1789 #>                                   Spending   0.0188   0.0563 #>                                    B-value   1.9992   1.9992 #>                        P(Cross) if delta=0   0.0233   0.9767 #>                      P(Cross) if delta=0.3   0.9000   0.1000  # add intermediate parameter value xinfo <- gsProbability(d = xinfo, theta = c(0, .15, .3)) class(xinfo) # note this is still as gsDesign class object #> [1] \"gsDesign\" gsBoundSummary(xinfo, Nname = \"Information\") #>             Analysis                  Value Efficacy Futility #>            IA 1: 33%                      Z   3.0107  -0.2387 #>   Information: 41.64            p (1-sided)   0.0013   0.5943 #>                             ~delta at bound   0.4666  -0.0370 #>                         P(Cross) if delta=0   0.0013   0.4057 #>                      P(Cross) if delta=0.15   0.0205   0.1138 #>                       P(Cross) if delta=0.3   0.1412   0.0148 #>            IA 2: 67%                      Z   2.5465   0.9411 #>   Information: 83.27            p (1-sided)   0.0054   0.1733 #>                             ~delta at bound   0.2791   0.1031 #>                         P(Cross) if delta=0   0.0062   0.8347 #>                      P(Cross) if delta=0.15   0.1243   0.3523 #>                       P(Cross) if delta=0.3   0.5815   0.0437 #>                Final                      Z   1.9992   1.9992 #>  Information: 124.91            p (1-sided)   0.0228   0.0228 #>                             ~delta at bound   0.1789   0.1789 #>                         P(Cross) if delta=0   0.0233   0.9767 #>                      P(Cross) if delta=0.15   0.3636   0.6364 #>                       P(Cross) if delta=0.3   0.9000   0.1000  # now look at a binomial endpoint; specify H0 treatment difference as p1-p2=.05 # now treatment effect at bound (say, thetahat) is transformed to # xp$delta0 + xp$delta1*(thetahat-xp$delta0)/xp$delta np <- nBinomial(p1 = .15, p2 = .10) xp <- gsDesign(n.fix = np, endpoint = \"Binomial\", delta1 = .05) summary(xp) #> [1] \"Asymmetric two-sided group sequential design with non-binding futility bound, 3 analyses, sample size 1963, 90 percent power, 2.5 percent (1-sided) Type I error. Efficacy bounds derived using a Hwang-Shih-DeCani spending function with gamma = -4. Futility bounds derived using a Hwang-Shih-DeCani spending function with gamma = -2.\" gsBoundSummary(xp, deltaname = \"p[C]-p[E]\") #>   Analysis                      Value Efficacy Futility #>  IA 1: 33%                          Z   3.0107  -0.2387 #>     N: 655                p (1-sided)   0.0013   0.5943 #>                   ~p[C]-p[E] at bound   0.0778  -0.0062 #>               P(Cross) if p[C]-p[E]=0   0.0013   0.4057 #>            P(Cross) if p[C]-p[E]=0.05   0.1412   0.0148 #>  IA 2: 67%                          Z   2.5465   0.9411 #>    N: 1309                p (1-sided)   0.0054   0.1733 #>                   ~p[C]-p[E] at bound   0.0465   0.0172 #>               P(Cross) if p[C]-p[E]=0   0.0062   0.8347 #>            P(Cross) if p[C]-p[E]=0.05   0.5815   0.0437 #>      Final                          Z   1.9992   1.9992 #>    N: 1963                p (1-sided)   0.0228   0.0228 #>                   ~p[C]-p[E] at bound   0.0298   0.0298 #>               P(Cross) if p[C]-p[E]=0   0.0233   0.9767 #>            P(Cross) if p[C]-p[E]=0.05   0.9000   0.1000 # estimate treatment effect at lower bound # by setting delta0=0 (default) and delta1 above in gsDesign # treatment effect at bounds is scaled to these differences # in this case, this is the difference in event rates gsDelta(z = xp$lower$bound, i = 1:3, xp) #> [1] -0.006166098  0.017187789  0.029813687  # binomial endpoint with risk ratio estimates n.fix <- nBinomial(p1 = .3, p2 = .15, scale = \"RR\") xrr <- gsDesign(k = 2, n.fix = n.fix, delta1 = log(.15 / .3), endpoint = \"Binomial\") gsBoundSummary(xrr, deltaname = \"RR\", logdelta = TRUE) #>   Analysis              Value Efficacy Futility #>  IA 1: 50%                  Z   2.7500   0.4122 #>     N: 168        p (1-sided)   0.0030   0.3401 #>                  ~RR at bound   0.4429   0.8851 #>              P(Cross) if RR=1   0.0030   0.6599 #>            P(Cross) if RR=0.5   0.3412   0.0269 #>      Final                  Z   1.9811   1.9811 #>     N: 336        p (1-sided)   0.0238   0.0238 #>                  ~RR at bound   0.6605   0.6605 #>              P(Cross) if RR=1   0.0239   0.9761 #>            P(Cross) if RR=0.5   0.9000   0.1000 gsRR(z = xp$lower$bound, i = 1:3, xrr) #> [1] 1.0732500 0.8211496        NA plot(xrr, plottype = \"RR\")   # delta is odds-ratio: sample size slightly smaller than for relative risk or risk difference n.fix <- nBinomial(p1 = .3, p2 = .15, scale = \"OR\") xOR <- gsDesign(k = 2, n.fix = n.fix, delta1 = log(.15 / .3 / .85 * .7), endpoint = \"Binomial\") gsBoundSummary(xOR, deltaname = \"OR\", logdelta = TRUE) #>   Analysis               Value Efficacy Futility #>  IA 1: 50%                   Z   2.7500   0.4122 #>     N: 166         p (1-sided)   0.0030   0.3401 #>                   ~OR at bound   0.3526   0.8553 #>               P(Cross) if OR=1   0.0030   0.6599 #>            P(Cross) if OR=0.41   0.3412   0.0269 #>      Final                   Z   1.9811   1.9811 #>     N: 332         p (1-sided)   0.0238   0.0238 #>                   ~OR at bound   0.5880   0.5880 #>               P(Cross) if OR=1   0.0239   0.9761 #>            P(Cross) if OR=0.41   0.9000   0.1000  # for nice LaTeX table output, use xprint xprint(xtable::xtable(gsBoundSummary(xOR, deltaname = \"OR\", logdelta = TRUE),                                            caption = \"Table caption.\")) #> % latex table generated in R 4.3.1 by xtable 1.8-4 package #> % Wed Jul 19 20:23:50 2023 #> \\begin{table}[ht] #> \\centering #> \\begin{tabular}{llrr} #>   \\hline #> Analysis & Value & Efficacy & Futility \\\\  #>   \\hline #> IA 1: 50\\% & Z & 2.75 & 0.41 \\\\  #>   N: 166 & p (1-sided) & 0.00 & 0.34 \\\\  #>    & \\~{}OR at bound & 0.35 & 0.86 \\\\  #>    & P(Cross) if OR=1 & 0.00 & 0.66 \\\\  #>    & P(Cross) if OR=0.41 & 0.34 & 0.03 \\\\  #>    \\hline #> Final & Z & 1.98 & 1.98 \\\\  #>   N: 332 & p (1-sided) & 0.02 & 0.02 \\\\  #>    & \\~{}OR at bound & 0.59 & 0.59 \\\\  #>    & P(Cross) if OR=1 & 0.02 & 0.98 \\\\  #>    & P(Cross) if OR=0.41 & 0.90 & 0.10 \\\\  #>    \\hline #> \\end{tabular} #> \\caption{Table caption.}  #> \\end{table}"},{"path":"https://keaven.github.io/gsDesign/reference/gsCP.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","title":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","text":"gsCP() computes conditional boundary crossing probabilities future planned analyses given group sequential design assuming interim z-statistic specified interim analysis. gsCP() designed toward computing conditional power variety underlying parameter values, condPower built compute conditional power variety interim test statistic values useful sample size adaptation (see ssrCP). gsPP() averages conditional power across posterior distribution compute predictive power. gsPI() computes Bayesian prediction intervals future analyses corresponding results produced gsPP().  gsPosterior() computes posterior density group sequential design parameter interest given prior density interim outcome exact interval. gsPOS() computes probability success trial using prior distribution average power set theta values interest. gsCPOS() assumes boundary crossed including interim analysis interest, computes probability success based event. Note gsCP() gsPP() take interim test statistic account computing conditional probabilities, gsCPOS() conditions crossing bound specified interim analysis. See Conditional power section manual clarification. See also Muller Schaffer (2001) background theory. gsPP(), gsPI(), gsPOS() gsCPOS(), prior distribution standardized parameter theta () group sequential design specified gsDesign object specified arguments theta wgts. can discrete continuous probability density function. discrete function, generally weights 1. continuous density, wgts contain integration grid weights, provided normalGrid. gsPosterior, prior distribution prior must composed vectors z density.  vector z contains points prior evaluated density corresponding density , discrete distribution, probabilities point z. Densities may supplied normalGrid() grid weights numerical integration supplied gridwgts. gridwgts supplied, defaulted 1 (equal weighting). ensure proper prior distribution, must sum(gridwgts * density) equal 1; checked, however.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsCP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","text":"","code":"gsCP(x, theta = NULL, i = 1, zi = 0, r = 18)  gsPP(   x,   i = 1,   zi = 0,   theta = c(0, 3),   wgts = c(0.5, 0.5),   r = 18,   total = TRUE )  gsPI(   x,   i = 1,   zi = 0,   j = 2,   level = 0.95,   theta = c(0, 3),   wgts = c(0.5, 0.5) )  gsPosterior(x = gsDesign(), i = 1, zi = NULL, prior = normalGrid(), r = 18)  gsPOS(x, theta, wgts)  gsCPOS(i, x, theta, wgts)"},{"path":"https://keaven.github.io/gsDesign/reference/gsCP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","text":"x object type gsDesign gsProbability theta vector \\(\\theta\\) value(s) conditional power computed; gsCP() NULL, estimated value \\(\\theta\\) based interim test statistic (zi/sqrt(x$n.[])) well x$theta computed. gsPosterior, may scalar interval; gsPP gsCP, must scalar. analysis interim z-value given; must 1 x$k-1 zi interim z-value analysis (scalar) r Integer value controlling grid numerical integration Jennison Turnbull (2000); default 18, range 1 80.  Larger values provide larger number grid points greater accuracy.  Normally r changed user. wgts Weights used grid points theta. Length can one weights equal, otherwise length theta. Values positive, need sum 1. total default total=TRUE produces combined probability planned analyses interim analysis specified . Otherwise, information analysis provided separately. j specific analysis prediction made; must >x$k level level used Bayes credible intervals (approach confidence intervals vague priors). default level=.95 corresponds 95% credible interval. level=0 provides point estimate rather interval. prior provides prior distribution form produced normalGrid","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsCP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","text":"gsCP() returns object class gsProbability. Based input design interim test statistic, output gsDesign object bounds test statistics computed based solely observations interim .  Boundary crossing probabilities computed input \\(\\theta\\) values. See manual examples. gsPP() total==TRUE, returns real value indicating predictive power trial conditional interim test statistic zi analysis ; otherwise returns vector predictive power future planned analysis. gsPI() returns interval (point estimate level=0) indicating 100level% credible interval z-statistic analysis j conditional z-statistic analysis <j. interval consider intervending interim analyses. probability estimate based predictive distribution used gsPP() requires prior distribution group sequential parameter theta specified theta wgts. gsPosterior() returns posterior distribution containing vector z input prior$z, posterior density density, grid weights integrating posterior density input prior$gridwgts defaulted vector ones, product output values density gridwgts wgts. gsPOS() returns real value indicating probability positive study weighted prior distribution input theta. gsCPOS() returns real value indicating probability positive study weighted posterior distribution derived interim test statistic prior distribution input theta conditional interim test statistic.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsCP.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsCP.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Proschan, Michael ., Lan, KK Gordon Wittes, Janet Turk (2006), Statistical Monitoring Clinical Trials. NY: Springer. Muller, Hans-Helge Schaffer, Helmut (2001), Adaptive group sequential designs clinical trials: combining advantages adaptive classical group sequential approaches. Biometrics;57:886-891.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsCP.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsCP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional and Predictive Power, Overall and Conditional Probability of Success — gsCP","text":"","code":"library(ggplot2) # set up a group sequential design x <- gsDesign(k = 5) x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.220 -0.90    0.1836 0.0077 3.25    0.0006  0.0006 #>          2  0.441 -0.04    0.4853 0.0115 2.99    0.0014  0.0013 #>          3  0.661  0.69    0.7563 0.0171 2.69    0.0036  0.0028 #>          4  0.881  1.36    0.9131 0.0256 2.37    0.0088  0.0063 #>          5  1.101  2.03    0.9786 0.0381 2.03    0.0214  0.0140 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Hwang-Shih-DeCani spending function with gamma = -2. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4      5  Total   E{N} #>   0.0000 0.0006 0.0013 0.0028 0.0062 0.0117 0.0226 0.5726 #>   3.2415 0.0417 0.1679 0.2806 0.2654 0.1444 0.9000 0.7440 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4      5  Total #>   0.0000 0.1836 0.3201 0.2700 0.1477 0.0559 0.9774 #>   3.2415 0.0077 0.0115 0.0171 0.0256 0.0381 0.1000  # set up a prior distribution for the treatment effect # that is normal with mean .75*x$delta and standard deviation x$delta/2 mu0 <- .75 * x$delta sigma0 <- x$delta / 2 prior <- normalGrid(mu = mu0, sigma = sigma0)  # compute POS for the design given the above prior distribution for theta gsPOS(x = x, theta = prior$z, wgts = prior$wgts) #> [1] 0.5954771  # assume POS should only count cases in prior where theta >= x$delta/2 gsPOS(x = x, theta = prior$z, wgts = prior$wgts * (prior$z >= x$delta / 2)) #> [1] 0.5554313  # assuming a z-value at lower bound at analysis 2, what are conditional # boundary crossing probabilities for future analyses # assuming theta values from x as well as a value based on the interim # observed z CP <- gsCP(x, i = 2, zi = x$lower$bound[2]) CP #>               Lower bounds   Upper bounds #>   Analysis N   Z   Nominal p  Z   Nominal p #>          1  1 1.25    0.8952 4.71    0.0000 #>          2  1 1.96    0.9750 3.39    0.0003 #>          3  1 2.64    0.9959 2.64    0.0041 #>  #> Boundary crossing probabilities and expected sample size assume #> any cross stops the trial #>  #> Upper boundary #>           Analysis #>     Theta     1      2      3  Total E{N} #>   -0.0554 0e+00 0.0003 0.0019 0.0022  0.2 #>    0.0000 0e+00 0.0003 0.0022 0.0026  0.2 #>    3.2415 7e-04 0.1038 0.2631 0.3677  0.4 #>  #> Lower boundary #>           Analysis #>     Theta      1      2      3  Total #>   -0.0554 0.8999 0.0841 0.0138 0.9978 #>    0.0000 0.8952 0.0872 0.0150 0.9974 #>    3.2415 0.3950 0.1368 0.1006 0.6323  # summing values for crossing future upper bounds gives overall # conditional power for each theta value CP$theta #> [1] -0.05536767  0.00000000  3.24151555 t(CP$upper$prob) %*% c(1, 1, 1) #>             [,1] #> [1,] 0.002238566 #> [2,] 0.002561570 #> [3,] 0.367657693  # compute predictive probability based on above assumptions gsPP(x, i = 2, zi = x$lower$bound[2], theta = prior$z, wgts = prior$wgts) #> [1] 0.06730167  # if it is known that boundary not crossed at interim 2, use # gsCPOS to compute conditional POS based on this gsCPOS(x = x, i = 2, theta = prior$z, wgts = prior$wgts) #> [1] 0.6114033  # 2-stage example to compare results to direct computation x <- gsDesign(k = 2) z1 <- 0.5 n1 <- x$n.I[1] n2 <- x$n.I[2] - x$n.I[1] thetahat <- z1 / sqrt(n1) theta <- c(thetahat, 0, x$delta)  # conditional power direct computation - comparison w gsCP pnorm((n2 * theta + z1 * sqrt(n1) - x$upper$bound[2] * sqrt(n1 + n2)) / sqrt(n2)) #> [1] 0.03579292 0.01067483 0.51555676  gsCP(x = x, zi = z1, i = 1)$upper$prob #>            [,1]       [,2]      [,3] #> [1,] 0.03579292 0.01067483 0.5155568  # predictive power direct computation - comparison w gsPP # use same prior as above mu0 <- .75 * x$delta * sqrt(x$n.I[2]) sigma2 <- (.5 * x$delta)^2 * x$n.I[2] prior <- normalGrid(mu = .75 * x$delta, sigma = x$delta / 2) gsPP(x = x, zi = z1, i = 1, theta = prior$z, wgts = prior$wgts) #> [1] 0.1556447 t <- .5 z1 <- .5 b <- z1 * sqrt(t) # direct from Proschan, Lan and Wittes eqn 3.10 # adjusted drift at n.I[2] pnorm(((b - x$upper$bound[2]) * (1 + t * sigma2) +   (1 - t) * (mu0 + b * sigma2)) /   sqrt((1 - t) * (1 + sigma2) * (1 + t * sigma2))) #> [1] 0.1556447  # plot prior then posterior distribution for unblinded analysis with i=1, zi=1 xp <- gsPosterior(x = x, i = 1, zi = 1, prior = prior) plot(x = xp$z, y = xp$density, type = \"l\", col = 2, xlab = expression(theta), ylab = \"Density\") points(x = x$z, y = x$density, col = 1)  # add posterior plot assuming only knowlede that interim bound has # not been crossed at interim 1 xpb <- gsPosterior(x = x, i = 1, zi = 1, prior = prior) lines(x = xpb$z, y = xpb$density, col = 4)   # prediction interval based in interim 1 results # start with point estimate, followed by 90% prediction interval gsPI(x = x, i = 1, zi = z1, j = 2, theta = prior$z, wgts = prior$wgts, level = 0) #> [1] 1.081745 gsPI(x = x, i = 1, zi = z1, j = 2, theta = prior$z, wgts = prior$wgts, level = .9) #> [1] -0.3793133  2.5428090"},{"path":"https://keaven.github.io/gsDesign/reference/gsDensity.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design interim density function — gsDensity","title":"Group sequential design interim density function — gsDensity","text":"Given interim analysis group sequential design vector real values zi, gsDensity() computes interim density function analysis values zi.  value zi, interim density derivative probability group sequential trial cross boundary prior -th analysis -th analysis interim Z-statistic less value. integrated real line, density computes probability crossing bound previous analysis. corresponds subdistribution function analysis excludes probability crossing bound earlier analysis. initial purpose routine component needed compute predictive power trial given interim result; see gsPP. See Jennison Turnbull (2000) details computations performed.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDensity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design interim density function — gsDensity","text":"","code":"gsDensity(x, theta = 0, i = 1, zi = 0, r = 18)"},{"path":"https://keaven.github.io/gsDesign/reference/gsDensity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design interim density function — gsDensity","text":"x object type gsDesign gsProbability theta vector \\(\\theta\\) value(s) interim density function computed. analysis interim z-values given; must 1 x$k zi interim z-value analysis (scalar) r Integer value controlling grid numerical integration Jennison Turnbull (2000); default 18, range 1 80.  Larger values provide larger number grid points greater accuracy.  Normally r changed user.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDensity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group sequential design interim density function — gsDensity","text":"zi input vector zi. theta input vector theta. density matrix length(zi) rows length(theta) columns.  subdensity function z[j], theta[m] analysis returned density[j,m].","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDensity.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Group sequential design interim density function — gsDensity","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDensity.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Group sequential design interim density function — gsDensity","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsDensity.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Group sequential design interim density function — gsDensity","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDensity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design interim density function — gsDensity","text":"","code":"library(ggplot2) # set up a group sequential design x <- gsDesign()  # set theta values where density is to be evaluated theta <- x$theta[2] * c(0, .5, 1, 1.5)  # set zi values from -1 to 7 where density is to be evaluated zi <- seq(-3, 7, .05)  # compute subdensity values at analysis 2 y <- gsDensity(x, theta = theta, i = 2, zi = zi)  # plot sub-density function for each theta value plot(y$zi, y$density[, 3],   type = \"l\", xlab = \"Z\",   ylab = \"Interim 2 density\", lty = 3, lwd = 2 ) lines(y$zi, y$density[, 2], lty = 2, lwd = 2) lines(y$zi, y$density[, 1], lwd = 2) lines(y$zi, y$density[, 4], lty = 4, lwd = 2) title(\"Sub-density functions at interim analysis 2\") legend(   x = c(3.85, 7.2), y = c(.27, .385), lty = 1:5, lwd = 2, cex = 1.5,   legend = c(     expression(paste(theta, \"=0.0\")),     expression(paste(theta, \"=0.5\", delta)),     expression(paste(theta, \"=1.0\", delta)),     expression(paste(theta, \"=1.5\", delta))   ) )  # add vertical lines with lower and upper bounds at analysis 2 # to demonstrate how likely it is to continue, stop for futility # or stop for efficacy at analysis 2 by treatment effect lines(rep(x$upper$bound[2], 2), c(0, .4), col = 2) lines(rep(x$lower$bound[2], 2), c(0, .4), lty = 2, col = 2)   # Replicate part of figures 8.1 and 8.2 of Jennison and Turnbull text book # O'Brien-Fleming design with four analyses  x <- gsDesign(k = 4, test.type = 2, sfu = \"OF\", alpha = .1, beta = .2)  z <- seq(-4.2, 4.2, .05) d <- gsDensity(x = x, theta = x$theta, i = 4, zi = z)  plot(z, d$density[, 1], type = \"l\", lwd = 2, ylab = expression(paste(p[4], \"(z,\", theta, \")\"))) lines(z, d$density[, 2], lty = 2, lwd = 2) u <- x$upper$bound[4] text(expression(paste(theta, \"=\", delta)), x = 2.2, y = .2, cex = 1.5) text(expression(paste(theta, \"=0\")), x = .55, y = .4, cex = 1.5)"},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign-package-overview.html","id":null,"dir":"Reference","previous_headings":"","what":"1.0 Group Sequential Design — gsDesign package overview","title":"1.0 Group Sequential Design — gsDesign package overview","text":"gsDesign package deriving describing group sequential designs. package allows particular flexibility designs alpha- beta-spending. Many plots available describing design properties.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign-package-overview.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"1.0 Group Sequential Design — gsDesign package overview","text":"Index: gsDesign package supports group sequential clinical trial design.  strong focus designs using \\(\\alpha\\)- \\(\\beta\\)-spending functions, Wang-Tsiatis designs, including O'Brien-Fleming Pocock designs, also available. ability design non-binding futility rules allows control Type error manner acceptable regulatory authorities futility bounds employed. routines designed provide simple access commonly used designs using default arguments.  Standard, published spending functions supported well ability write custom spending functions.  gsDesign class defined returned gsDesign() function.  plot function class provides wide variety plots: boundaries, power, estimated treatment effect boundaries, conditional power boundaries, spending function plots, expected sample size plot, B-values boundaries. Using function calls access package routines provides powerful capability derive designs output formatting anticipated gui interface.  enables user easily create designs features desire, designs minimum expected sample size. Thus, intent gsDesign package easily create, fully characterize even optimize routine group sequential trial designs well provide tool evaluate innovative designs.","code":"gsDesign 2.1: Design Derivation gsProbability 2.2: Boundary Crossing Probabilities plot.gsDesign 2.3: Plots for group sequential designs gsCP 2.4: Conditional Power Computation gsBoundCP 2.5: Conditional Power at Interim Boundaries gsbound 2.6: Boundary derivation - low level normalGrid 3.1: Normal Density Grid binomial 3.2: Testing, Confidence Intervals and Sample Size for Comparing Two Binomial Rates Survival sample size 3.3: Time-to-event sample size calculation (Lachin-Foulkes) Spending function overview 4.0: Spending functions sfHSD 4.1: Hwang-Shih-DeCani Spending Function sfPower 4.2: Kim-DeMets (power) Spending Function sfExponential 4.3: Exponential Spending Function sfLDPocock 4.4: Lan-DeMets Spending function overview sfPoints 4.5: Pointwise Spending Function sfLogistic 4.6: 2-parameter Spending Function Families sfTDist 4.7: t-distribution Spending Function Wang-Tsiatis Bounds 5.0: Wang-Tsiatis Bounds checkScalar 6.0: Utility functions to verify variable properties"},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign-package-overview.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"1.0 Group Sequential Design — gsDesign package overview","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Proschan, MA, Lan, KKG, Wittes, JT (2006), Statistical Monitoring Clinical Trials. Unified Approach.  New York: Springer.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign-package-overview.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"1.0 Group Sequential Design — gsDesign package overview","text":"Keaven Anderson Maintainer: Keaven Anderson <keaven_anderson@merck.com>","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign-package-overview.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1.0 Group Sequential Design — gsDesign package overview","text":"","code":"library(ggplot2) # assume a fixed design (no interim) trial with the same endpoint # requires 200 subjects for 90% power at alpha=.025, one-sided x <- gsDesign(n.fix=200) plot(x)"},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Design Derivation — gsDesign","title":"Design Derivation — gsDesign","text":"gsDesign() used find boundaries trial size required group sequential design. Many parameters normally take default values thus require explicit specification. One- two-sided designs supported. Two-sided designs may symmetric asymmetric. Wang-Tsiatis designs, including O'Brien-Fleming Pocock designs can generated. Designs common spending functions well built-user-specified functions Type error futility supported. Type error computations asymmetric designs may assume binding non-binding lower bounds. print function extended using print.gsDesign() print gsDesign objects; see examples. user may ignore structure value returned gsDesign() standard printing plotting suffice; see examples. delta n.fix used together determine sample size output options user seeks. default, delta=0 n.fix=1, results ‘generic’ design may used sampling situation. Sample size ratios provided user multiplies times sample size fixed design obtain corresponding group sequential analysis times. delta>0, n.fix ignored, delta taken standardized effect size - signal noise ratio single observation; example, mean divided standard deviation one-sample normal problem.  case, sample size analysis computed.  delta=0 n.fix>1, n.fix assumed sample size fixed design interim analyses. See examples . Following comments input argument test.type used control type error measurements used trial design. manual may also worth review order see actual formulas boundary crossing probabilities various options.  Options 3 5 assume trial stops lower bound crossed Type Type II error computation (binding lower bound).  purpose computing Type error, options 4 6 assume trial continues lower bound crossed (non-binding lower bound); Type error can made crossing upper bound crossing previous lower bound. Beta-spending refers error spending lower bound crossing probabilities alternative hypothesis (options 3 4). case, final analysis lower upper boundaries assumed . appropriate total beta spending (power) determined adjusting maximum sample size iterative process options. Since options 3 4 must compute boundary crossing probabilities null alternative hypotheses, deriving designs can take longer options. Options 5 6 compute lower bound spending null hypothesis.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Design Derivation — gsDesign","text":"","code":"gsDesign(   k = 3,   test.type = 4,   alpha = 0.025,   beta = 0.1,   astar = 0,   delta = 0,   n.fix = 1,   timing = 1,   sfu = sfHSD,   sfupar = -4,   sfl = sfHSD,   sflpar = -2,   tol = 1e-06,   r = 18,   n.I = 0,   maxn.IPlan = 0,   nFixSurv = 0,   endpoint = NULL,   delta1 = 1,   delta0 = 0,   overrun = 0,   usTime = NULL,   lsTime = NULL )  # S3 method for gsDesign xtable(   x,   caption = NULL,   label = NULL,   align = NULL,   digits = NULL,   display = NULL,   ... )"},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Design Derivation — gsDesign","text":"k Number analyses planned, including interim final. test.type 1=one-sided 2=two-sided symmetric 3=two-sided, asymmetric, beta-spending binding lower bound 4=two-sided, asymmetric, beta-spending non-binding lower bound 5=two-sided, asymmetric, lower bound spending null hypothesis binding lower bound 6=two-sided, asymmetric, lower bound spending null hypothesis non-binding lower bound.  See details, examples manual. alpha Type error, always one-sided. Default value 0.025. beta Type II error, default value 0.1 (90% power). astar Normally specified. test.type=5 6, astar specifies total probability crossing lower bound analyses combined.  changed \\(1 - \\)alpha default value 0 used.  Since expected usage, normally astar specified user. delta Effect size theta alternative hypothesis. can set standardized effect size generate sample size n.fix=NULL. See details examples. n.fix Sample size fixed design interim; used find maximum group sequential sample size. time--event outcome, input number events required fixed design rather sample size enter fixed design sample size (optional) nFixSurv.  See details examples. timing Sets relative timing interim analyses. Default 1 produces equally spaced analyses.  Otherwise, vector length k k-1.  values satisfy 0 < timing[1] < timing[2] < ... < timing[k-1] < timing[k]=1. sfu spending function character string indicating boundary type (, “WT” Wang-Tsiatis bounds, “” O'Brien-Fleming bounds “Pocock” Pocock bounds).  one-sided symmetric two-sided testing used completely specify spending (test.type=1, 2), sfu.  default value sfHSD Hwang-Shih-DeCani spending function.  See details, Spending_Function_Overview, manual examples. sfupar Real value, default \\(-4\\) O'Brien-Fleming-like conservative bound used default Hwang-Shih-DeCani spending function. real-vector many spending functions.  parameter sfupar specifies parameters needed spending function specified sfu; ignored spending functions (sfLDOF, sfLDPocock) bound types (“”, “Pocock”) require parameters. sfl Specifies spending function lower boundary crossing probabilities asymmetric, two-sided testing performed (test.type = 3, 4, 5, 6).  Unlike upper bound, spending functions used specify lower bound.  default value sfHSD Hwang-Shih-DeCani spending function.  parameter sfl ignored one-sided testing (test.type=1) symmetric 2-sided testing (test.type=2).  See details, spending functions, manual examples. sflpar Real value, default \\(-2\\), , default Hwang-Shih-DeCani spending function, specifies less conservative spending rate default upper bound. tol Tolerance error (default 0.000001). Normally changed user.  translate directly number digits accuracy, use extra decimal places. r Integer value controlling grid numerical integration Jennison Turnbull (2000); default 18, range 1 80.  Larger values provide larger number grid points greater accuracy.  Normally r changed user. n.Used re-setting bounds timing analyses changes initial design; see examples. maxn.IPlan Used re-setting bounds timing analyses changes initial design; see examples. nFixSurv time--event variable used, nFixSurv computed sample size nSurvival may entered gsDesign compute total sample size required well number events analysis returned n.fix; rounded even number. endpoint optional character string represent type endpoint used study. may used output functions. Types likely recognized initially \"TTE\" time--event outcomes fixed design sample size generated nSurvival() \"Binomial\" 2-sample binomial outcomes fixed design sample size generated nBinomial(). delta1 delta1 delta0 may used store information natural parameter scale compared delta standardized effect size. delta1 alternative hypothesis parameter value natural parameter scale (e.g., difference two binomial rates). delta0 delta0 null hypothesis parameter value natural parameter scale. overrun Scalar vector length k-1 patients enrolled included interim analysis. usTime Default NULL case upper bound spending time  determined timing. Otherwise, vector length  k spending time analysis (see Details). lsTime Default NULL case lower bound spending time  determined timing. Otherwise, vector length  k spending time analysis (see Details). x R object class found among methods(xtable).  See     write additional method functions xtable. caption Character vector length 1 2 containing     table's caption title.  length 2, second item     \"short caption\" used LaTeX generates \"List Tables\". Set     NULL suppress caption.  Default value NULL. label Character vector length 1 containing LaTeX label     HTML anchor. Set NULL suppress label.  Default     value NULL. align Character vector length equal number columns     resulting table, indicating alignment corresponding     columns.  Also, \"|\" may used produce vertical lines     columns LaTeX tables, effectively ignored     considering required length supplied vector.      character vector length one supplied, split     strsplit(align, \"\")[[1]] processing. Since row     names printed first column, length align     one greater ncol(x) x     data.frame. Use \"l\", \"r\", \"c\"     denote left, right, center alignment, respectively.  Use     \"p{3cm}\" etc. LaTeX column specified width.     HTML output \"p\" alignment interpreted \"l\",     ignoring width request. Default depends class     x. digits Numeric vector length equal one (case     replicated necessary) number columns     resulting table matrix size resulting     table, indicating number digits display     corresponding columns. Since row names printed first     column, length vector digits number     columns matrix digits one greater     ncol(x) x data.frame. Default depends     class x. values digits negative,     corresponding values x displayed scientific format     abs(digits) digits. display Character vector length equal number columns     resulting table, indicating format corresponding columns.     Since row names printed first column, length     display one greater ncol(x) x     data.frame.  values passed formatC     function.  Use \"d\" (integers), \"f\", \"e\",     \"E\", \"g\", \"G\", \"fg\" (reals),     \"s\" (strings).  \"f\" gives numbers usual     xxx.xxx format; \"e\" \"E\" give     n.ddde+nn n.dddE+nn (scientific format); \"g\"     \"G\" put x[] scientific format     saves space .  \"fg\" uses fixed format \"f\",     digits number significant digits.  Note     can lead quite long result strings.  Default depends     class x. ... Additional arguments.  (Currently ignored.)","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Design Derivation — gsDesign","text":"object class gsDesign. class following elements upon return gsDesign() contains: k input. test.type input. alpha input. beta input. astar input, except test.type=5 6 astar input 0; case astar changed 1-alpha. delta standardized effect size design powered. input gsDesign() unless input 0; case, value computed give desired power fixed design input sample size n.fix. n.fix Sample size required obtain desired power effect size delta. timing vector length k containing portion total planned information sample size analysis. tol input. r input. n.Vector length k. values input, values output. Otherwise, n.contain sample size required analysis achieve desired timing beta output value delta.  delta=0 input, sample size required specified group sequential design fixed design requires sample size n.fix. delta=0 n.fix=1 relative sample size compared fixed design; see details examples. maxn.IPlan input. nFixSurv input. nSurv Sample size Lachin Foulkes method nSurvival used fixed design input. nSurvival used compute n.fix, nFixSurv inflated amount n.fix stored nSurv. Note use gsSurv time--event sample size, needed complete output summary given. endpoint input. delta1 input. delta0 input. overrun input. usTime input. lsTime input. upper Upper bound spending function, boundary boundary crossing probabilities NULL alternate hypotheses. See Spending_Function_Overview manual details. lower Lower bound spending function, boundary boundary crossing probabilities analysis. Lower spending alternative hypothesis (beta spending) test.type=3 4.  test.type=2, 5 6, lower spending null hypothesis. test.type=1, output value NULL. See Spending_Function_Overview manual. theta Standarized effect size null (0) alternate hypothesis. delta input, theta[1]=delta. n.fix input, theta[1] computed using standard sample size formula (pseudocode): ((Zalpha+Zbeta)/theta[1])^2=n.fix. falseprobnb test.type=4 6, contains false positive probabilities null hypothesis assuming crossing futility bound stop trial. en Expected sample size accounting early stopping. time--event outcomes, expected number events (although gsSurv give expected sample size). information-based-design, give expected information trial stops. overrun specified, expected sample size includes overrun interim. object class \"xtable\" attributes specifying formatting options table","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Design Derivation — gsDesign","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Design Derivation — gsDesign","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Lan KK, DeMets DL (1989). Group sequential procedures: calendar versus information  time. Statistics medicine 8(10):1191-8. Liu, Q, Lim, P, Nuamah, , Li, Y (2012), adaptive error spending approach  group sequential trials random information levels. Journal biopharmaceutical statistics; 22(4), 687-699.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Design Derivation — gsDesign","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsDesign.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Design Derivation — gsDesign","text":"","code":"library(ggplot2) #  symmetric, 2-sided design with O'Brien-Fleming-like boundaries #  lower bound is non-binding (ignored in Type I error computation) #  sample size is computed based on a fixed design requiring n=800 x <- gsDesign(k = 5, test.type = 2, n.fix = 800)  # note that \"x\" below is equivalent to print(x) and print.gsDesign(x) x #> Symmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Spending computations assume trial stops #> if a bound is crossed. #>  #>                #>   Analysis  N   Z   Nominal p  Spend #>          1 164 3.25    0.0006 0.0006 #>          2 328 2.99    0.0014 0.0013 #>          3 492 2.69    0.0036 0.0028 #>          4 656 2.37    0.0088 0.0063 #>          5 819 2.03    0.0214 0.0140 #>      Total                    0.0250  #>  #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4      5 Total  E{N} #>   0.0000 0.0006 0.0013 0.0028 0.0063 0.0140 0.025 812.8 #>   0.1146 0.0370 0.1512 0.2647 0.2699 0.1771 0.900 589.3 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta     1      2      3      4     5 Total #>   0.0000 6e-04 0.0013 0.0028 0.0063 0.014 0.025 #>   0.1146 0e+00 0.0000 0.0000 0.0000 0.000 0.000 plot(x)  plot(x, plottype = 2) #> Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in #> dplyr 1.1.0. #> ℹ Please use `reframe()` instead. #> ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()` #>   always returns an ungrouped data frame and adjust accordingly. #> ℹ The deprecated feature was likely used in the gsDesign package. #>   Please report the issue at <https://github.com/keaven/gsDesign/issues>.   # Assuming after trial was designed actual analyses occurred after # 300, 600, and 860 patients, reset bounds y <- gsDesign(   k = 3, test.type = 2, n.fix = 800, n.I = c(300, 600, 860),   maxn.IPlan = x$n.I[x$k] ) y #> Symmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Spending computations assume trial stops #> if a bound is crossed. #>  #>                #>   Analysis  N   Z   Nominal p  Spend #>          1 300 2.96    0.0016 0.0016 #>          2 600 2.44    0.0074 0.0067 #>          3 860 2.01    0.0220 0.0167 #>      Total                    0.0250  #>  #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3  Total  E{N} #>   0.0000 0.0016 0.0067 0.0167 0.0250 854.8 #>   0.1146 0.1655 0.4833 0.2654 0.9142 641.6 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3 Total #>   0.0000 0.0016 0.0067 0.0167 0.025 #>   0.1146 0.0000 0.0000 0.0000 0.000  #  asymmetric design with user-specified spending that is non-binding #  sample size is computed relative to a fixed design with n=1000 sfup <- c(.033333, .063367, .1) sflp <- c(.25, .5, .75) timing <- c(.1, .4, .7) x <- gsDesign(   k = 4, timing = timing, sfu = sfPoints, sfupar = sfup, sfl = sfPoints,   sflpar = sflp, n.fix = 1000 ) x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>                   ----Lower bounds----  ----Upper bounds----- #>   Analysis   N    Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  123 -0.83    0.2041  0.025 3.14    0.0008  0.0008 #>          2  489  0.39    0.6513  0.025 3.16    0.0008  0.0008 #>          3  855  1.26    0.8966  0.025 3.06    0.0011  0.0009 #>          4 1222  1.98    0.9761  0.025 1.98    0.0239  0.0225 #>      Total                      0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  User-specified spending function with Points = 0.25 0.5 0.75 1. #> ++ alpha spending: #>  User-specified spending function with Points = 0.033333 0.063367 0.1 1. #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4  Total  E{N} #>   0.0000 0.0008 0.0007 0.0009 0.0177 0.0202 564.0 #>   0.1025 0.0222 0.1716 0.2969 0.4094 0.9000 907.4 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4  Total #>   0.0000 0.2041 0.4703 0.2361 0.0693 0.9798 #>   0.1025 0.0250 0.0250 0.0250 0.0250 0.1000 plot(x)  plot(x, plottype = 2)   # same design, but with relative sample sizes gsDesign(   k = 4, timing = timing, sfu = sfPoints, sfupar = sfup, sfl = sfPoints,   sflpar = sflp ) #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.122 -0.83    0.2041  0.025 3.14    0.0008  0.0008 #>          2  0.488  0.39    0.6513  0.025 3.16    0.0008  0.0008 #>          3  0.855  1.26    0.8966  0.025 3.06    0.0011  0.0009 #>          4  1.221  1.98    0.9761  0.025 1.98    0.0239  0.0225 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  User-specified spending function with Points = 0.25 0.5 0.75 1. #> ++ alpha spending: #>  User-specified spending function with Points = 0.033333 0.063367 0.1 1. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4  Total   E{N} #>   0.0000 0.0008 0.0007 0.0009 0.0177 0.0202 0.5640 #>   3.2415 0.0222 0.1716 0.2969 0.4094 0.9000 0.9074 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4  Total #>   0.0000 0.2041 0.4703 0.2361 0.0693 0.9798 #>   3.2415 0.0250 0.0250 0.0250 0.0250 0.1000"},{"path":"https://keaven.github.io/gsDesign/reference/gsProbability.html","id":null,"dir":"Reference","previous_headings":"","what":"Boundary Crossing Probabilities — gsProbability","title":"Boundary Crossing Probabilities — gsProbability","text":"Computes power/Type error expected sample size group sequential design across selected set parameter values given set analyses boundaries. print function extended using print.gsProbability print gsProbability objects; see examples. Depending calling sequence, object class gsProbability class gsDesign returned. class gsDesign members object described gsDesign. d input NULL (default), arguments (r) must specified object class gsProbability returned. d passed object class gsProbability gsDesign argument required theta; object returned class input d. output, values theta input gsProbability parameter values design characterized.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsProbability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Boundary Crossing Probabilities — gsProbability","text":"","code":"gsProbability(k = 0, theta, n.I, a, b, r = 18, d = NULL, overrun = 0)  # S3 method for gsProbability print(x, ...)"},{"path":"https://keaven.github.io/gsDesign/reference/gsProbability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boundary Crossing Probabilities — gsProbability","text":"k Number analyses planned, including interim final. theta Vector standardized effect sizes boundary crossing probabilities computed. n.Sample size relative sample size analyses; vector length k. See gsDesign manual. Lower bound cutoffs (z-values) futility harm analysis, vector length k. b Upper bound cutoffs (z-values) futility analysis; vector length k. r Control grid Jennison Turnbull (2000); default 18, range 1 80.  Normally changed user. d NULL, object type gsDesign returned call gsDesign().  specified, values k, n., , b, r obtained d theta needs specified user. overrun Scalar vector length k-1 patients enrolled included interim analysis. x item class gsProbability. ... implemented (compatibility generic print input).","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsProbability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Boundary Crossing Probabilities — gsProbability","text":"k input. theta input. n.input. lower list containing two elements: bound input prob matrix boundary crossing probabilities. Element ,j contains boundary crossing probability analysis j-th element theta input. boundary crossing assumed binding computation; , trial must stop boundary crossed. upper list form lower containing upper bound upper boundary crossing probabilities. en vector length theta containing expected sample sizes trial design corresponding value vector theta. r input. Note: print.gsProbability() returns input x.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsProbability.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Boundary Crossing Probabilities — gsProbability","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsProbability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Boundary Crossing Probabilities — gsProbability","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/gsProbability.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Boundary Crossing Probabilities — gsProbability","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/gsProbability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Boundary Crossing Probabilities — gsProbability","text":"","code":"library(ggplot2) # making a gsDesign object first may be easiest... x <- gsDesign()  # take a look at it x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.357 -0.24    0.4057 0.0148 3.01    0.0013  0.0013 #>          2  0.713  0.94    0.8267 0.0289 2.55    0.0054  0.0049 #>          3  1.070  2.00    0.9772 0.0563 2.00    0.0228  0.0188 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Hwang-Shih-DeCani spending function with gamma = -2. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3  Total   E{N} #>   0.0000 0.0013 0.0049 0.0171 0.0233 0.6249 #>   3.2415 0.1412 0.4403 0.3185 0.9000 0.7913 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3  Total #>   0.0000 0.4057 0.4290 0.1420 0.9767 #>   3.2415 0.0148 0.0289 0.0563 0.1000  # default plot for gsDesign object shows boundaries plot(x)   # \\code{plottype=2} shows boundary crossing probabilities plot(x, plottype = 2)   # now add boundary crossing probabilities and # expected sample size for more theta values y <- gsProbability(d = x, theta = x$delta * seq(0, 2, .25)) class(y) #> [1] \"gsDesign\"  # note that \"y\" below is equivalent to \\code{print(y)} and # \\code{print.gsProbability(y)} y #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.357 -0.24    0.4057 0.0148 3.01    0.0013  0.0013 #>          2  0.713  0.94    0.8267 0.0289 2.55    0.0054  0.0049 #>          3  1.070  2.00    0.9772 0.0563 2.00    0.0228  0.0188 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Hwang-Shih-DeCani spending function with gamma = -2. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3  Total   E{N} #>   0.0000 0.0013 0.0049 0.0171 0.0233 0.6249 #>   0.8104 0.0058 0.0279 0.0872 0.1209 0.7523 #>   1.6208 0.0205 0.1038 0.2393 0.3636 0.8520 #>   2.4311 0.0595 0.2579 0.3636 0.6810 0.8668 #>   3.2415 0.1412 0.4403 0.3185 0.9000 0.7913 #>   4.0519 0.2773 0.5353 0.1684 0.9810 0.6765 #>   4.8623 0.4574 0.4844 0.0559 0.9976 0.5701 #>   5.6727 0.6469 0.3410 0.0119 0.9998 0.4868 #>   6.4830 0.8053 0.1930 0.0016 1.0000 0.4266 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3  Total #>   0.0000 0.4057 0.4290 0.1420 0.9767 #>   0.8104 0.2349 0.3812 0.2630 0.8791 #>   1.6208 0.1138 0.2385 0.2841 0.6364 #>   2.4311 0.0455 0.1017 0.1718 0.3190 #>   3.2415 0.0148 0.0289 0.0563 0.1000 #>   4.0519 0.0039 0.0054 0.0097 0.0190 #>   4.8623 0.0008 0.0006 0.0009 0.0024 #>   5.6727 0.0001 0.0001 0.0000 0.0002 #>   6.4830 0.0000 0.0000 0.0000 0.0000  # the plot does not change from before since this is a # gsDesign object; note that theta/delta is on x axis plot(y, plottype = 2)   # now let's see what happens with a gsProbability object z <- gsProbability(   k = 3, a = x$lower$bound, b = x$upper$bound,   n.I = x$n.I, theta = x$delta * seq(0, 2, .25) )  # with the above form,  the results is a gsProbability object class(z) #> [1] \"gsProbability\" z #>               Lower bounds   Upper bounds #>   Analysis N    Z   Nominal p  Z   Nominal p #>          1  1 -0.24    0.4057 3.01    0.0013 #>          2  1  0.94    0.8267 2.55    0.0054 #>          3  2  2.00    0.9772 2.00    0.0228 #>  #> Boundary crossing probabilities and expected sample size assume #> any cross stops the trial #>  #> Upper boundary #>           Analysis #>    Theta      1      2      3  Total E{N} #>   0.0000 0.0013 0.0049 0.0171 0.0233  0.6 #>   0.8104 0.0058 0.0279 0.0872 0.1209  0.8 #>   1.6208 0.0205 0.1038 0.2393 0.3636  0.9 #>   2.4311 0.0595 0.2579 0.3636 0.6810  0.9 #>   3.2415 0.1412 0.4403 0.3185 0.9000  0.8 #>   4.0519 0.2773 0.5353 0.1684 0.9810  0.7 #>   4.8623 0.4574 0.4844 0.0559 0.9976  0.6 #>   5.6727 0.6469 0.3410 0.0119 0.9998  0.5 #>   6.4830 0.8053 0.1930 0.0016 1.0000  0.4 #>  #> Lower boundary #>           Analysis #>    Theta      1      2      3  Total #>   0.0000 0.4057 0.4290 0.1420 0.9767 #>   0.8104 0.2349 0.3812 0.2630 0.8791 #>   1.6208 0.1138 0.2385 0.2841 0.6364 #>   2.4311 0.0455 0.1017 0.1718 0.3190 #>   3.2415 0.0148 0.0289 0.0563 0.1000 #>   4.0519 0.0039 0.0054 0.0097 0.0190 #>   4.8623 0.0008 0.0006 0.0009 0.0024 #>   5.6727 0.0001 0.0001 0.0000 0.0002 #>   6.4830 0.0000 0.0000 0.0000 0.0000  # default plottype is now 2 # this is the same range for theta, but plot now has theta on x axis plot(z)"},{"path":"https://keaven.github.io/gsDesign/reference/hGraph.html","id":null,"dir":"Reference","previous_headings":"","what":"Create multiplicity graphs using ggplot2 — hGraph","title":"Create multiplicity graphs using ggplot2 — hGraph","text":"hGraph() plots multiplicity graph defined user inputs. graph can also used **gMCPLite** package evaluate set nominal p-values tests hypotheses graph","code":""},{"path":"https://keaven.github.io/gsDesign/reference/hGraph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create multiplicity graphs using ggplot2 — hGraph","text":"","code":"hGraph(   nHypotheses = 4,   nameHypotheses = paste(\"H\", (1:nHypotheses), sep = \"\"),   alphaHypotheses = 0.025/nHypotheses,   m = matrix(array(1/(nHypotheses - 1), nHypotheses^2), nrow = nHypotheses) -     diag(1/(nHypotheses - 1), nHypotheses),   fill = 1,   palette = grDevices::gray.colors(length(unique(fill)), start = 0.5, end = 0.8),   labels = LETTERS[1:length(unique(fill))],   legend.name = \" \",   legend.position = \"none\",   halfWid = 0.5,   halfHgt = 0.5,   trhw = 0.1,   trhh = 0.075,   trprop = 1/3,   digits = 5,   trdigits = 2,   size = 6,   boxtextsize = 4,   arrowsize = 0.02,   radianStart = if ((nHypotheses)%%2 != 0) {      pi * (1/2 + 1/nHypotheses)  } else {          pi * (1 + 2/nHypotheses)/2  },   offset = pi/4/nHypotheses,   xradius = 2,   yradius = xradius,   x = NULL,   y = NULL,   wchar = if (as.character(Sys.info()[1]) == \"Windows\") {      \"w\"  } else {      \"w\"  } )"},{"path":"https://keaven.github.io/gsDesign/reference/hGraph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create multiplicity graphs using ggplot2 — hGraph","text":"nHypotheses number hypotheses graph nameHypotheses hypothesis names alphaHypotheses alpha-levels weights ellipses m square transition matrix dimension `nHypotheses` fill grouping variable hypotheses palette colors groups labels text labels groups legend.name text legend header legend.position text string x,y coordinates legend halfWid half width ellipses halfHgt half height ellipses trhw transition box width trhh transition box height trprop proportion transition arrow length transition box placed digits number digits show alphaHypotheses trdigits digits displayed transition weights size text size ellipses boxtextsize transition text size arrowsize size arrowhead transition arrows radianStart radians origin first ellipse; nodes spaced equally clockwise order centers ellipse default offset rotational offset radians transition weight arrows xradius horizontal ellipse diameter ellipses drawn yradius vertical ellipse diameter ellipses drawn x x coordinates hypothesis ellipses elliptical arrangement wanted y y coordinates hypothesis ellipses elliptical arrangement wanted wchar character alphaHypotheses ellipses","code":""},{"path":"https://keaven.github.io/gsDesign/reference/hGraph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create multiplicity graphs using ggplot2 — hGraph","text":"`ggplot` object multi-layer multiplicity graph","code":""},{"path":"https://keaven.github.io/gsDesign/reference/hGraph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create multiplicity graphs using ggplot2 — hGraph","text":"See vignette **Multiplicity graphs formatting using ggplot2** explanation formatting.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/hGraph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create multiplicity graphs using ggplot2 — hGraph","text":"","code":"# 'gsDesign::hGraph' is deprecated. # See the examples in 'gMCPLite::hGraph' instead."},{"path":"https://keaven.github.io/gsDesign/reference/nNormal.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal distribution sample size (2-sample) — nNormal","title":"Normal distribution sample size (2-sample) — nNormal","text":"nNormal() computes fixed design sample size comparing 2 means variance known. T function allows computation sample size non-inferiority hypothesis. Note may wish investigate  R packages pwr package uses t-distribution. examples show set 2-arm group sequential design normal outcome. nNormal() computes sample size comparing two normal means variance observations ","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nNormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal distribution sample size (2-sample) — nNormal","text":"","code":"nNormal(   delta1 = 1,   sd = 1.7,   sd2 = NULL,   alpha = 0.025,   beta = 0.1,   ratio = 1,   sided = 1,   n = NULL,   delta0 = 0,   outtype = 1 )"},{"path":"https://keaven.github.io/gsDesign/reference/nNormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal distribution sample size (2-sample) — nNormal","text":"delta1 difference sample means alternate hypothesis. sd Standard deviation control arm. sd2 Standard deviation experimental arm; set control arm default NULL. alpha type error rate. Default 0.025 since 1-sided testing default. beta type II error rate. Default 0.10 (90% power). needed n provided. ratio randomization ratio experimental group compared control. sided 1 1-sided test (default), 2 2-sided test. n Sample size; may input compute power rather sample size. NULL (default) sample size computed. delta0 difference sample means null hypothesis; normally left default 0. outtype controls output; see value section .","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nNormal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal distribution sample size (2-sample) — nNormal","text":"n NULL (default), total sample size (2 arms combined) computed. Otherwise, power computed. outtype=1 (default), computed value (sample size power) returned scalar vector. outtype=2, data frame sample sizes arm (n1, n2)returned; n input NULL, third variable, Power, added output data frame. outtype=3, data frame returned following columns: n vector total samples size required event rate comparison specified n1 vector sample sizes group 1 event rate comparison specified n2 vector sample sizes group 2 event rate comparison specified alpha input sided input beta input; n input, computed Power n=NULL input, 1-beta; otherwise, power computed sample size input sd input sd2 input delta1 input delta0 input se standard error estimate difference treatment group means","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nNormal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normal distribution sample size (2-sample) — nNormal","text":"convenience routine one recommended broad use without careful considerations outlined Jennison Turnbull (2000). larger studies conservative estimate within group standard deviations available, can useful. detailed formulation available vignette two-sample normal sample size.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nNormal.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Normal distribution sample size (2-sample) — nNormal","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Lachin JM (1981), Introduction sample size determination power analysis clinical trials. Controlled Clinical Trials 2:93-113. Snedecor GW Cochran WG (1989), Statistical Methods. 8th ed. Ames, IA: Iowa State University Press.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/nNormal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Normal distribution sample size (2-sample) — nNormal","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nNormal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal distribution sample size (2-sample) — nNormal","text":"","code":"# EXAMPLES # equal variances n=nNormal(delta1=.5,sd=1.1,alpha=.025,beta=.2) n #> [1] 151.9543 x <- gsDesign(k = 3, n.fix = n, test.type = 4, alpha = 0.025, beta = 0.1, timing = c(.5,.75), sfu = sfLDOF, sfl = sfHSD, sflpar = -1, delta1 = 0.5, endpoint = 'normal')  gsBoundSummary(x) #>   Analysis                 Value Efficacy Futility #>  IA 1: 50%                     Z   2.9626   0.6475 #>      N: 86           p (1-sided)   0.0015   0.2587 #>                  ~delta at bound   0.6109   0.1335 #>              P(Cross) if delta=0   0.0015   0.7413 #>            P(Cross) if delta=0.5   0.2954   0.0378 #>  IA 2: 75%                     Z   2.3590   1.3115 #>     N: 128           p (1-sided)   0.0092   0.0948 #>                  ~delta at bound   0.3972   0.2208 #>              P(Cross) if delta=0   0.0096   0.9155 #>            P(Cross) if delta=0.5   0.7309   0.0650 #>      Final                     Z   2.0141   2.0141 #>     N: 171           p (1-sided)   0.0220   0.0220 #>                  ~delta at bound   0.2937   0.2937 #>              P(Cross) if delta=0   0.0219   0.9781 #>            P(Cross) if delta=0.5   0.9000   0.1000 summary(x) #> [1] \"Asymmetric two-sided group sequential design with non-binding futility bound, 3 analyses, sample size 171, 90 percent power, 2.5 percent (1-sided) Type I error. Efficacy bounds derived using a Lan-DeMets O'Brien-Fleming approximation spending function with none = 1. Futility bounds derived using a Hwang-Shih-DeCani spending function with gamma = -1.\" # unequal variances, fixed design nNormal(delta1 = .5, sd = 1.1, sd2 = 2, alpha = .025, beta = .2) #> [1] 327.1413 # unequal sample sizes nNormal(delta1 = .5, sd = 1.1, alpha = .025, beta = .2, ratio = 2) #> [1] 170.9486 # non-inferiority assuming a better effect than null nNormal(delta1 = .5, delta0 = -.1, sd = 1.2) #> [1] 168.1188"},{"path":"https://keaven.github.io/gsDesign/reference/nSurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Advanced time-to-event sample size calculation — print.nSurv","title":"Advanced time-to-event sample size calculation — print.nSurv","text":"nSurv() used calculate sample size clinical trial time--event endpoint assumption proportional hazards. set routines new version 2.7 continue modified refined improve input error checking output format subsequent versions. allows Lachin Foulkes (1986) method (fixed trial duration) well Kim Tsiatis(1990) method (fixed enrollment rates either fixed enrollment duration fixed minimum follow-). Piecewise exponential survival supported well piecewise constant enrollment dropout rates. methods 2-arm trial treatment groups referred experimental control. stratified population allowed Lachin Foulkes (1986); method extended derive non-inferiority well superiority trials. Stratification also allows power calculation meta-analyses. gsSurv() combines nSurv() gsDesign() derive group sequential design study time--event endpoint.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Advanced time-to-event sample size calculation — print.nSurv","text":"","code":"# S3 method for nSurv print(x, digits = 4, ...)  nSurv(   lambdaC = log(2)/6,   hr = 0.6,   hr0 = 1,   eta = 0,   etaE = NULL,   gamma = 1,   R = 12,   S = NULL,   T = NULL,   minfup = NULL,   ratio = 1,   alpha = 0.025,   beta = 0.1,   sided = 1,   tol = .Machine$double.eps^0.25 )  tEventsIA(x, timing = 0.25, tol = .Machine$double.eps^0.25)  nEventsIA(tIA = 5, x = NULL, target = 0, simple = TRUE)  gsSurv(   k = 3,   test.type = 4,   alpha = 0.025,   sided = 1,   beta = 0.1,   astar = 0,   timing = 1,   sfu = sfHSD,   sfupar = -4,   sfl = sfHSD,   sflpar = -2,   r = 18,   lambdaC = log(2)/6,   hr = 0.6,   hr0 = 1,   eta = 0,   etaE = NULL,   gamma = 1,   R = 12,   S = NULL,   T = NULL,   minfup = NULL,   ratio = 1,   tol = .Machine$double.eps^0.25,   usTime = NULL,   lsTime = NULL )  # S3 method for gsSurv print(x, digits = 2, ...)  # S3 method for gsSurv xtable(   x,   caption = NULL,   label = NULL,   align = NULL,   digits = NULL,   display = NULL,   auto = FALSE,   footnote = NULL,   fnwid = \"9cm\",   timename = \"months\",   ... )"},{"path":"https://keaven.github.io/gsDesign/reference/nSurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Advanced time-to-event sample size calculation — print.nSurv","text":"x object class nSurv gsSurv. print.nSurv() used object class nSurv generally output nSurv(). print.gsSurv() used object class gsSurv generally output gsSurv(). nEventsIA tEventsIA operate nSurv gsSurv class. digits Number digits past decimal place print (print.gsSurv.); also pass generic xtable() xtable.gsSurv(). ... arguments may passed generic functions underlying methods . lambdaC scalar, vector matrix event hazard rates control group; rows represent time periods columns represent strata; vector implies single stratum. hr hazard ratio (experimental/control) alternate hypothesis (scalar). hr0 hazard ratio (experimental/control) null hypothesis (scalar). eta scalar, vector matrix dropout hazard rates control group; rows represent time periods columns represent strata; entered scalar, rate constant across strata time periods; entered vector, rates constant across strata. etaE matrix dropout hazard rates experimental group specified like form eta; NULL, set equal eta. gamma scalar, vector matrix rates entry time period (rows) strata (columns); entered scalar, rate constant across strata time periods; entered vector, rates constant across strata. R scalar vector durations time periods recruitment rates specified rows gamma. Length number rows gamma. Note variable enrollment duration specified (input T=NULL), final enrollment period extended long needed. S scalar vector durations piecewise constant event rates specified rows lambda, eta etaE; NULL single event rate per stratum (exponential failure) length number rows lambda minus 1, otherwise. T study duration; T input NULL, computed output; see details. minfup follow-last patient enrolled; minfup input NULL, computed output; see details. ratio randomization ratio experimental treatment divided control; normally scalar, may vector length equal number strata. alpha type error rate. Default 0.025 since 1-sided testing default. beta type II error rate. Default 0.10 (90% power); NULL power computed based input values. sided 1 1-sided testing, 2 2-sided testing. tol cases T minfup values derived root finding (T minfup input NULL), tol provides level error input uniroot() root-finding function. default uniroot. timing Sets relative timing interim analyses gsSurv. Default 1 produces equally spaced analyses.  Otherwise, vector length k k-1.  values satisfy 0 < timing[1] < timing[2] < ... < timing[k-1] < timing[k]=1. tEventsIA, scalar strictly 0 1 indicates targeted proportion final planned events available interim analysis. tIA Timing interim analysis; 0 y$T. target targeted proportion events interim analysis. used root-finding 0 normal use. simple See output specification nEventsIA(). k Number analyses planned, including interim final. test.type 1=one-sided 2=two-sided symmetric 3=two-sided, asymmetric, beta-spending binding lower bound 4=two-sided, asymmetric, beta-spending non-binding lower bound 5=two-sided, asymmetric, lower bound spending null hypothesis binding lower bound 6=two-sided, asymmetric, lower bound spending null hypothesis non-binding lower bound.  See details, examples manual. astar Normally specified. test.type=5 6, astar specifies total probability crossing lower bound analyses combined.  changed \\(1 - \\)alpha default value 0 used.  Since expected usage, normally astar specified user. sfu spending function character string indicating boundary type (, “WT” Wang-Tsiatis bounds, “” O'Brien-Fleming bounds “Pocock” Pocock bounds).  one-sided symmetric two-sided testing used completely specify spending (test.type=1, 2), sfu.  default value sfHSD Hwang-Shih-DeCani spending function.  See details, Spending_Function_Overview, manual examples. sfupar Real value, default \\(-4\\) O'Brien-Fleming-like conservative bound used default Hwang-Shih-DeCani spending function. real-vector many spending functions.  parameter sfupar specifies parameters needed spending function specified sfu; ignored spending functions (sfLDOF, sfLDPocock) bound types (“”, “Pocock”) require parameters. sfl Specifies spending function lower boundary crossing probabilities asymmetric, two-sided testing performed (test.type = 3, 4, 5, 6).  Unlike upper bound, spending functions used specify lower bound.  default value sfHSD Hwang-Shih-DeCani spending function.  parameter sfl ignored one-sided testing (test.type=1) symmetric 2-sided testing (test.type=2).  See details, spending functions, manual examples. sflpar Real value, default \\(-2\\), , default Hwang-Shih-DeCani spending function, specifies less conservative spending rate default upper bound. r Integer value controlling grid numerical integration Jennison Turnbull (2000); default 18, range 1 80. Larger values provide larger number grid points greater accuracy.  Normally r changed user. usTime Default NULL case upper bound spending time determined timing. Otherwise, vector length codek spending time analysis (see Details help gsDesign). lsTime Default NULL case lower bound spending time determined timing. Otherwise, vector length k spending time analysis (see Details help gsDesign). caption passed generic xtable(). label passed generic xtable(). align passed generic xtable(). display passed generic xtable(). auto passed generic xtable(). footnote footnote xtable output; may useful describing design parameters. fnwid text string controlling width footnote text bottom xtable output. timename character string plural time units (e.g., \"months\")","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Advanced time-to-event sample size calculation — print.nSurv","text":"nSurv() returns object type nSurv following components: alpha input. sided input. beta Type II error; missing, computed. power Power corresponding input beta computed output beta computed. lambdaC input. etaC input. etaE input. gamma input unless none following NULL: T, minfup, beta; otherwise, constant times input value required power trial given input variables. ratio input. R input unless T NULL input. S input. T input. minfup input. hr input. hr0 input. n Total expected sample size corresponding output accrual rates durations. d Total expected number events alternate hypothesis. tol input, except used computations case returned NULL.  remaining output printed print() extension nSurv class. eDC vector expected number events stratum control group alternate hypothesis. eDE vector expected number events stratum experimental group alternate hypothesis. eDC0 vector expected number events stratum control group null hypothesis. eDE0 vector expected number events stratum experimental group null hypothesis. eNC vector expected accrual stratum control group. eNE vector expected accrual stratum experimental group. variable text string equal \"Accrual rate\" design derived varying accrual rate, \"Accrual duration\" design derived varying accrual duration, \"Follow-duration\" design derived varying follow-duration, \"Power\" accrual rates duration well follow-duration specified beta=NULL input. gsSurv() returns much plus variables class gsDesign; see gsDesign general documentation returned gs.  value gs$n.represents number endpoints required analysis adequately power trial. items returned gsSurv() : lambdaC input. etaC input. etaE input. gamma input unless none following NULL: T, minfup, beta; otherwise, constant times input value required power trial given input variables. ratio input. R input unless T NULL input. S input. T input. minfup input. hr input. hr0 input. eNC Total expected sample size corresponding output accrual rates durations. eNE Total expected sample size corresponding output accrual rates durations. eDC Total expected number events alternate hypothesis. eDE Total expected number events alternate hypothesis. tol input, except used computations case returned NULL.  remaining output printed print() extension nSurv class. eDC vector expected number events stratum control group alternate hypothesis. eDE vector expected number events stratum experimental group alternate hypothesis. eNC vector expected accrual stratum control group. eNE vector expected accrual stratum experimental group. variable text string equal \"Accrual rate\" design derived varying accrual rate, \"Accrual duration\" design derived varying accrual duration, \"Follow-duration\" design derived varying follow-duration, \"Power\" accrual rates duration well follow-duration specified beta=NULL input. nEventsIA() returns expected proportion final planned events observed input analysis time minus target simple=TRUE. simple=FALSE, nEventsIA returns list following components: T input value tIA. eDC expected number events control group time output time T. eDE expected number events experimental group output time T. eNC expected enrollment control group output time T. eNE expected enrollment experimental group output time T. tEventsIA() returns structure nEventsIA(..., simple=TRUE) ","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Advanced time-to-event sample size calculation — print.nSurv","text":"print(), xtable() summary() methods provided operate returned value gsSurv(), object class gsSurv. print() also extended nSurv objects. functions gsBoundSummary (data frame tabular output), xprint (application xtable tabular output) summary.gsSurv (textual summary gsDesign gsSurv object) may preferred summary functions; see example vignettes. See also gsBoundSummary output tabular summaries bounds designs produced gsSurv(). nEventsIA tEventsIA require group sequential design time--event endpoint class gsSurv input. nEventsIA calculates expected number events alternate hypothesis given interim time. tEventsIA calculates time expected number events alternate hypothesis given proportion total events planned final analysis. nSurv() produces object class nSurv number subjects events set pre-specified trial parameters, accrual duration follow-period. underlying power calculation based Lachin Foulkes (1986) method proportional hazards assuming fixed underlying hazard ratio 2 treatment groups. method extended enable designs test non-inferiority. Piecewise constant enrollment failure rates assumed stratified population allowed. See also nSurvival Lachin Foulkes (1986) methods assuming constant hazard difference exponential enrollment rate. study duration (T) follow-duration (minfup) fixed, nSurv applies exactly Lachin Foulkes (1986) method computing sample size proportional hazards assumption computation, enrollment rates altered proportionately input gamma achieve power interest. Given specified enrollment rate(s) input gamma, nSurv may also used derive enrollment duration required trial defined power T input NULL; case, R (enrollment duration specified enrollment rate) T (study duration) computed output. Alternatively also using fixed enrollment rate(s) gamma, minimum follow-minfup specified NULL, enrollment duration(s) specified R considered fixed minfup T computed derive desired power. method fail specified enrollment rates durations either -powers trial additional follow-underpowers trial infinite follow-. method produces corresponding error message cases. input gsSurv combination input nSurv() gsDesign(). nEventsIA() provided compute expected number events given point time given enrollment, event censoring rates. routine used root finding routine approximate approximate timing interim analysis. also used extend enrollment follow-fixed design obtain sufficient number events power group sequential design.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Advanced time-to-event sample size calculation — print.nSurv","text":"Kim KM Tsiatis AA (1990), Study duration clinical trials survival response early stopping rule. Biometrics, 46, 81-92 Lachin JM Foulkes MA (1986), Evaluation Sample Size Power Analyses Survival Allowance Nonuniform Patient Entry, Losses Follow-, Noncompliance, Stratification. Biometrics, 42, 507-519. Schoenfeld D (1981), Asymptotic Properties Nonparametric Tests Comparing Survival Distributions. Biometrika, 68, 316-319.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/nSurv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Advanced time-to-event sample size calculation — print.nSurv","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Advanced time-to-event sample size calculation — print.nSurv","text":"","code":"# vary accrual rate to obtain power nSurv(lambdaC = log(2) / 6, hr = .5, eta = log(2) / 40, gamma = 1, T = 36, minfup = 12) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Accrual rate  #> Hazard ratio                  H1/H0=0.5/1 #> Study duration:                   T=36 #> Accrual duration:                   24 #> Min. end-of-study follow-up: minfup=12 #> Expected events (total, H1):        86.3258 #> Expected sample size (total):       119.8184 #> Accrual rates: #>      Stratum 1 #> 0-24    4.9924 #> Control event rates (H1): #>       Stratum 1 #> 0-Inf    0.1155 #> Censoring rates: #>       Stratum 1 #> 0-Inf    0.0173 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1  # vary accrual duration to obtain power nSurv(lambdaC = log(2) / 6, hr = .5, eta = log(2) / 40, gamma = 6, minfup = 12) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Accrual duration  #> Hazard ratio                  H1/H0=0.5/1 #> Study duration:                   T=32.3089 #> Accrual duration:                   20.3089 #> Min. end-of-study follow-up: minfup=12 #> Expected events (total, H1):        86.3627 #> Expected sample size (total):       121.8535 #> Accrual rates: #>         Stratum 1 #> 0-20.31         6 #> Control event rates (H1): #>       Stratum 1 #> 0-Inf    0.1155 #> Censoring rates: #>       Stratum 1 #> 0-Inf    0.0173 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1  # vary follow-up duration to obtain power nSurv(lambdaC = log(2) / 6, hr = .5, eta = log(2) / 40, gamma = 6, R = 25) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Follow-up duration  #> Hazard ratio                  H1/H0=0.5/1 #> Study duration:                   T=27.2508 #> Accrual duration:                   25 #> Min. end-of-study follow-up: minfup=2.2508 #> Expected events (total, H1):        86.8927 #> Expected sample size (total):       150 #> Accrual rates: #>      Stratum 1 #> 0-25         6 #> Control event rates (H1): #>       Stratum 1 #> 0-Inf    0.1155 #> Censoring rates: #>       Stratum 1 #> 0-Inf    0.0173 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1  # piecewise constant enrollment rates (vary accrual duration) nSurv(   lambdaC = log(2) / 6, hr = .5, eta = log(2) / 40, gamma = c(1, 3, 6),   R = c(3, 6, 9), minfup = 12 ) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Accrual duration  #> Hazard ratio                  H1/H0=0.5/1 #> Study duration:                   T=37.7809 #> Accrual duration:                   25.7809 #> Min. end-of-study follow-up: minfup=12 #> Expected events (total, H1):        86.3632 #> Expected sample size (total):       121.6855 #> Accrual rates: #>         Stratum 1 #> 0-3             1 #> 3-9             3 #> 9-25.78         6 #> Control event rates (H1): #>       Stratum 1 #> 0-Inf    0.1155 #> Censoring rates: #>       Stratum 1 #> 0-Inf    0.0173 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1  # stratified population (vary accrual duration) nSurv(   lambdaC = matrix(log(2) / c(6, 12), ncol = 2), hr = .5, eta = log(2) / 40,   gamma = matrix(c(2, 4), ncol = 2), minfup = 12 ) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Accrual duration  #> Hazard ratio                  H1/H0=0.5/1 #> Study duration:                   T=36.6817 #> Accrual duration:                   24.6817 #> Min. end-of-study follow-up: minfup=12 #> Expected events (total, H1):        86.8976 #> Expected sample size (total):       148.09 #> Accrual rates: #>         Stratum 1 Stratum 2 #> 0-24.68         2         4 #> Control event rates (H1): #>       Stratum 1 Stratum 2 #> 0-Inf    0.1155    0.0578 #> Censoring rates: #>       Stratum 1 Stratum 2 #> 0-Inf    0.0173    0.0173 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1  # piecewise exponential failure rates (vary accrual duration) nSurv(lambdaC = log(2) / c(6, 12), hr = .5, eta = log(2) / 40, S = 3, gamma = 6, minfup = 12) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Accrual duration  #> Hazard ratio                  H1/H0=0.5/1 #> Study duration:                   T=37.3655 #> Accrual duration:                   25.3655 #> Min. end-of-study follow-up: minfup=12 #> Expected events (total, H1):        87.1347 #> Expected sample size (total):       152.1929 #> Accrual rates: #>         Stratum 1 #> 0-25.37         6 #> Control event rates (H1): #>       Stratum 1 #> 0-3      0.1155 #> 3-Inf    0.0578 #> Censoring rates: #>       Stratum 1 #> 0-3      0.0173 #> 3-Inf    0.0173 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1  # combine it all: 2 strata, 2 failure rate periods nSurv(   lambdaC = matrix(log(2) / c(6, 12, 18, 24), ncol = 2), hr = .5,   eta = matrix(log(2) / c(40, 50, 45, 55), ncol = 2), S = 3,   gamma = matrix(c(3, 6, 5, 7), ncol = 2), R = c(5, 10), minfup = 12 ) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Accrual duration  #> Hazard ratio                  H1/H0=0.5/1 #> Study duration:                   T=30.097 #> Accrual duration:                   18.097 #> Min. end-of-study follow-up: minfup=12 #> Expected events (total, H1):        88.0958 #> Expected sample size (total):       210.2612 #> Accrual rates: #>        Stratum 1 Stratum 2 #> 0-5            3         5 #> 5-18.1         6         7 #> Control event rates (H1): #>       Stratum 1 Stratum 2 #> 0-3      0.1155    0.0385 #> 3-Inf    0.0578    0.0289 #> Censoring rates: #>       Stratum 1 Stratum 2 #> 0-3      0.0173    0.0154 #> 3-Inf    0.0139    0.0126 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1  # example where only 1 month of follow-up is desired # set failure rate to 0 after 1 month using lambdaC and S nSurv(lambdaC = c(.4, 0), hr = 2 / 3, S = 1, minfup = 1) #> Fixed design, two-arm trial with time-to-event #> outcome (Lachin and Foulkes, 1986). #> Solving for:  Accrual duration  #> Hazard ratio                  H1/H0=0.6667/1 #> Study duration:                   T=915.4375 #> Accrual duration:                   914.4375 #> Min. end-of-study follow-up: minfup=1 #> Expected events (total, H1):        257.7578 #> Expected sample size (total):       914.4375 #> Accrual rates: #>          Stratum 1 #> 0-914.44         1 #> Control event rates (H1): #>       Stratum 1 #> 0-1         0.4 #> 1-Inf       0.0 #> Censoring rates: #>       Stratum 1 #> 0-1           0 #> 1-Inf         0 #> Power:                 100*(1-beta)=90% #> Type I error (1-sided):   100*alpha=2.5% #> Equal randomization:          ratio=1  # group sequential design (vary accrual rate to obtain power) x <- gsSurv(   k = 4, sfl = sfPower, sflpar = .5, lambdaC = log(2) / 6, hr = .5,   eta = log(2) / 40, gamma = 1, T = 36, minfup = 12 ) x #> Time to event group sequential design with HR= 0.5  #> Equal randomization:          ratio=1 #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>                 ----Lower bounds----  ----Upper bounds----- #>   Analysis  N   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  29 0.23    0.5895 0.0500 3.16    0.0008  0.0008 #>          2  58 0.86    0.8056 0.0207 2.82    0.0024  0.0022 #>          3  87 1.46    0.9277 0.0159 2.44    0.0074  0.0059 #>          4 116 2.01    0.9780 0.0134 2.01    0.0220  0.0161 #>      Total                    0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Kim-DeMets (power) spending function with rho = 0.5. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4  Total E{N} #>   0.0000 0.0008 0.0022 0.0055 0.0102 0.0187 46.5 #>   0.3489 0.0995 0.3393 0.3388 0.1224 0.9000 71.2 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4  Total #>   0.0000 0.5895 0.2470 0.1079 0.0369 0.9813 #>   0.3489 0.0500 0.0207 0.0159 0.0134 0.1000 #>              T         n    Events HR futility HR efficacy #> IA 1  12.24228  81.46723  28.76662       0.919       0.308 #> IA 2  18.97078 126.24254  57.53321       0.797       0.476 #> IA 3  25.02728 159.70989  86.29984       0.730       0.591 #> Final 36.00000 159.70989 115.06648       0.687       0.687 #> Accrual rates: #>      Stratum 1 #> 0-24      6.65 #> Control event rates (H1): #>       Stratum 1 #> 0-Inf      0.12 #> Censoring rates: #>       Stratum 1 #> 0-Inf      0.02 print(xtable::xtable(x,   footnote = \"This is a footnote; note that it can be wide.\",   caption = \"Caption example.\" )) #> % latex table generated in R 4.3.1 by xtable 1.8-4 package #> % Wed Jul 19 20:23:59 2023 #> \\begin{table}[ht] #> \\centering #> \\begin{tabular}{rllll} #>   \\hline #>  & Analysis & Value & Futility & Efficacy \\\\  #>   \\hline #> 1 & IA 1: 25$\\backslash$\\% & Z-value & 0.23 & 3.16 \\\\  #>   2 & N: 82 & HR & 0.92 & 0.31 \\\\  #>   3 & Events: 29 & p (1-sided) & 0.4105 & 8e-04 \\\\  #>   4 & 12.2 months & P$\\backslash$\\{Cross$\\backslash$\\} if HR=1 & 0.5895 & 8e-04 \\\\  #>   5 &   & P$\\backslash$\\{Cross$\\backslash$\\} if HR=0.5 & 0.05 & 0.0995 \\\\  #>   6 & $\\backslash$hline IA 2: 50$\\backslash$\\% & Z-value & 0.86 & 2.82 \\\\  #>   7 & N: 128 & HR & 0.8 & 0.48 \\\\  #>   8 & Events: 58 & p (1-sided) & 0.1944 & 0.0024 \\\\  #>   9 & 19 months & P$\\backslash$\\{Cross$\\backslash$\\} if HR=1 & 0.8366 & 0.003 \\\\  #>   10 &   & P$\\backslash$\\{Cross$\\backslash$\\} if HR=0.5 & 0.0707 & 0.4388 \\\\  #>   11 & $\\backslash$hline IA 3: 75$\\backslash$\\% & Z-value & 1.46 & 2.44 \\\\  #>   12 & N: 160 & HR & 0.73 & 0.59 \\\\  #>   13 & Events: 87 & p (1-sided) & 0.0723 & 0.0074 \\\\  #>   14 & 25 months & P$\\backslash$\\{Cross$\\backslash$\\} if HR=1 & 0.9445 & 0.0085 \\\\  #>   15 &   & P$\\backslash$\\{Cross$\\backslash$\\} if HR=0.5 & 0.0866 & 0.7776 \\\\  #>   16 & $\\backslash$hline Final analysis & Z-value & 2.01 & 2.01 \\\\  #>   17 & N: 160 & HR & 0.69 & 0.69 \\\\  #>   18 & Events: 116 & p (1-sided) & 0.022 & 0.022 \\\\  #>   19 & 36 months & P$\\backslash$\\{Cross$\\backslash$\\} if HR=1 & 0.9813 & 0.0187 \\\\  #>   20 &   & P$\\backslash$\\{Cross$\\backslash$\\} if HR=0.5 & 0.1 & 0.9 $\\backslash$$\\backslash$ $\\backslash$hline $\\backslash$multicolumn\\{4\\}\\{p\\{ 9cm \\}\\}\\{$\\backslash$footnotesize This is a footnote; note that it can be wide. \\} \\\\  #>    \\hline #> \\end{tabular} #> \\caption{Caption example.}  #> \\end{table} # find expected number of events at time 12 in the above trial nEventsIA(x = x, tIA = 10) #> [1] 20.51876  # find time at which 1/4 of events are expected tEventsIA(x = x, timing = .25) #> $T #> [1] 12.24228 #>  #> $eDC #> [1] 17.92465 #>  #> $eDE #> [1] 10.84196 #>  #> $eNC #> [1] 40.73361 #>  #> $eNE #> [1] 40.73361 #>"},{"path":"https://keaven.github.io/gsDesign/reference/nSurvival.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-to-event sample size calculation (Lachin-Foulkes) — print.nSurvival","title":"Time-to-event sample size calculation (Lachin-Foulkes) — print.nSurvival","text":"nSurvival() used calculate sample size clinical trial time--event endpoint. Lachin Foulkes (1986) method used. nEvents uses Schoenfeld (1981) approximation provide sample size power terms underlying hazard ratio number events observed survival analysis. functions hrz2n(), hrn2z() zn2hr() also use Schoenfeld approximation provide simple translations hazard ratios, z-values number events analysis; input variables can given vectors. nSurvival() produces object class \"nSurvival\" number subjects events set pre-specified trial parameters, accrual duration follow-period. calculation based Lachin Foulkes (1986) method can used risk ratio risk difference. function also consider non-uniform (exponential) entry well uniform entry. logical approx TRUE, variance alternative hypothesis used replace variance null hypothesis.  non-uniform entry, non-zero value gamma exponential entry must supplied. positive gamma, entry distribution convex, whereas negative gamma, entry distribution concave. nEvents() uses Schoenfeld (1981) method approximate number events n (given beta) power (given n). Arguments may vectors scalars, vectors must length. functions hrz2n, hrn2z zn2hr also apply Schoenfeld approximation proportional hazards modeling.  approximation based asymptotic normal distribtuion logrank statistic well related statistics asymptotically normal.  Let \\(\\lambda\\) denote underlying hazard ratio (lambda1/lambda2 terms arguments nSurvival). , let \\(n\\) denote number events observed computing statistic interest \\(r\\) ratio sample size experimental group relative control. estimated natural logarithm hazard ratio proportional hazards ratio approximately normal mean \\(log{\\lambda}\\) variance \\((1+r)^2/nr\\). Let \\(z\\) denote logrank statistic (Wald statistic score statistic proportional hazards regression model). asymptotic theory implies \\(z\\) asymptotically equivalent normalized estimate hazard ratio \\(\\lambda\\) thus \\(z\\) asymptotically normal variance 1 mean $$\\frac{log{\\lambda}r}{(1+r)^2}.$$ Plugging estimated hazard ratio equation allows approximating one following based two: estimate hazard ratio, number events z-statistic. , $$\\hat{\\lambda}= \\exp(z(1+r)/\\sqrt{rn})$$ $$z=\\log(\\hat{\\lambda})\\sqrt{nr}/(1+r)$$ $$n= (z(1+r)/\\log(\\hat{\\lambda}))^2/r.$$ hrz2n() translates observed interim hazard ratio interim z-value number events required Z-value hazard ratio correspond . hrn2z() translates hazard ratio number events approximate corresponding Z-value. zn2hr() translates Z-value number events approximate corresponding hazard ratio. functions default assumption underlying hazard ratio 1 can changed using argument hr0. hrn2z() zn2hr() also argument hr1 used compute sign computed Z-value case hrn2z() whether z-value > 0 corresponds hazard ratio > < null hazard ratio hr0.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurvival.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-to-event sample size calculation (Lachin-Foulkes) — print.nSurvival","text":"","code":"# S3 method for nSurvival print(x, ...)  nSurvival(   lambda1 = 1/12,   lambda2 = 1/24,   Ts = 24,   Tr = 12,   eta = 0,   ratio = 1,   alpha = 0.025,   beta = 0.1,   sided = 1,   approx = FALSE,   type = c(\"rr\", \"rd\"),   entry = c(\"unif\", \"expo\"),   gamma = NA )  nEvents(   hr = 0.6,   alpha = 0.025,   beta = 0.1,   ratio = 1,   sided = 1,   hr0 = 1,   n = 0,   tbl = FALSE )  zn2hr(z, n, ratio = 1, hr0 = 1, hr1 = 0.7)  hrn2z(hr, n, ratio = 1, hr0 = 1, hr1 = 0.7)  hrz2n(hr, z, ratio = 1, hr0 = 1)"},{"path":"https://keaven.github.io/gsDesign/reference/nSurvival.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time-to-event sample size calculation (Lachin-Foulkes) — print.nSurvival","text":"x object class \"nSurvival\" returned nSurvival() (optional: used output; \"months\" \"years\" 'usual' choices). ... Allows additional arguments print.nSurvival(). lambda1, lambda2 event hazard rate placebo treatment group respectively. Ts maximum study duration. Tr accrual (recruitment) duration. eta equal dropout hazard rate groups. ratio randomization ratio placebo treatment group. Default balanced design, .e., randomization ratio 1. alpha type error rate. Default 0.025 since 1-sided testing default. beta type II error rate. Default 0.10 (90% power). needed nEvents() n provided. sided one two-sided test? Default one-sided test. approx logical. TRUE, approximation sample size formula risk difference used. type type sample size calculation: risk ratio (“rr”) risk difference (“rd”). entry patient entry type: uniform entry (\"unif\") exponential entry (\"expo\"). gamma rate parameter exponential entry. NA entry type \"unif\" (uniform). non-zero value supplied entry type \"expo\" (exponential). hr Hazard ratio. nEvents, hazard ratio alternative hypothesis (>0). hr0 Hazard ratio null hypothesis (>0, nEvents, != hr). n Number events. nEvents may input compute power rather sample size. tbl Indicator whether scalar (vector) tabular output desired nEvents(). z z-statistic. hr1 Hazard ratio alternate hypothesis hrn2z, zn2hr (>0, != hr0)","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurvival.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Time-to-event sample size calculation (Lachin-Foulkes) — print.nSurvival","text":"nSurvival produces list following component returned: type input. entry input. n Sample size required (computed). nEvents Number events required (computed). lambda1 input. lambda2 input. eta input. ratio input. gamma input. alpha input. beta input. sided input. Ts input. Tr input. nEvents produces scalar vector sample sizes (powers) tbl=FALSE , tbl=TRUE data frame values following columns: hr input. n n[1]=0 input (default), output contains number events need obtain input Type II error. n[1]>0 input, input value returned. alpha input. beta n[1]=0 input (default), beta output input. Otherwise, computed Type II error based input n. Power One minus output beta. tbl=FALSE, n[1]>0, value vector values returned. delta Standardized effect size represented input difference null alternative hypothesis hazard ratios. ratio Ratio experimental control sample size 'experimental' group hazard represented numerator hazard ratio. se Estimated standard error observed log(hazard ratio) given sample size. hrz2n outputs number events required approximately input hazard ratio, z-statistic sample size correspond. hrn2z outputs approximate z-statistic corresponding input hazard ratio number events. zn2hr outputs approximate hazard ratio corresponding input z-statistic number events.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurvival.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Time-to-event sample size calculation (Lachin-Foulkes) — print.nSurvival","text":"Lachin JM Foulkes MA (1986), Evaluation Sample Size Power Analyses Survival Allowance Nonuniform Patient Entry, Losses Follow-, Noncompliance, Stratification. Biometrics, 42, 507-519. Schoenfeld D (1981), Asymptotic Properties Nonparametric Tests Comparing Survival Distributions. Biometrika, 68, 316-319.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/nSurvival.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Time-to-event sample size calculation (Lachin-Foulkes) — print.nSurvival","text":"Shanhong Guan shanhong.guan@gmail.com, Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/nSurvival.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-to-event sample size calculation (Lachin-Foulkes) — print.nSurvival","text":"","code":"library(ggplot2)  # consider a trial with # 2 year maximum follow-up # 6 month uniform enrollment # Treatment/placebo hazards = 0.1/0.2 per 1 person-year # drop out hazard 0.1 per 1 person-year # alpha = 0.025 (1-sided) # power = 0.9 (default beta=.1)  ss <- nSurvival(   lambda1 = .2, lambda2 = .1, eta = .1, Ts = 2, Tr = .5,   sided = 1, alpha = .025 )  #  group sequential translation with default bounds #  note that delta1 is log hazard ratio; used later in gsBoundSummary summary x <- gsDesign(   k = 5, test.type = 2, n.fix = ss$nEvents, nFixSurv = ss$n,   delta1 = log(ss$lambda2 / ss$lambda1) ) # boundary plot plot(x)  # effect size plot plot(x, plottype = \"hr\")  # total sample size x$nSurv #> [1] 440 # number of events at analyses x$n.I #> [1] 18.44213 36.88425 55.32638 73.76850 92.21063 # print the design x #> Group sequential design sample size for time-to-event outcome #> with sample size 440. The analysis plan below shows events #> at each analysis. #> Symmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Spending computations assume trial stops #> if a bound is crossed. #>  #>               #>   Analysis N   Z   Nominal p  Spend #>          1 19 3.25    0.0006 0.0006 #>          2 37 2.99    0.0014 0.0013 #>          3 56 2.69    0.0036 0.0028 #>          4 74 2.37    0.0088 0.0063 #>          5 93 2.03    0.0214 0.0140 #>      Total                   0.0250  #>  #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4      5 Total E{N} #>   0.0000 0.0006 0.0013 0.0028 0.0063 0.0140 0.025 91.5 #>   0.3415 0.0370 0.1512 0.2647 0.2699 0.1771 0.900 66.4 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta     1      2      3      4     5 Total #>   0.0000 6e-04 0.0013 0.0028 0.0063 0.014 0.025 #>   0.3415 0e+00 0.0000 0.0000 0.0000 0.000 0.000 # overall design summary cat(summary(x)) #> Symmetric two-sided group sequential design with 5 analyses, time-to-event outcome with sample size 440 and 93 events required, 90 percent power, 2.5 percent (1-sided) Type I error. Bounds derived using a  Hwang-Shih-DeCani spending function with gamma = -4. # tabular summary of bounds gsBoundSummary(x, deltaname = \"HR\", Nname = \"Events\", logdelta = TRUE) #>    Analysis              Value Efficacy Futility #>   IA 1: 20%                  Z   3.2527  -3.2527 #>  Events: 19        p (1-sided)   0.0006   0.0006 #>                   ~HR at bound   0.2198   4.5487 #>               P(Cross) if HR=1   0.0006   0.0006 #>             P(Cross) if HR=0.5   0.0370   0.0000 #>   IA 2: 40%                  Z   2.9860  -2.9860 #>  Events: 37        p (1-sided)   0.0014   0.0014 #>                   ~HR at bound   0.3741   2.6734 #>               P(Cross) if HR=1   0.0018   0.0018 #>             P(Cross) if HR=0.5   0.1883   0.0000 #>   IA 3: 60%                  Z   2.6917  -2.6917 #>  Events: 56        p (1-sided)   0.0036   0.0036 #>                   ~HR at bound   0.4849   2.0621 #>               P(Cross) if HR=1   0.0047   0.0047 #>             P(Cross) if HR=0.5   0.4530   0.0000 #>   IA 4: 80%                  Z   2.3737  -2.3737 #>  Events: 74        p (1-sided)   0.0088   0.0088 #>                   ~HR at bound   0.5754   1.7380 #>               P(Cross) if HR=1   0.0110   0.0110 #>             P(Cross) if HR=0.5   0.7229   0.0000 #>       Final                  Z   2.0253  -2.0253 #>  Events: 93        p (1-sided)   0.0214   0.0214 #>                   ~HR at bound   0.6558   1.5247 #>               P(Cross) if HR=1   0.0250   0.0250 #>             P(Cross) if HR=0.5   0.9000   0.0000    # approximate number of events required using Schoenfeld's method # for 2 different hazard ratios nEvents(hr = c(.5, .6), tbl = TRUE) #>    hr   n alpha sided beta Power     delta ratio hr0        se #> 1 0.5  88 0.025     1  0.1   0.9 0.3465736     1   1 0.2132007 #> 2 0.6 162 0.025     1  0.1   0.9 0.2554128     1   1 0.1571348 # vector output nEvents(hr = c(.5, .6)) #> [1]  87.4793 161.0686  # approximate power using Schoenfeld's method # given 2 sample sizes and hr=.6 nEvents(hr = .6, n = c(50, 100), tbl = TRUE) #>    hr   n alpha sided      beta     Power     delta ratio hr0        se #> 1 0.6  50 0.025     1 0.5611646 0.4388354 0.2554128     1   1 0.2828427 #> 2 0.6 100 0.025     1 0.2762012 0.7237988 0.2554128     1   1 0.2000000 # vector output nEvents(hr = .6, n = c(50, 100)) #> [1] 0.4388354 0.7237988  # approximate hazard ratio corresponding to 100 events and z-statistic of 2 zn2hr(n = 100, z = 2) #> [1] 0.67032 # same when hr0 is 1.1 zn2hr(n = 100, z = 2, hr0 = 1.1) #> [1] 0.7373521 # same when hr0 is .9 and hr1 is greater than hr0 zn2hr(n = 100, z = 2, hr0 = .9, hr1 = 1) #> [1] 1.342642  # approximate number of events corresponding to z-statistic of 2 and # estimated hazard ratio of .5 (or 2) hrz2n(hr = .5, z = 2) #> [1] 33.3019 hrz2n(hr = 2, z = 2) #> [1] 33.3019  # approximate z statistic corresponding to 75 events # and estimated hazard ratio of .6 (or 1/.6) # assuming 2-to-1 randomization of experimental to control hrn2z(hr = .6, n = 75, ratio = 2) #> [1] -2.085437 hrn2z(hr = 1 / .6, n = 75, ratio = 2) #> [1] 2.085437"},{"path":"https://keaven.github.io/gsDesign/reference/normalGrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal Density Grid — normalGrid","title":"Normal Density Grid — normalGrid","text":"normalGrid() intended used computation expected value function normal random variable.  function produces grid points weights used numerical integration. utility function provide normal density function grid integrate described Jennison Turnbull (2000), Chapter 19. integration can performed real line portion , numerical integration extend beyond 6 standard deviations mean. grid used integration uses equally spaced points middle distribution function, spreads points apart tails. values returned gridwgts may used integrate function given grid, although user take care function integrated large tails grid points spread apart.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/normalGrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal Density Grid — normalGrid","text":"","code":"normalGrid(r = 18, bounds = c(0, 0), mu = 0, sigma = 1)"},{"path":"https://keaven.github.io/gsDesign/reference/normalGrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal Density Grid — normalGrid","text":"r Control grid points Jennison Turnbull (2000), Chapter 19; default 18. Range: 1 80.  might changed user (e.g., r=6 produces 65 gridpoints compare 185 points r=18) speed important precision. bounds Range integration. Real-valued vector length 2. Default value 0, 0 produces range + - 6 standard deviations (6*sigma) mean (=mu). mu Mean desired normal distribution. sigma Standard deviation desired normal distribution.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/normalGrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal Density Grid — normalGrid","text":"z Grid points numerical integration. density standard normal density function evaluated values z; see examples. gridwgts Simpson's rule weights numerical integration grid z; see examples. wgts Weights used grid z integrating normal density function; see examples. equal density * gridwgts.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/normalGrid.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Normal Density Grid — normalGrid","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/normalGrid.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Normal Density Grid — normalGrid","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/normalGrid.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Normal Density Grid — normalGrid","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/normalGrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal Density Grid — normalGrid","text":"","code":"library(ggplot2) #  standard normal distribution x <- normalGrid(r = 3) plot(x$z, x$wgts)   #  verify that numerical integration replicates sigma #  get grid points and weights x <- normalGrid(mu = 2, sigma = 3)  # compute squared deviation from mean for grid points dev <- (x$z - 2)^2  # multiply squared deviations by integration weights and sum sigma2 <- sum(dev * x$wgts)  # square root of sigma2 should be sigma (3) sqrt(sigma2) #> [1] 3.000001  # do it again with larger r to increase accuracy x <- normalGrid(r = 22, mu = 2, sigma = 3) sqrt(sum((x$z - 2)^2 * x$wgts)) #> [1] 3  # this can also be done by combining gridwgts and density sqrt(sum((x$z - 2)^2 * x$gridwgts * x$density)) #> [1] 3  # integrate normal density and compare to built-in function # to compute probability of being within 1 standard deviation # of the mean pnorm(1) - pnorm(-1) #> [1] 0.6826895 x <- normalGrid(bounds = c(-1, 1)) sum(x$wgts) #> [1] 0.6826895 sum(x$gridwgts * x$density) #> [1] 0.6826895  # find expected sample size for default design with # n.fix=1000 x <- gsDesign(n.fix = 1000) x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>                   ----Lower bounds----  ----Upper bounds----- #>   Analysis   N    Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  357 -0.24    0.4057 0.0148 3.01    0.0013  0.0013 #>          2  714  0.94    0.8267 0.0289 2.55    0.0054  0.0049 #>          3 1070  2.00    0.9772 0.0563 2.00    0.0228  0.0188 #>      Total                      0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Hwang-Shih-DeCani spending function with gamma = -2. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3  Total  E{N} #>   0.0000 0.0013 0.0049 0.0171 0.0233 624.9 #>   0.1025 0.1412 0.4403 0.3185 0.9000 791.3 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3  Total #>   0.0000 0.4057 0.4290 0.1420 0.9767 #>   0.1025 0.0148 0.0289 0.0563 0.1000  # set a prior distribution for theta y <- normalGrid(r = 3, mu = x$theta[2], sigma = x$theta[2] / 1.5) z <- gsProbability(   k = 3, theta = y$z, n.I = x$n.I, a = x$lower$bound,   b = x$upper$bound ) z <- gsProbability(d = x, theta = y$z) cat(   \"Expected sample size averaged over normal\\n prior distribution for theta with \\n mu=\",   x$theta[2], \"sigma=\", x$theta[2] / 1.5, \":\",   round(sum(z$en * y$wgt), 1), \"\\n\" ) #> Expected sample size averaged over normal #>  prior distribution for theta with  #>  mu= 0.1025057 sigma= 0.06833715 : 682.2  plot(y$z, z$en,   xlab = \"theta\", ylab = \"E{N}\",   main = \"Expected sample size for different theta values\" ) lines(y$z, z$en)"},{"path":"https://keaven.github.io/gsDesign/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://keaven.github.io/gsDesign/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling `rhs(lhs)`.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/plot.gsDesign.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots for group sequential designs — plot.gsDesign","title":"Plots for group sequential designs — plot.gsDesign","text":"plot() function extended work objects returned gsDesign() gsProbability().  objects type gsDesign, seven types plots provided: z-values boundaries (default), power, approximate treatment effects boundaries, conditional power boundaries, spending functions, expected sample size, B-values boundaries. objects type gsProbability plots available z-values boundaries, power (default), approximate treatment effects boundaries, conditional power, expected sample size B-values boundaries. intent many standard plot() parameters function expected; exceptions rule exist. particular, main, xlab, ylab, lty, col, lwd, type, pch, cex tested work values plottype; one exception type=\"l\" overridden plottype=2. Default values labels depend plottype class x. Note special behavior values plotted returned power expected sample size (ASN) plots gsDesign object. call x<-gsDesign() produces power expected sample size two theta values: 0 x$delta.  call plot(x, plottype=\"Power\") (plot(x,plottype=\"ASN\") gsDesign object produces power (expected sample size) curves returns gsDesign object theta values determined follows.  theta non-null input, input value(s) used. Otherwise, gsProbability object, theta values object used. gsDesign object theta input NULL (default), theta=seq(0,2,.05)*x$delta) used.  gsDesign object, x-axis values rescaled theta/x$delta label x-axis \\(theta / delta\\). gsProbability object, values theta plotted labeled \\(theta\\). See examples . Approximate treatment effects boundaries computed dividing Z-values boundaries square root n.analysis. Spending functions plotted continuous set values 0 1. option used boundary used pointwise spending function used (sfu sfl=\"WT\", \"\", \"Pocock\" sfPoints). Conditional power computed using function gsBoundCP().  default input routine theta=\"thetahat\" compute conditional power bound using approximate treatment effect bound.  Otherwise, input gsDesign object conditional power computed assuming theta=x$delta, original effect size trial planned. Average sample number/expected sample size computed using n.analysis times probability crossing boundary analysis. boundary crossed analysis, counted stopping final analysis. B-values Z-values multiplied sqrt(t)=sqrt(x$n./x$n.[x$k]). Thus, expected value B-value analysis true value \\(theta\\) multiplied proportion total planned observations time. See Proschan, Lan Wittes (2006).","code":""},{"path":"https://keaven.github.io/gsDesign/reference/plot.gsDesign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots for group sequential designs — plot.gsDesign","text":"","code":"# S3 method for gsDesign plot(x, plottype = 1, base = FALSE, ...)  # S3 method for gsProbability plot(x, plottype = 2, base = FALSE, ...)"},{"path":"https://keaven.github.io/gsDesign/reference/plot.gsDesign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots for group sequential designs — plot.gsDesign","text":"x Object class gsDesign plot.gsDesign() gsProbability plot.gsProbability(). plottype 1=boundary plot (default gsDesign), 2=power plot (default gsProbability), 3=approximate treatment effect boundaries, 4=conditional power boundaries, 5=spending function plot (available class(x)==\"gsDesign\"), 6=expected sample size plot, 7=B-values boundaries. Character values plottype may also entered: \"Z\" plot type 1, \"power\" plot type 2, \"thetahat\" plot type 3, \"CP\" plot type 4, \"sf\" plot type 5, \"ASN\", \"N\" \"n\" plot type 6, \"B\", \"B-val\" \"B-value\" plot type 7. base Default FALSE, means ggplot2 graphics used. true, base graphics used plotting. ... allows many optional arguments standard calling plot. arguments include: theta used plottype=2, 4, 6; normally defaults adequate; see details. ses=TRUE applies plottype=3 class(x)==\"gsDesign\"; indicates approximate standardized effect size boundary plotted rather approximate natural parameter. xval=\"Default\" effective plottype=2 6. Appropriately scaled (reparameterized) values x-axis power expected sample size graphs; see details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/plot.gsDesign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots for group sequential designs — plot.gsDesign","text":"object class(x); many cases input value x, others x$theta replaced corresponding characteristics computed; see details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/plot.gsDesign.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Plots for group sequential designs — plot.gsDesign","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/plot.gsDesign.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plots for group sequential designs — plot.gsDesign","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Proschan, MA, Lan, KKG, Wittes, JT (2006), Statistical Monitoring Clinical Trials. Unified Approach.  New York: Springer.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/plot.gsDesign.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plots for group sequential designs — plot.gsDesign","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/plot.gsDesign.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots for group sequential designs — plot.gsDesign","text":"","code":"library(ggplot2) #  symmetric, 2-sided design with O'Brien-Fleming-like boundaries #  lower bound is non-binding (ignored in Type I error computation) #  sample size is computed based on a fixed design requiring n=100 x <- gsDesign(k = 5, test.type = 2, n.fix = 100) x #> Symmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Spending computations assume trial stops #> if a bound is crossed. #>  #>                #>   Analysis  N   Z   Nominal p  Spend #>          1  21 3.25    0.0006 0.0006 #>          2  41 2.99    0.0014 0.0013 #>          3  62 2.69    0.0036 0.0028 #>          4  82 2.37    0.0088 0.0063 #>          5 103 2.03    0.0214 0.0140 #>      Total                    0.0250  #>  #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4      5 Total  E{N} #>   0.0000 0.0006 0.0013 0.0028 0.0063 0.0140 0.025 101.6 #>   0.3242 0.0370 0.1512 0.2647 0.2699 0.1771 0.900  73.7 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta     1      2      3      4     5 Total #>   0.0000 6e-04 0.0013 0.0028 0.0063 0.014 0.025 #>   0.3242 0e+00 0.0000 0.0000 0.0000 0.000 0.000  # the following translate to calls to plot.gsDesign since x was # returned by gsDesign; run these commands one at a time plot(x)  plot(x, plottype = 2)  plot(x, plottype = 3)  plot(x, plottype = 4)  plot(x, plottype = 5)  plot(x, plottype = 6)  plot(x, plottype = 7)   #  choose different parameter values for power plot #  start with design in x from above y <- gsProbability(   k = 5, theta = seq(0, .5, .025), x$n.I,   x$lower$bound, x$upper$bound )  # the following translates to a call to plot.gsProbability since # y has that type plot(y)"},{"path":"https://keaven.github.io/gsDesign/reference/sequentiaPValue.html","id":null,"dir":"Reference","previous_headings":"","what":"Sequential p-value computation — sequentialPValue","title":"Sequential p-value computation — sequentialPValue","text":"sequentialPValue computes sequential p-value group sequential design using spending function described  Maurer Bretz (2013) previously defined Liu Anderson (2008). minimum repeated p-values computed analysis (Jennison Turnbull, 2000). particularly useful multiplicity methods graphical method group sequential designs  sequential p-values multiple hypotheses can used nominal p-values plug multiplicity graph.  sequential p-value described minimum alpha level one-sided group sequential bound  rejected given interim final observed results. meaningful one-sided designs designs non-binding futility bounds (test.type 1, 4, 6),  2-sided designs binding futility bounds (test.type 2, 3 5). Mild restrictions required spending functions used, satisfied commonly used spending functions Lan-DeMets spending function approximating O'Brien-Fleming bound Hwang-Shih-DeCani spending function; see Maurer Bretz (2013).","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sequentiaPValue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sequential p-value computation — sequentialPValue","text":"","code":"sequentialPValue(   gsD = gsDesign(),   n.I = NULL,   Z = NULL,   usTime = NULL,   interval = c(1e-05, 0.9999) )"},{"path":"https://keaven.github.io/gsDesign/reference/sequentiaPValue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sequential p-value computation — sequentialPValue","text":"gsD Group sequential design generated gsDesign gsSurv. n.Event counts (time--event outcomes) sample size (designs); numeric vector increasing, positive values one value greater equal largest value gsD$n.; NOTE: NULL, planned n.used (gsD$n.). Z Z-value tests corresponding analyses n.; positive values indicate positive finding; must length n.. usTime Spending time upper bound specified analyses; specify default: NULL based information fraction;  NULL, must length n.; increasing positive values 1 greater equal 1. interval Interval search derive p-value; Default: c(1e-05, 0.9999). Lower end interval must >0 upper end must < 1.  primary reason use defaults likely test vs Type error <0.0001.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sequentiaPValue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sequential p-value computation — sequentialPValue","text":"Sequential p-value (single numeric one-sided p-value 0 1).  Note sequential p-value less lower end input interval,  lower interval returned. Similarly, sequential p-value greater upper end input interval,  upper end interval returned.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sequentiaPValue.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sequential p-value computation — sequentialPValue","text":"Solution found search using uniroot. finds maximum alpha-level efficacy bound crossed,  completely ignoring futility bound.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sequentiaPValue.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sequential p-value computation — sequentialPValue","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Liu, Qing, Keaven M. Anderson. \"adaptive extensions group sequential trials clinical investigations.\" Journal American Statistical Association 103.484 (2008): 1621-1630. Maurer, Willi, Frank Bretz. \"Multiple testing group sequential trials using graphical approaches.\" Statistics Biopharmaceutical Research 5.4 (2013): 311-320.;","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sequentiaPValue.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sequential p-value computation — sequentialPValue","text":"Keaven Anderson","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sequentiaPValue.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sequential p-value computation — sequentialPValue","text":"","code":"# Derive Group Sequential Design  x <- gsSurv(k = 4, alpha = 0.025, beta = 0.1, timing = c(.5,.65,.8), sfu = sfLDOF,             sfl = sfHSD, sflpar = 2, lambdaC = log(2)/6, hr = 0.6,             eta = 0.01 , gamma = c(2.5,5,7.5,10), R = c( 2,2,2,6 ),             T = 30 , minfup = 18) x$n.I #> [1] 109.2757 142.0585 174.8412 218.5515 # Analysis at IA2 sequentialPValue(gsD=x,n.I=c(100,160),Z=c(1.5,2)) #> [1] 0.05363369 # Use planned spending instead of information fraction; do final analysis sequentialPValue(gsD=x,n.I=c(100,160,190,230),Z=c(1.5,2,2.5,3),usTime=x$timing) #> [1] 0.001452684 # Check bounds for updated design to verify at least one was crossed xupdate <- gsDesign(maxn.IPlan=max(x$n.I),n.I=c(100,160,190,230),usTime=x$timing,                     delta=x$delta,delta1=x$delta1,k=4,alpha=x$alpha,test.type=1,                     sfu=x$upper$sf,sfupar=x$upper$param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfDistribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Two-parameter Spending Function Families — sfLogistic","title":"Two-parameter Spending Function Families — sfLogistic","text":"functions sfLogistic(), sfNormal(), sfExtremeValue(), sfExtremeValue2(), sfCauchy(), sfBetaDist() 2-parameter spending function families. provide increased flexibility situations flexibility one-parameter spending function family sufficient. functions allow fitting two points cumulative spending function curve; case, four parameters specified indicating x y coordinate 2 points. Normally functions passed gsDesign() parameter sfu upper bound sfl lower bound specify spending function family design. case, user need know calling sequence. calling sequence useful, however, user wishes plot spending function demonstrated examples; note, however, automatic \\(\\alpha\\)- \\(\\beta\\)-spending function plot also available. sfBetaDist(alpha,t,param) simply alpha times incomplete beta cumulative distribution function parameters \\(\\) \\(b\\) passed param evaluated values passed t. spending functions take form $$f(t;\\alpha,,b)=\\alpha F(+bF^{-1}(t))$$ \\(F()\\) cumulative distribution function values \\(> 0\\) real line (logistic sfLogistic(), normal sfNormal(), extreme value sfExtremeValue() Cauchy sfCauchy()) \\(F^{-1}()\\) inverse. logistic spending function simplifies $$f(t;\\alpha,,b)=\\alpha (1-(1+e^(t/(1-t))^b)^{-1}).$$ extreme value distribution $$F(x)=\\exp(-\\exp(-x))$$ simplifies $$f(t;\\alpha,,b)=\\alpha \\exp(-e^(-\\ln t)^b).$$ Since extreme value distribution symmetric, also version standard distribution flipped 0. reflected sfExtremeValue2() $$F(x)=1-\\exp(-\\exp(x)).$$","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfDistribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two-parameter Spending Function Families — sfLogistic","text":"","code":"sfLogistic(alpha, t, param)  sfBetaDist(alpha, t, param)  sfCauchy(alpha, t, param)  sfExtremeValue(alpha, t, param)  sfExtremeValue2(alpha, t, param)  sfNormal(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfDistribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two-parameter Spending Function Families — sfLogistic","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size information. t vector points increasing values 0 1, inclusive. Values proportion sample size information spending function computed. param two-parameter specification, sfBetaDist() requires 2 positive values, sfLogistic(), sfNormal(), sfExtremeValue(), sfExtremeValue2() sfCauchy() require first parameter real value second positive value.  four parameter specification c(t1,t2,u1,u2) objective sf(t1)=alpha*u1 sf(t2)=alpha*u2.  parameterization, four values must 0 1 t1 < t2, u1 < u2.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfDistribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two-parameter Spending Function Families — sfLogistic","text":"object type spendfn.  See Spending_Function_Overview details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfDistribution.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Two-parameter Spending Function Families — sfLogistic","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfDistribution.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two-parameter Spending Function Families — sfLogistic","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfDistribution.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two-parameter Spending Function Families — sfLogistic","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfDistribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two-parameter Spending Function Families — sfLogistic","text":"","code":"library(ggplot2) # design a 4-analysis trial using a Kim-DeMets spending function # for both lower and upper bounds x <- gsDesign(k = 4, sfu = sfPower, sfupar = 3, sfl = sfPower, sflpar = 1.5)  # print the design x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.282 -0.52    0.3015 0.0125 3.36    0.0004  0.0004 #>          2  0.564  0.53    0.7028 0.0229 2.76    0.0029  0.0027 #>          3  0.846  1.32    0.9072 0.0296 2.36    0.0092  0.0074 #>          4  1.128  2.03    0.9788 0.0350 2.03    0.0212  0.0145 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Kim-DeMets (power) spending function with rho = 1.5. #> ++ alpha spending: #>  Kim-DeMets (power) spending function with rho = 3. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4  Total  E{N} #>   0.0000 0.0004 0.0027 0.0073 0.0116 0.0221 0.579 #>   3.2415 0.0507 0.3248 0.3619 0.1626 0.9000 0.768 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4  Total #>   0.0000 0.3015 0.4138 0.2008 0.0619 0.9779 #>   3.2415 0.0125 0.0229 0.0296 0.0350 0.1000  # plot the alpha- and beta-spending functions plot(x, plottype = 5)   # start by showing how to fit two points with sfLogistic # plot the spending function using many points to obtain a smooth curve # note that curve fits the points x=.1,  y=.01 and x=.4,  y=.1 # specified in the 3rd parameter of sfLogistic t <- 0:100 / 100 plot(t, sfLogistic(1, t, c(.1, .4, .01, .1))$spend,   xlab = \"Proportion of final sample size\",   ylab = \"Cumulative Type I error spending\",   main = \"Logistic Spending Function Examples\",   type = \"l\", cex.main = .9 ) lines(t, sfLogistic(1, t, c(.01, .1, .1, .4))$spend, lty = 2)  # now just give a=0 and b=1 as 3rd parameters for sfLogistic lines(t, sfLogistic(1, t, c(0, 1))$spend, lty = 3)  # try a couple with unconventional shapes again using # the xy form in the 3rd parameter lines(t, sfLogistic(1, t, c(.4, .6, .1, .7))$spend, lty = 4) lines(t, sfLogistic(1, t, c(.1, .7, .4, .6))$spend, lty = 5) legend(   x = c(.0, .475), y = c(.76, 1.03), lty = 1:5,   legend = c(     \"Fit (.1, 01) and (.4, .1)\", \"Fit (.01, .1) and (.1, .4)\",     \"a=0,  b=1\", \"Fit (.4, .1) and (.6, .7)\",     \"Fit (.1, .4) and (.7, .6)\"   ) )   # set up a function to plot comparsons of all # 2-parameter spending functions plotsf <- function(alpha, t, param) {   plot(t, sfCauchy(alpha, t, param)$spend,     xlab = \"Proportion of enrollment\",     ylab = \"Cumulative spending\", type = \"l\", lty = 2   )   lines(t, sfExtremeValue(alpha, t, param)$spend, lty = 5)   lines(t, sfLogistic(alpha, t, param)$spend, lty = 1)   lines(t, sfNormal(alpha, t, param)$spend, lty = 3)   lines(t, sfExtremeValue2(alpha, t, param)$spend, lty = 6, col = 2)   lines(t, sfBetaDist(alpha, t, param)$spend, lty = 7, col = 3)   legend(     x = c(.05, .475), y = .025 * c(.55, .9),     lty = c(1, 2, 3, 5, 6, 7),     col = c(1, 1, 1, 1, 2, 3),     legend = c(       \"Logistic\", \"Cauchy\", \"Normal\", \"Extreme value\",       \"Extreme value 2\", \"Beta distribution\"     )   ) } # do comparison for a design with conservative early spending # note that Cauchy spending function is quite different # from the others param <- c(.25, .5, .05, .1) plotsf(.025, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfExponential.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential Spending Function — sfExponential","title":"Exponential Spending Function — sfExponential","text":"function sfExponential implements exponential spending function (Anderson Clark, 2009). Normally sfExponential passed gsDesign parameter sfu upper bound sfl lower bound specify spending function family design. case, user need know calling sequence. calling sequence useful, however, user wishes plot spending function demonstrated examples. exponential spending function defined positive nu \\(0\\le t\\le 1\\) $$f(t;\\alpha,\\nu)=\\alpha(t)=\\alpha^{t^{-\\nu}}.$$ value nu=0.8 approximates O'Brien-Fleming spending function well. general class spending functions family derived requires continuously increasing cumulative distribution function defined \\(x>0\\) defined $$f(t;\\alpha, \\nu)=1-F\\left(F^{-1}(1-\\alpha)/ t^\\nu\\right).$$ exponential spending function can derived letting \\(F(x)=1-\\exp(-x)\\), exponential cumulative distribution function. function derived generalization Lan-DeMets (1983) spending function used approximate O'Brien-Fleming spending function (sfLDOF()), $$f(t; \\alpha)=2-2\\Phi \\left( \\Phi^{-1}(1-\\alpha/2)/ t^{1/2} \\right).$$","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfExponential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential Spending Function — sfExponential","text":"","code":"sfExponential(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfExponential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential Spending Function — sfExponential","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size/information. t vector points increasing values 0 1, inclusive. Values proportion sample size/information spending function computed. param single positive value specifying nu parameter exponential spending computed; allowable range (0, 1.5].","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfExponential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exponential Spending Function — sfExponential","text":"object type spendfn.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfExponential.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Exponential Spending Function — sfExponential","text":"gsDesign technical manual shows use sfExponential()   closely approximate O'Brien-Fleming design. example given .   manual available <https://keaven.github.io/gsd-tech-manual/>.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfExponential.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Exponential Spending Function — sfExponential","text":"Anderson KM Clark JB (2009), Fitting spending functions. Statistics Medicine; 29:321-327. Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Lan, KKG DeMets, DL (1983), Discrete sequential boundaries clinical trials. Biometrika; 70:659-663.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfExponential.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Exponential Spending Function — sfExponential","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfExponential.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exponential Spending Function — sfExponential","text":"","code":"library(ggplot2) # use 'best' exponential approximation for k=6 to O'Brien-Fleming design # (see manual for details) gsDesign(   k = 6, sfu = sfExponential, sfupar = 0.7849295,   test.type = 2 )$upper$bound #> [1] 4.998123 3.598098 2.933292 2.530838 2.253723 2.047082  # show actual O'Brien-Fleming bound gsDesign(k = 6, sfu = \"OF\", test.type = 2)$upper$bound #> [1] 5.028296 3.555542 2.903088 2.514148 2.248722 2.052793  # show Lan-DeMets approximation # (not as close as sfExponential approximation) gsDesign(k = 6, sfu = sfLDOF, test.type = 2)$upper$bound #> [1] 5.366558 3.710340 2.969736 2.538677 2.252190 2.044790  # plot exponential spending function across a range of values of interest t <- 0:100 / 100 plot(t, sfExponential(0.025, t, 0.8)$spend,   xlab = \"Proportion of final sample size\",   ylab = \"Cumulative Type I error spending\",   main = \"Exponential Spending Function Example\", type = \"l\" ) lines(t, sfExponential(0.025, t, 0.5)$spend, lty = 2) lines(t, sfExponential(0.025, t, 0.3)$spend, lty = 3) lines(t, sfExponential(0.025, t, 0.2)$spend, lty = 4) lines(t, sfExponential(0.025, t, 0.15)$spend, lty = 5) legend(   x = c(.0, .3), y = .025 * c(.7, 1), lty = 1:5,   legend = c(     \"nu = 0.8\", \"nu = 0.5\", \"nu = 0.3\", \"nu = 0.2\",     \"nu = 0.15\"   ) ) text(x = .59, y = .95 * .025, labels = \"<--approximates O'Brien-Fleming\")"},{"path":"https://keaven.github.io/gsDesign/reference/sfHSD.html","id":null,"dir":"Reference","previous_headings":"","what":"Hwang-Shih-DeCani Spending Function — sfHSD","title":"Hwang-Shih-DeCani Spending Function — sfHSD","text":"function sfHSD implements Hwang-Shih-DeCani spending function. default spending function gsDesign(). Normally passed gsDesign parameter sfu upper bound sfl lower bound specify spending function family design. case, user need know calling sequence. calling sequence useful, however, user wishes plot spending function demonstrated examples. Hwang-Shih-DeCani spending function takes form $$f(t;\\alpha, \\gamma)=\\alpha(1-e^{-\\gamma t})/(1-e^{-\\gamma})$$ \\(\\gamma\\) value passed param. value \\(\\gamma=-4\\) used approximate O'Brien-Fleming design (see sfExponential better fit), value \\(\\gamma=1\\) approximates Pocock design well.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfHSD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hwang-Shih-DeCani Spending Function — sfHSD","text":"","code":"sfHSD(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfHSD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hwang-Shih-DeCani Spending Function — sfHSD","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size/information. t vector points increasing values 0 1, inclusive. Values proportion sample size/information spending function computed. param single real value specifying gamma parameter Hwang-Shih-DeCani spending computed; allowable range [-40, 40]","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfHSD.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hwang-Shih-DeCani Spending Function — sfHSD","text":"object type spendfn. See Spending_Function_Overview details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfHSD.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Hwang-Shih-DeCani Spending Function — sfHSD","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfHSD.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hwang-Shih-DeCani Spending Function — sfHSD","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfHSD.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hwang-Shih-DeCani Spending Function — sfHSD","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfHSD.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hwang-Shih-DeCani Spending Function — sfHSD","text":"","code":"library(ggplot2) # design a 4-analysis trial using a Hwang-Shih-DeCani spending function # for both lower and upper bounds x <- gsDesign(k = 4, sfu = sfHSD, sfupar = -2, sfl = sfHSD, sflpar = 1)  # print the design x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size   ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*  Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.324 0.03    0.5136 0.0350 2.80    0.0025  0.0025 #>          2  0.649 0.88    0.8096 0.0273 2.58    0.0049  0.0042 #>          3  0.973 1.51    0.9349 0.0212 2.34    0.0096  0.0069 #>          4  1.297 2.09    0.9817 0.0165 2.09    0.0183  0.0114 #>      Total                       0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Hwang-Shih-DeCani spending function with gamma = 1. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -2. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4  Total   E{N} #>   0.0000 0.0025 0.0042 0.0065 0.0072 0.0203 0.5477 #>   3.2415 0.1695 0.3553 0.2774 0.0978 0.9000 0.7533 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4  Total #>   0.0000 0.5136 0.3156 0.1169 0.0336 0.9797 #>   3.2415 0.0350 0.0273 0.0212 0.0165 0.1000  # since sfHSD is the default for both sfu and sfl, # this could have been written as x <- gsDesign(k = 4, sfupar = -2, sflpar = 1)  # print again x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size   ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*  Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.324 0.03    0.5136 0.0350 2.80    0.0025  0.0025 #>          2  0.649 0.88    0.8096 0.0273 2.58    0.0049  0.0042 #>          3  0.973 1.51    0.9349 0.0212 2.34    0.0096  0.0069 #>          4  1.297 2.09    0.9817 0.0165 2.09    0.0183  0.0114 #>      Total                       0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Hwang-Shih-DeCani spending function with gamma = 1. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -2. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4  Total   E{N} #>   0.0000 0.0025 0.0042 0.0065 0.0072 0.0203 0.5477 #>   3.2415 0.1695 0.3553 0.2774 0.0978 0.9000 0.7533 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4  Total #>   0.0000 0.5136 0.3156 0.1169 0.0336 0.9797 #>   3.2415 0.0350 0.0273 0.0212 0.0165 0.1000  # plot the spending function using many points to obtain a smooth curve # show default values of gamma to see how the spending function changes # also show gamma=1 which is supposed to approximate a Pocock design t <- 0:100 / 100 plot(t, sfHSD(0.025, t, -4)$spend,   xlab = \"Proportion of final sample size\",   ylab = \"Cumulative Type I error spending\",   main = \"Hwang-Shih-DeCani Spending Function Example\", type = \"l\" ) lines(t, sfHSD(0.025, t, -2)$spend, lty = 2) lines(t, sfHSD(0.025, t, 1)$spend, lty = 3) legend(   x = c(.0, .375), y = .025 * c(.8, 1), lty = 1:3,   legend = c(\"gamma= -4\", \"gamma= -2\", \"gamma= 1\") )"},{"path":"https://keaven.github.io/gsDesign/reference/sfLDOF.html","id":null,"dir":"Reference","previous_headings":"","what":"Lan-DeMets Spending function overview — sfLDOF","title":"Lan-DeMets Spending function overview — sfLDOF","text":"Lan DeMets (1983) first published method using spending functions  set boundaries group sequential trials. publication proposed two specific spending functions: one approximate O'Brien-Fleming design approximate Pocock design. spending function approximate O'Brien-Fleming generalized proposed Liu, et al (2012) param=1=rho, Lan-DeMets (1983) spending function approximate O'Brien-Fleming bound implemented function (sfLDOF()): $$f(t;  \\alpha)=2-2\\Phi\\left(\\Phi^{-1}(1-\\alpha/2)/ t^{\\rho/2}\\right).$$ rho otherwise [.005,2], generalized version Liu et al (2012). param outside [.005,2], rho set 1. Lan-DeMets (1983) spending function approximate Pocock design implemented function sfLDPocock(): $$f(t;\\alpha)=\\alpha ln(1+(e-1)t).$$ shown examples , spending functions can used ge t good better approximations Pocock O'Brien-Fleming bounds. particular, O'Brien-Fleming bounds can closely approximated using sfExponential.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLDOF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lan-DeMets Spending function overview — sfLDOF","text":"","code":"sfLDOF(alpha, t, param = NULL)  sfLDPocock(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfLDOF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lan-DeMets Spending function overview — sfLDOF","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size/information. t vector points increasing values 0 1, inclusive. Values proportion sample size/information spending function computed. param parameter used sfLDPocock, required  sfLDOF need specified. sfLDPocock  calling sequence conforms standard spending functions used  gsDesign(). sfLDOF default 1 (Lan-DeMets function  approximate O'Brien-Fleming) NULL outside range [.005,2]. otherwise, use set rho Liu et al (2012).","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLDOF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lan-DeMets Spending function overview — sfLDOF","text":"object type spendfn. See spending functions details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLDOF.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Lan-DeMets Spending function overview — sfLDOF","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLDOF.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Lan-DeMets Spending function overview — sfLDOF","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall. Lan, KKG DeMets, DL (1983), Discrete sequential boundaries clinical trials. Biometrika;70: 659-663. Liu, Q, Lim, P, Nuamah, , Li, Y (2012), adaptive error spending approach  group sequential trials random information levels.  Journal biopharmaceutical statistics; 22(4), 687-699.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfLDOF.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Lan-DeMets Spending function overview — sfLDOF","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLDOF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lan-DeMets Spending function overview — sfLDOF","text":"","code":"library(ggplot2) # 2-sided,  symmetric 6-analysis trial Pocock # spending function approximation gsDesign(k = 6, sfu = sfLDPocock, test.type = 2)$upper$bound #> [1] 2.495115 2.476907 2.454964 2.437262 2.423276 2.412059  # show actual Pocock design gsDesign(k = 6, sfu = \"Pocock\", test.type = 2)$upper$bound #> [1] 2.453211 2.453211 2.453211 2.453211 2.453211 2.453211  # approximate Pocock again using a standard # Hwang-Shih-DeCani approximation gsDesign(k = 6, sfu = sfHSD, sfupar = 1, test.type = 2)$upper$bound #> [1] 2.507958 2.471981 2.443139 2.426686 2.420302 2.421749  # use 'best' Hwang-Shih-DeCani approximation for Pocock,  k=6; # see manual for details gsDesign(k = 6, sfu = sfHSD, sfupar = 1.3354376, test.type = 2)$upper$bound #> [1] 2.469285 2.448341 2.436191 2.437278 2.448837 2.468360  # 2-sided, symmetric 6-analysis trial # O'Brien-Fleming spending function approximation gsDesign(k = 6, sfu = sfLDOF, test.type = 2)$upper$bound #> [1] 5.366558 3.710340 2.969736 2.538677 2.252190 2.044790  # show actual O'Brien-Fleming bound gsDesign(k = 6, sfu = \"OF\", test.type = 2)$upper$bound #> [1] 5.028296 3.555542 2.903088 2.514148 2.248722 2.052793  # approximate again using a standard Hwang-Shih-DeCani # approximation to O'Brien-Fleming x <- gsDesign(k = 6, test.type = 2) x$upper$bound #> [1] 3.325024 3.103223 2.860383 2.603454 2.330046 2.034988 x$upper$param #> [1] -4  # use 'best' exponential approximation for k=6; see manual for details gsDesign(   k = 6, sfu = sfExponential, sfupar = 0.7849295,   test.type = 2 )$upper$bound #> [1] 4.998123 3.598098 2.933292 2.530838 2.253723 2.047082  # plot spending functions for generalized Lan-DeMets approximation of ti <-(0:100)/100 rho <- c(.05,.5,1,1.5,2,2.5,3:6,8,10,12.5,15,20,30,200)/10 df <- NULL for(r in rho){   df <- rbind(df,data.frame(t=ti,rho=r,alpha=.025,spend=sfLDOF(alpha=.025,t=ti,param=r)$spend)) } ggplot(df,aes(x=t,y=spend,col=as.factor(rho)))+   geom_line()+   guides(col=guide_legend(expression(rho)))+   ggtitle(\"Generalized Lan-DeMets O'Brien-Fleming Spending Function\")"},{"path":"https://keaven.github.io/gsDesign/reference/sfLinear.html","id":null,"dir":"Reference","previous_headings":"","what":"Piecewise Linear and Step Function Spending Functions — sfLinear","title":"Piecewise Linear and Step Function Spending Functions — sfLinear","text":"function sfLinear() allows specification piecewise linear spending function. function sfStep() specifies step function spending function. functions provide complete flexibility setting spending desired timepoints group sequential design. Normally function passed gsDesign() parameter sfu upper bound sfl lower bound specify spending function family design. passed gsDesign(), value param passed sfLinear() sfStep() gsDesign() arguments sfupar upper bound sflpar lower bound. Note sfStep() allows setting particular level spending timing strictly known; example shows can inflate Type error timing analyses changed based knowing treatment effect interim.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Piecewise Linear and Step Function Spending Functions — sfLinear","text":"","code":"sfLinear(alpha, t, param)  sfStep(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfLinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Piecewise Linear and Step Function Spending Functions — sfLinear","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size information. t vector points increasing values 0 1, inclusive. Values proportion sample size information spending function computed. param vector positive, even length. Values must range 0 1, inclusive. Letting m <- length(param/2), first m points param specify increasing values strictly 0 1 corresponding interim timing (proportion final total statistical information). last m points param specify non-decreasing values 0 1, inclusive, cumulative proportion spending specified timepoints.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLinear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Piecewise Linear and Step Function Spending Functions — sfLinear","text":"object type spendfn.  cumulative spending returned sfLinear$spend 0 t <= 0 alpha t>=1.  t specified points, linear interpolation used determine sfLinear$spend. cumulative spending returned sfStep$spend 0 t<param[1] alpha t>=1.  Letting m <- length(param/2), =1,2,...m-1  param[]<= t < param[+1], cumulative spending set alpha * param[+m] (also param[m]<=t<1). Note param[2m] 1, first time analysis performed last proportion final planned information (param[m]) final analysis, using remaining error previously spent. See Spending_Function_Overview details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLinear.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Piecewise Linear and Step Function Spending Functions — sfLinear","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLinear.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Piecewise Linear and Step Function Spending Functions — sfLinear","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfLinear.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Piecewise Linear and Step Function Spending Functions — sfLinear","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfLinear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Piecewise Linear and Step Function Spending Functions — sfLinear","text":"","code":"library(ggplot2) # set up alpha spending and beta spending to be piecewise linear sfupar <- c(.2, .4, .05, .2) sflpar <- c(.3, .5, .65, .5, .75, .9) x <- gsDesign(sfu = sfLinear, sfl = sfLinear, sfupar = sfupar, sflpar = sflpar) plot(x, plottype = \"sf\")  x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size   ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*  Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.474 0.63    0.7342 0.0542 2.67    0.0038  0.0037 #>          2  0.948 1.60    0.9455 0.0363 2.27    0.0117  0.0101 #>          3  1.422 2.11    0.9827 0.0095 2.11    0.0173  0.0111 #>      Total                       0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Piecewise linear spending function with line points = 0.3 0.5 0.65 0.5 0.75 0.9. #> ++ alpha spending: #>  Piecewise linear spending function with line points = 0.2 0.4 0.05 0.2. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3 Total   E{N} #>   0.0000 0.0038 0.0096 0.0056 0.019 0.6143 #>   3.2415 0.3291 0.4762 0.0947 0.900 0.8155 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3 Total #>   0.0000 0.7342 0.2181 0.0288 0.981 #>   3.2415 0.0542 0.0363 0.0095 0.100  # now do an example where there is no lower-spending at interim 1 # and no upper spending at interim 2 sflpar <- c(1 / 3, 2 / 3, 0, .25) sfupar <- c(1 / 3, 2 / 3, .1, .1) x <- gsDesign(sfu = sfLinear, sfl = sfLinear, sfupar = sfupar, sflpar = sflpar) plot(x, plottype = \"sf\")  x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*    Z   Nominal p Spend+   Z   Nominal p Spend++ #>          1  0.343 -20.00    0.0000  0.000  2.81    0.0025  0.0025 #>          2  0.685   0.72    0.7652  0.025 20.00    0.0000  0.0000 #>          3  1.028   1.99    0.9765  0.075  1.99    0.0235  0.0225 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Piecewise linear spending function with line points = 0.333333333333333 0.666666666666667 0 0.25. #> ++ alpha spending: #>  Piecewise linear spending function with line points = 0.333333333333333 0.666666666666667 0.1 0.1. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1 2      3  Total   E{N} #>   0.0000 0.0025 0 0.0219 0.0244 0.7638 #>   3.2415 0.1814 0 0.7186 0.9000 0.8947 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta 1      2      3  Total #>   0.0000 0 0.7651 0.2105 0.9756 #>   3.2415 0 0.0250 0.0750 0.1000  # now do an example where timing of interims changes slightly, but error spending does not # also, spend all alpha when at least >=90 percent of final information is in the analysis sfupar <- c(.2, .4, .9, ((1:3) / 3)^3) x <- gsDesign(k = 3, n.fix = 100, sfu = sfStep, sfupar = sfupar, test.type = 1) plot(x, pl = \"sf\")  # original planned sample sizes ceiling(x$n.I) #> [1]  34  68 102 # cumulative spending planned at original interims cumsum(x$upper$spend) #> [1] 0.0009259259 0.0074074074 0.0250000000 # change timing of analyses; # note that cumulative spending \"P(Cross) if delta=0\" does not change from cumsum(x$upper$spend) # while full alpha is spent, power is reduced by reduced sample size y <- gsDesign(   k = 3, sfu = sfStep, sfupar = sfupar, test.type = 1,   maxn.IPlan = x$n.I[x$k], n.I = c(30, 70, 95),   n.fix = x$n.fix ) # note that full alpha is used, but power is reduced due to lowered sample size gsBoundSummary(y) #>   Analysis               Value Efficacy #>  IA 1: 29%                   Z   3.1130 #>      N: 30         p (1-sided)   0.0009 #>                ~delta at bound   1.7534 #>            P(Cross) if delta=0   0.0009 #>            P(Cross) if delta=1   0.0905 #>  IA 2: 69%                   Z   2.4662 #>      N: 70         p (1-sided)   0.0068 #>                ~delta at bound   0.9094 #>            P(Cross) if delta=0   0.0074 #>            P(Cross) if delta=1   0.6004 #>      Final                   Z   1.9975 #>      N: 95         p (1-sided)   0.0229 #>                ~delta at bound   0.6322 #>            P(Cross) if delta=0   0.0250 #>            P(Cross) if delta=1   0.8807  # now show how step function can be abused by 'adapting' stage 2 sample size based on interim result x <- gsDesign(k = 2, delta = .05, sfu = sfStep, sfupar = c(.02, .001), timing = .02, test.type = 1) # spending jumps from miniscule to full alpha at first analysis after interim 1 plot(x, pl = \"sf\")  # sample sizes at analyses: ceiling(x$n.I) #> [1]   85 4204 # simulate 1 million stage 1 sum of 178 Normal(0,1) random variables # Normal(0,Variance=178) under null hypothesis s1 <- rnorm(1000000, 0, sqrt(178)) # compute corresponding z-values z1 <- s1 / sqrt(178) # set stage 2 sample size to 1 if z1 is over final bound, otherwise full sample size n2 <- rep(1, 1000000) n2[z1 < 1.96] <- ceiling(x$n.I[2]) - ceiling(178) # now sample n2 observations for second stage s2 <- rnorm(1000000, 0, sqrt(n2)) # add sum and divide by standard deviation z2 <- (s1 + s2) / (sqrt(178 + n2)) # By allowing full spending when final analysis is either # early or late depending on observed interim z1, # Type I error is now almost twice the planned .025 sum(z1 >= x$upper$bound[1] | z2 >= x$upper$bound[2]) / 1000000 #> [1] 0.046755 # if stage 2 sample size is random and independent of z1 with same frequency, # this is not a problem s1alt <- rnorm(1000000, 0, sqrt(178)) z1alt <- s1alt / sqrt(178) z2alt <- (s1alt + s2) / sqrt(178 + n2) sum(z1alt >= x$upper$bound[1] | z2alt >= x$upper$bound[2]) / 1000000 #> [1] 0.024938"},{"path":"https://keaven.github.io/gsDesign/reference/sfPoints.html","id":null,"dir":"Reference","previous_headings":"","what":"Pointwise Spending Function — sfPoints","title":"Pointwise Spending Function — sfPoints","text":"function sfPoints implements spending function values specified arbitrary set specified points. now recommended use sfLinear rather sfPoints. Normally sfPoints passed gsDesign parameter sfu upper bound sfl lower bound specify spending function family design. case, user need know calling sequence, just points wish specify. using sfPoints() design, recommended specify interpolate specified points (e.g,, linear interpolation); also consider fitting smooth spending functions; see Spending_Function_Overview.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPoints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pointwise Spending Function — sfPoints","text":"","code":"sfPoints(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfPoints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pointwise Spending Function — sfPoints","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size/information. t vector points increasing values >0 <=1.  Values proportion sample size/information spending function computed. param vector length t specifying cumulative proportion spending corresponding point t; must >=0 <=1.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPoints.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pointwise Spending Function — sfPoints","text":"object type spendfn. See spending functions details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPoints.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pointwise Spending Function — sfPoints","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPoints.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pointwise Spending Function — sfPoints","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfPoints.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Pointwise Spending Function — sfPoints","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPoints.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pointwise Spending Function — sfPoints","text":"","code":"library(ggplot2) # example to specify spending on a pointwise basis x <- gsDesign(   k = 6, sfu = sfPoints, sfupar = c(.01, .05, .1, .25, .5, 1),   test.type = 2 ) x #> Symmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Spending computations assume trial stops #> if a bound is crossed. #>  #>            Sample #>             Size  #>   Analysis Ratio*  Z   Nominal p  Spend #>          1  0.171 3.48    0.0002 0.0003 #>          2  0.342 3.07    0.0011 0.0010 #>          3  0.512 2.94    0.0017 0.0013 #>          4  0.683 2.58    0.0050 0.0037 #>          5  0.854 2.33    0.0099 0.0063 #>          6  1.025 2.03    0.0211 0.0125 #>      Total                       0.0250  #>  #> ++ alpha spending: #>  User-specified spending function with Points = 0.01 0.05 0.1 0.25 0.5 1. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4      5      6 Total   E{N} #>   0.0000 0.0002 0.0010 0.0013 0.0038 0.0063 0.0125 0.025 1.0171 #>   3.2415 0.0161 0.1072 0.1626 0.2666 0.2066 0.1409 0.900 0.7282 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta     1     2      3      4      5      6 Total #>   0.0000 2e-04 0.001 0.0013 0.0038 0.0063 0.0125 0.025 #>   3.2415 0e+00 0.000 0.0000 0.0000 0.0000 0.0000 0.000  # get proportion of upper spending under null hypothesis # at each analysis y <- x$upper$prob[, 1] / .025  # change to cumulative proportion of spending for (i in 2:length(y))   y[i] <- y[i - 1] + y[i]  # this should correspond to input sfupar round(y, 6) #> [1] 0.01 0.05 0.10 0.25 0.50 1.00  # plot these cumulative spending points plot(1:6 / 6, y,   main = \"Pointwise spending function example\",   xlab = \"Proportion of final sample size\",   ylab = \"Cumulative proportion of spending\",   type = \"p\" )  # approximate this with a t-distribution spending function # by fitting 3 points tx <- 0:100 / 100 lines(tx, sfTDist(1, tx, c(c(1, 3, 5) / 6, .01, .1, .5))$spend) text(x = .6, y = .9, labels = \"Pointwise Spending Approximated by\") text(x = .6, y = .83, \"t-Distribution Spending with 3-point interpolation\")   # example without lower spending at initial interim or # upper spending at last interim x <- gsDesign(   k = 3, sfu = sfPoints, sfupar = c(.25, .25),   sfl = sfPoints, sflpar = c(0, .25) ) x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*    Z   Nominal p Spend+   Z   Nominal p Spend++ #>          1  0.351 -20.00    0.0000  0.000  2.50    0.0063  0.0063 #>          2  0.703   0.76    0.7758  0.025 20.00    0.0000  0.0000 #>          3  1.054   2.04    0.9793  0.075  2.04    0.0207  0.0188 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  User-specified spending function with Points = 0 0.25 1. #> ++ alpha spending: #>  User-specified spending function with Points = 0.25 0.25 1. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1 2      3  Total   E{N} #>   0.0000 0.0063 0 0.0182 0.0245 0.7773 #>   3.2415 0.2822 0 0.6178 0.9000 0.8470 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta 1      2      3  Total #>   0.0000 0 0.7755 0.2001 0.9755 #>   3.2415 0 0.0250 0.0750 0.1000"},{"path":"https://keaven.github.io/gsDesign/reference/sfPower.html","id":null,"dir":"Reference","previous_headings":"","what":"Kim-DeMets (power) Spending Function — sfPower","title":"Kim-DeMets (power) Spending Function — sfPower","text":"function sfPower() implements Kim-DeMets (power) spending function. flexible, one-parameter spending function recommended Jennison Turnbull (2000). Normally passed gsDesign() parameter sfu upper bound sfl lower bound specify spending function family design. case, user need know calling sequence. calling sequence useful, however, user wishes plot spending function demonstrated examples. Kim-DeMets spending function takes form $$f(t;\\alpha,\\rho)=\\alpha t^\\rho$$ \\(\\rho\\) value passed param. See examples range values \\(\\rho\\) may interest (param=0.75 3 documented ).","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPower.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kim-DeMets (power) Spending Function — sfPower","text":"","code":"sfPower(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfPower.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kim-DeMets (power) Spending Function — sfPower","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size/information. t vector points increasing values 0 1, inclusive. Values proportion sample size/information spending function computed. param single, positive value specifying \\(\\rho\\) parameter Kim-DeMets spending computed; allowable range (0,50]","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPower.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kim-DeMets (power) Spending Function — sfPower","text":"object type spendfn. See Spending_Function_Overview details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPower.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Kim-DeMets (power) Spending Function — sfPower","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPower.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kim-DeMets (power) Spending Function — sfPower","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfPower.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Kim-DeMets (power) Spending Function — sfPower","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfPower.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kim-DeMets (power) Spending Function — sfPower","text":"","code":"library(ggplot2) # design a 4-analysis trial using a Kim-DeMets spending function # for both lower and upper bounds x <- gsDesign(k = 4, sfu = sfPower, sfupar = 3, sfl = sfPower, sflpar = 1.5)  # print the design x #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>            Sample #>             Size    ----Lower bounds----  ----Upper bounds----- #>   Analysis Ratio*   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1  0.282 -0.52    0.3015 0.0125 3.36    0.0004  0.0004 #>          2  0.564  0.53    0.7028 0.0229 2.76    0.0029  0.0027 #>          3  0.846  1.32    0.9072 0.0296 2.36    0.0092  0.0074 #>          4  1.128  2.03    0.9788 0.0350 2.03    0.0212  0.0145 #>      Total                        0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Kim-DeMets (power) spending function with rho = 1.5. #> ++ alpha spending: #>  Kim-DeMets (power) spending function with rho = 3. #> * Sample size ratio compared to fixed design with no interim #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3      4  Total  E{N} #>   0.0000 0.0004 0.0027 0.0073 0.0116 0.0221 0.579 #>   3.2415 0.0507 0.3248 0.3619 0.1626 0.9000 0.768 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3      4  Total #>   0.0000 0.3015 0.4138 0.2008 0.0619 0.9779 #>   3.2415 0.0125 0.0229 0.0296 0.0350 0.1000  # plot the spending function using many points to obtain a smooth curve # show rho=3 for approximation to O'Brien-Fleming and rho=.75 for # approximation to Pocock design. # Also show rho=2 for an intermediate spending. # Compare these to Hwang-Shih-DeCani spending with gamma=-4,  -2,  1 t <- 0:100 / 100 plot(t, sfPower(0.025, t, 3)$spend,   xlab = \"Proportion of sample size\",   ylab = \"Cumulative Type I error spending\",   main = \"Kim-DeMets (rho) versus Hwang-Shih-DeCani (gamma) Spending\",   type = \"l\", cex.main = .9 ) lines(t, sfPower(0.025, t, 2)$spend, lty = 2) lines(t, sfPower(0.025, t, 0.75)$spend, lty = 3) lines(t, sfHSD(0.025, t, 1)$spend, lty = 3, col = 2) lines(t, sfHSD(0.025, t, -2)$spend, lty = 2, col = 2) lines(t, sfHSD(0.025, t, -4)$spend, lty = 1, col = 2) legend(   x = c(.0, .375), y = .025 * c(.65, 1), lty = 1:3,   legend = c(\"rho= 3\", \"rho= 2\", \"rho= 0.75\") ) legend(   x = c(.0, .357), y = .025 * c(.65, .85), lty = 1:3, bty = \"n\", col = 2,   legend = c(\"gamma= -4\", \"gamma= -2\", \"gamma=1\") )"},{"path":"https://keaven.github.io/gsDesign/reference/sfSpecial.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncated, trimmed and gapped spending functions — sfTruncated","title":"Truncated, trimmed and gapped spending functions — sfTruncated","text":"functions sfTruncated() sfTrimmed apply spending function restricted range. allows eliminating spending early interim analyses desire stop bound specified; usually applied eliminate early tests positive efficacy finding. truncation can come late trial desire stop trial time , say, 90 percent information available analysis performed. allows full Type error spending final analysis occurs early. functions set cumulative spending 0 'spending interval' interval [0,1], set cumulative spending 1 range. sfTrimmed() otherwise change input spending function specified; probably preferred intuitive method cases. sfTruncated() resets time scale input spending function computed 'spending interval.' sfGapped() allows elimination analyses time point trial; see details examples. sfTrimmed simply computes value input spending function parameters sub-range [0,1], sets spending 0 range sets spending 1 range. sfGapped spends outside range provided trange. trange, input spending function used. trange, full spending used; .e., first analysis performed interval trange final analysis. long input spending function strictly increasing, means first interim interval trange final interim analysis bound specified. sfTruncated compresses spending sub-range [0,1]. parameter param$trange specifies range spending occur. Within range, spending spent according spending function specified param$sf along corresponding spending function parameter(s) param$param. See example using sfLinear spends uniformly specified range.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfSpecial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncated, trimmed and gapped spending functions — sfTruncated","text":"","code":"sfTruncated(alpha, t, param)  sfTrimmed(alpha, t, param)  sfGapped(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfSpecial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncated, trimmed and gapped spending functions — sfTruncated","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size information. t vector points increasing values 0 1, inclusive. Values proportion sample size information spending function computed. param list containing elements sf (spendfn object sfHSD), trange (range spending function increases 0 1; 0 <= trange[1]<trange[2] <=1; sfGapped, trange[1] must > 0), param (null spending function parameters scalar vector parameters needed fully specify spending function sf).","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfSpecial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncated, trimmed and gapped spending functions — sfTruncated","text":"object type spendfn. See Spending_Function_Overview details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfSpecial.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Truncated, trimmed and gapped spending functions — sfTruncated","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfSpecial.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Truncated, trimmed and gapped spending functions — sfTruncated","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfSpecial.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Truncated, trimmed and gapped spending functions — sfTruncated","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfSpecial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncated, trimmed and gapped spending functions — sfTruncated","text":"","code":"# Eliminate efficacy spending forany interim at or before 20 percent of information. # Complete spending at first interim at or after 80 percent of information. tx <- (0:100) / 100 s <- sfHSD(alpha = .05, t = tx, param = 1)$spend x <- data.frame(t = tx, Spending = s, sf = \"Original spending\") param <- list(trange = c(.2, .8), sf = sfHSD, param = 1) s <- sfTruncated(alpha = .05, t = tx, param = param)$spend x <- rbind(x, data.frame(t = tx, Spending = s, sf = \"Truncated\")) s <- sfTrimmed(alpha = .05, t = tx, param = param)$spend x <- rbind(x, data.frame(t = tx, Spending = s, sf = \"Trimmed\")) s <- sfGapped(alpha = .05, t = tx, param = param)$spend x <- rbind(x, data.frame(t = tx, Spending = s, sf = \"Gapped\")) ggplot2::ggplot(x, ggplot2::aes(x = t, y = Spending, col = sf)) +  ggplot2::geom_line()    # now apply the sfTrimmed version in gsDesign # initially, eliminate the early efficacy analysis # note: final spend must occur at > next to last interim x <- gsDesign(   k = 4, n.fix = 100, sfu = sfTrimmed,   sfupar = list(sf = sfHSD, param = 1, trange = c(.3, .9)) )  # first upper bound=20 means no testing there gsBoundSummary(x) #>   Analysis               Value Efficacy Futility #>  IA 1: 25%                   Z  20.0000  -0.5316 #>      N: 31         p (1-sided)   0.0000   0.7025 #>                ~delta at bound  11.1795  -0.2972 #>            P(Cross) if delta=0   0.0000   0.2975 #>            P(Cross) if delta=1   0.0000   0.0102 #>  IA 2: 50%                   Z   2.1555   0.4956 #>      N: 61         p (1-sided)   0.0156   0.3101 #>                ~delta at bound   0.8520   0.1959 #>            P(Cross) if delta=0   0.0155   0.7033 #>            P(Cross) if delta=1   0.6458   0.0269 #>  IA 3: 75%                   Z   2.3061   1.3812 #>      N: 92         p (1-sided)   0.0106   0.0836 #>                ~delta at bound   0.7442   0.4457 #>            P(Cross) if delta=0   0.0208   0.9208 #>            P(Cross) if delta=1   0.8136   0.0545 #>      Final                   Z   2.3352   2.3352 #>     N: 122         p (1-sided)   0.0098   0.0098 #>                ~delta at bound   0.6527   0.6527 #>            P(Cross) if delta=0   0.0242   0.9758 #>            P(Cross) if delta=1   0.9000   0.1000  # now, do not eliminate early efficacy analysis param <- list(sf = sfHSD, param = 1, trange = c(0, .9)) x <- gsDesign(k = 4, n.fix = 100, sfu = sfTrimmed, sfupar = param)  # The above means if final analysis is done a little early, all spending can occur # Suppose we set calendar date for final analysis based on # estimated full information, but come up with only 97 pct of plan xA <- gsDesign(   k = x$k, n.fix = 100, n.I = c(x$n.I[1:3], .97 * x$n.I[4]),   test.type = x$test.type,   maxn.IPlan = x$n.I[x$k],   sfu = sfTrimmed, sfupar = param ) # now accelerate without the trimmed spending function xNT <- gsDesign(   k = x$k, n.fix = 100, n.I = c(x$n.I[1:3], .97 * x$n.I[4]),   test.type = x$test.type,   maxn.IPlan = x$n.I[x$k],   sfu = sfHSD, sfupar = 1 ) # Check last bound if analysis done at early time x$upper$bound[4] #> [1] 2.357469 # Now look at last bound if done at early time with trimmed spending function # that allows capture of full alpha xA$upper$bound[4] #> [1] 2.343624 # With original spending function, we don't get full alpha and therefore have # unnecessarily stringent bound at final analysis xNT$upper$bound[4] #> [1] 2.37218  # note that if the last analysis is LATE, all 3 approaches should give the same # final bound that has a little larger z-value xlate <- gsDesign(   k = x$k, n.fix = 100, n.I = c(x$n.I[1:3], 1.25 * x$n.I[4]),   test.type = x$test.type,   maxn.IPlan = x$n.I[x$k],   sfu = sfHSD, sfupar = 1 ) xlate$upper$bound[4] #> [1] 2.435171  # eliminate futility after the first interim analysis # note that by setting trange[1] to .2, the spend at t=.2 is used for the first # interim at or after 20 percent of information x <- gsDesign(n.fix = 100, sfl = sfGapped, sflpar = list(trange = c(.2, .9), sf = sfHSD, param = 1))"},{"path":"https://keaven.github.io/gsDesign/reference/sfTDist.html","id":null,"dir":"Reference","previous_headings":"","what":"t-distribution Spending Function — sfTDist","title":"t-distribution Spending Function — sfTDist","text":"function sfTDist() provides perhaps maximum flexibility among spending functions provided gsDesign package. function allows fitting three points cumulative spending function curve; case, six parameters specified indicating x y coordinate 3 points. Normally function passed gsDesign() parameter sfu upper bound sfl lower bound specify spending function family design. case, user need know calling sequence. calling sequence useful, however, user wishes plot spending function demonstrated examples. t-distribution spending function takes form $$f(t;\\alpha)=\\alpha F(+bF^{-1}(t))$$ \\(F()\\) cumulative t-distribution function df degrees freedom \\(F^{-1}()\\) inverse.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfTDist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"t-distribution Spending Function — sfTDist","text":"","code":"sfTDist(alpha, t, param)"},{"path":"https://keaven.github.io/gsDesign/reference/sfTDist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"t-distribution Spending Function — sfTDist","text":"alpha Real value \\(> 0\\) 1. Normally, alpha=0.025 one-sided Type error specification alpha=0.1 Type II error specification. However, set 1 descriptive purposes wish see proportion spending function proportion sample size/information. t vector points increasing values 0 1, inclusive. Values proportion sample size/information spending function computed. param three-parameter specification, first paramater () may real value, second (b) positive value, third parameter (df=degrees freedom) real value 1 greater. gsDesign() called t-distribution spending function, parameterization printed.  five parameter specification c(t1,t2,u1,u2,df) objective resulting cumulative proportion spending t represented sf(t) satisfies sf(t1)=alpha*u1, sf(t2)=alpha*u2. t-distribution used df degrees freedom.  parameterization, first four values must 0 1 t1 < t2, u1 < u2.  final parameter real value 1 . parameterization can fit two points satisfying requirements.  six parameter specification attempts fit 3 points, flexibility fit three points.  case, specification param c(t1,t2,t3,u1,u2,u3) objective sf(t1)=alpha*u1, sf(t2)=alpha*u2, sf(t3)=alpha*u3. See examples see happens points specified fit.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfTDist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"t-distribution Spending Function — sfTDist","text":"object type spendfn. See spending functions details.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfTDist.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"t-distribution Spending Function — sfTDist","text":"gsDesign technical manual available   https://keaven.github.io/gsd-tech-manual/.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfTDist.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"t-distribution Spending Function — sfTDist","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/sfTDist.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"t-distribution Spending Function — sfTDist","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/sfTDist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"t-distribution Spending Function — sfTDist","text":"","code":"library(ggplot2) # 3-parameter specification: a,  b,  df sfTDist(1, 1:5 / 6, c(-1, 1.5, 4))$spend #> [1] 0.02851967 0.08253974 0.18695048 0.38823035 0.72415039  # 5-parameter specification fits 2 points,  in this case # the 1st 2 interims are at 25% and 50% of observations with # cumulative error spending of 10% and 20%, respectively # final parameter is df sfTDist(1, 1:3 / 4, c(.25, .5, .1, .2, 4))$spend #> [1] 0.1000000 0.2000000 0.3724396  # 6-parameter specification fits 3 points # Interims are at 25%. 50% and 75% of observations # with cumulative spending of 10%, 20% and 50%, respectively # Note: not all 3 point combinations can be fit sfTDist(1, 1:3 / 4, c(.25, .5, .75, .1, .2, .5))$spend #> [1] 0.1000000 0.2000000 0.5000006  # Example of error message when the 3-points specified # in the 6-parameter version cannot be fit try(sfTDist(1, 1:3 / 4, c(.25, .5, .75, .1, .2, .3))$errmsg) #> Error in sfTDist(1, 1:3/4, c(0.25, 0.5, 0.75, 0.1, 0.2, 0.3)) :  #>   6-parameter specification of t-distribution spending function did not produce a solution  # sfCauchy (sfTDist with 1 df) and sfNormal (sfTDist with infinite df) # show the limits of what sfTdist can fit # for the third point are u3 from 0.344 to 0.6 when t3=0.75 sfNormal(1, 1:3 / 4, c(.25, .5, .1, .2))$spend[3] #> [1] 0.3439558 sfCauchy(1, 1:3 / 4, c(.25, .5, .1, .2))$spend[3] #> [1] 0.6  # plot a few t-distribution spending functions fitting # t=0.25, .5 and u=0.1, 0.2 # to demonstrate the range of flexibility t <- 0:100 / 100 plot(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 1))$spend,   xlab = \"Proportion of final sample size\",   ylab = \"Cumulative Type I error spending\",   main = \"t-Distribution Spending Function Examples\", type = \"l\" ) lines(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 1.5))$spend, lty = 2) lines(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 3))$spend, lty = 3) lines(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 10))$spend, lty = 4) lines(t, sfTDist(0.025, t, c(.25, .5, .1, .2, 100))$spend, lty = 5) legend(   x = c(.0, .3), y = .025 * c(.7, 1), lty = 1:5,   legend = c(\"df = 1\", \"df = 1.5\", \"df = 3\", \"df = 10\", \"df = 100\") )"},{"path":"https://keaven.github.io/gsDesign/reference/ssrCP.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample size re-estimation based on conditional power — condPower","title":"Sample size re-estimation based on conditional power — condPower","text":"ssrCP() adapts 2-stage group sequential designs 2-stage sample size re-estimation designs based interim analysis conditional power. simple case designs developed Lehmacher Wassmer, Biometrics (1999). conditional power designs Bauer Kohne (1994),  Proschan Hunsberger (1995), Cui, Hung Wang (1999) Liu Chi (2001),  Gao, Ware Mehta (2008), Mehta Pocock (2011). Either estimated treatment effect interim analysis chosen effect size can used sample size re-estimation. done carefully, designs can inefficient. probably good idea compare design simpler group sequential design; see, example, Jennison Turnbull (2003). assumes small Type error included interim analysis design adaptation 2-stage group sequential design Related functions include 3 pre-defined combination test functions (z2NC, z2Z, z2Fisher) represent inverse normal combination test (Lehmacher Wassmer, 1999), sufficient statistic complete data, Fisher's combination test. Power.ssrCP computes unconditional power conditional power design derived ssrCP. condPower supportive routine also interesting right; computes conditional power combination test given interim test statistic, stage 2 sample size combination test statistic. returned data frame make general plotting easy, function plot.ssrCP() prints plot study sample size stage 1 outcome multiple x-axis labels stage 1 z-value, conditional power, stage 1 effect size relative effect size underlying group sequential design powered. Sample size re-estimation using conditional power interim estimate treatment effect proposed several authors 1990's (see references ). Statistical testing original methods based combination tests since Type error inflated using sufficient statistic testing end trial. Since 2000, efficient variations conditional power designs developed. Fully optimized designs also derived (Posch et , 2003, Lokhnygina Tsiatis, 2008). later conditional power methods allow use sufficient statistics testing (Chen, DeMets Lan, 2004, Gao, Ware Mehta, 2008, Mehta Pocock, 2011). methods considered extensions 2-stage group sequential designs include efficacy futility bound planned interim analysis. maximum fold-increase sample size (maxinc)supplied group sequential design (x) specified user, well range conditional power (cpadj) sample size re-estimated interim analysis, 1-targeted conditional power used sample size re-estimation (beta) combination test statistic (z2) used testing end trial. input value overrun represents incremental enrollment included interim analysis included analysis; used calculating required number patients enrolled complete trial. Whereas methods proposed based using interim estimated treatment effect size (default ssrCP), variable theta allows user specify alternative; Liu Chi (2001) suggest using parameter value trial originally powered good choice.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/ssrCP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample size re-estimation based on conditional power — condPower","text":"","code":"condPower(   z1,   n2,   z2 = z2NC,   theta = NULL,   x = gsDesign(k = 2, timing = 0.5, beta = beta),   ... )  ssrCP(   z1,   theta = NULL,   maxinc = 2,   overrun = 0,   beta = x$beta,   cpadj = c(0.5, 1 - beta),   x = gsDesign(k = 2, timing = 0.5),   z2 = z2NC,   ... )  # S3 method for ssrCP plot(   x,   z1ticks = NULL,   mar = c(7, 4, 4, 4) + 0.1,   ylab = \"Adapted sample size\",   xlaboffset = -0.2,   lty = 1,   col = 1,   ... )  z2NC(z1, x, ...)  z2Z(z1, x, n2 = x$n.I[2] - x$n.I[1], ...)  z2Fisher(z1, x, ...)  Power.ssrCP(x, theta = NULL, delta = NULL, r = 18)"},{"path":"https://keaven.github.io/gsDesign/reference/ssrCP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample size re-estimation based on conditional power — condPower","text":"z1 Scalar vector interim standardized Z-value(s). Input multiple values makes easy plot revised sample size function interim test statistic. n2 stage 2 sample size used computing sufficient statistic combining stage 1 2 test statistics. z2 combination function returns test statistic cutoff stage 2 test based interim test statistic supplied z1, design x stage 2 sample size. theta NULL (default), conditional power calculation based estimated interim treatment effect. Otherwise, theta standardized effect size used conditional power calculation. Using alternate hypothesis treatment effect can efficient estimated effect size; see Liu Chi, Biometrics (2001). x group sequential design 2 stages (k=2) generated gsDesign. plot.ssrCP, x design returned ssrCP(). ... Allows passing arguments may needed user-supplied function, codez2. case plot.ssrCP(), allows passing graphical parameters. maxinc Maximum fold-increase planned maximum sample size underlying group sequential design provided x. overrun number patients enrolled interim analysis completed included interim analysis. beta Targeted Type II error (1 - targeted conditional power); used conditional power sample size reestimation. cpadj Range values strictly 0 1 specifying range interim conditional power sample size re-estimation performed. Outside range, sample size supplied x used. z1ticks Test statistic values tick marks made x-axis; automatically calculated default NULL mar Plot margins; see help par ylab y-axis label xlaboffset offset x-axis printing x-axis labels lty line type stage 2 sample size col line color stage 2 sample size delta Natural parameter values power calculation; see gsDesign description related theta. r Integer value controlling grid numerical integration Jennison Turnbull (2000); default 18, range 1 80.  Larger values provide larger number grid points greater accuracy.  Normally r changed user.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/ssrCP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample size re-estimation based on conditional power — condPower","text":"ssrCP returns list following items: x input. z2fn input z2. theta standardize effect size used conditional power; NULL input, computed z1/sqrt(n1) n1 stage 1 sample size. maxinc input. overrun input. beta input. cpadj input. dat data frame containing input z1 values, computed cutoffs standard normal test statistic based solely stage 2 data (z2), stage 2 sample sizes (n2), stage 2 conditional power (CP), standardize effect size used conditional power calculation (theta), natural parameter value corresponding theta (delta). relation theta delta determined delta0 delta1 values x: delta = delta0 + theta(delta1-delta0).","code":""},{"path":"https://keaven.github.io/gsDesign/reference/ssrCP.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample size re-estimation based on conditional power — condPower","text":"Bauer, Peter Kohne, F., Evaluation experiments adaptive interim analyses, Biometrics, 50:1029-1041, 1994. Chen, YHJ, DeMets, DL Lan, KKG. Increasing sample size unblinded interim result promising, Statistics Medicine, 23:1023-1038, 2004. Gao, P, Ware, JH Mehta, C, Sample size re-estimation adaptive sequential design clinical trials, Journal Biopharmaceutical Statistics\", 18:1184-1196, 2008. Jennison, C Turnbull, BW.  Mid-course sample size modification clinical trials based observed treatment effect. Statistics Medicine, 22:971-993\", 2003. Lehmacher, W Wassmer, G. Adaptive sample size calculations group sequential trials, Biometrics, 55:1286-1290, 1999. Liu, Q Chi, GY., sample size inference two-stage adaptive designs, Biometrics, 57:172-177, 2001. Mehta, C Pocock, S. Adaptive increase sample size interim results promising: practical guide examples, Statistics Medicine, 30:3267-3284, 2011.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/ssrCP.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample size re-estimation based on conditional power — condPower","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/ssrCP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample size re-estimation based on conditional power — condPower","text":"","code":"library(ggplot2) # quick trick for simple conditional power based on interim z-value, stage 1 and 2 sample size # assumed treatment effect and final alpha level # and observed treatment effect alpha <- .01 # set final nominal significance level timing <- .6 # set proportion of sample size, events or statistical information at IA n2 <- 40 # set stage 2 sample size events or statistical information hr <- .6 # for this example we will derive conditional power based on hazard ratios n.fix <- nEvents(hr=hr,alpha=alpha) # you could otherwise make n.fix an arbitrary positive value # this just derives a group sequential design that should not change sample size from n.fix # due to stringent IA bound x <- gsDesign(k=2,n.fix=n.fix,alpha=alpha,test.type=1,sfu=sfHSD, sfupar=-20,timing=timing,delta1=log(hr)) # derive effect sizes for which you wish to compute conditional power hrpostIA = seq(.4,1,.05) # in the following, we convert HR into standardized effect size based on the design in x powr <- condPower(x=x,z1=1,n2=x$n.I[2]-x$n.I[1],theta=log(hrpostIA)/x$delta1*x$theta[2]) ggplot(   data.frame(     x = hrpostIA,     y = condPower(       x = x,       z1 = 1,       n2 = x$n.I[2] - x$n.I[1],       theta = log(hrpostIA) / x$delta1 * x$theta[2]     )   ),   aes(x = x, y = y) ) +   geom_line() +   labs(     x = \"HR post IA\",     y = \"Conditional power\",     title = \"Conditional power as a function of assumed HR\"   )   # Following is a template for entering parameters for ssrCP # Natural parameter value null and alternate hypothesis values delta0 <- 0 delta1 <- 1 # timing of interim analysis for underlying group sequential design timing <- .5 # upper spending function sfu <- sfHSD # upper spending function paramater sfupar <- -12 # maximum sample size inflation maxinflation <- 2 # assumed enrollment overrrun at IA overrun <- 25 # interim z-values for plotting z <- seq(0, 4, .025) # Type I error (1-sided) alpha <- .025 # Type II error for design beta <- .1 # Fixed design sample size n.fix <- 100 # conditional power interval where sample # size is to be adjusted cpadj <- c(.3, .9) # targeted Type II error when adapting sample size betastar <- beta # combination test (built-in options are: z2Z, z2NC, z2Fisher) z2 <- z2NC  # use the above parameters to generate design # generate a 2-stage group sequential design with x <- gsDesign(   k = 2, n.fix = n.fix, timing = timing, sfu = sfu, sfupar = sfupar,   alpha = alpha, beta = beta, delta0 = delta0, delta1 = delta1 ) # extend this to a conditional power design xx <- ssrCP(   x = x, z1 = z, overrun = overrun, beta = betastar, cpadj = cpadj,   maxinc = maxinflation, z2 = z2 ) # plot the stage 2 sample size plot(xx) # demonstrate overlays on this plot # overlay with densities for z1 under different hypotheses lines(z, 80 + 240 * dnorm(z, mean = 0), col = 2) lines(z, 80 + 240 * dnorm(z, mean = sqrt(x$n.I[1]) * x$theta[2]), col = 3) lines(z, 80 + 240 * dnorm(z, mean = sqrt(x$n.I[1]) * x$theta[2] / 2), col = 4) lines(z, 80 + 240 * dnorm(z, mean = sqrt(x$n.I[1]) * x$theta[2] * .75), col = 5) axis(side = 4, at = 80 + 240 * seq(0, .4, .1), labels = as.character(seq(0, .4, .1))) mtext(side = 4, expression(paste(\"Density for \", z[1])), line = 2) text(x = 1.5, y = 90, col = 2, labels = expression(paste(\"Density for \", theta, \"=0\"))) text(x = 3.00, y = 180, col = 3, labels = expression(paste(\"Density for \", theta, \"=\",  theta[1]))) text(x = 1.00, y = 180, col = 4, labels = expression(paste(\"Density for \", theta, \"=\",  theta[1], \"/2\"))) text(x = 2.5, y = 140, col = 5, labels = expression(paste(\"Density for \", theta, \"=\",  theta[1], \"*.75\"))) # overall line for max sample size nalt <- xx$maxinc * x$n.I[2] lines(x = par(\"usr\")[1:2], y = c(nalt, nalt), lty = 2)   # compare above design with different combination tests # use sufficient statistic for final testing xxZ <- ssrCP(   x = x, z1 = z, overrun = overrun, beta = betastar, cpadj = cpadj,   maxinc = maxinflation, z2 = z2Z ) # use Fisher combination test for final testing xxFisher <- ssrCP(   x = x, z1 = z, overrun = overrun, beta = betastar, cpadj = cpadj,   maxinc = maxinflation, z2 = z2Fisher ) # combine data frames from these designs y <- rbind(   data.frame(cbind(xx$dat, Test = \"Normal combination\")),   data.frame(cbind(xxZ$dat, Test = \"Sufficient statistic\")),   data.frame(cbind(xxFisher$dat, Test = \"Fisher combination\")) ) # plot stage 2 statistic required for positive combination test ggplot2::ggplot(data = y, ggplot2::aes(x = z1, y = z2, col = Test)) +  ggplot2::geom_line()  # plot total sample size versus stage 1 test statistic ggplot2::ggplot(data = y, ggplot2::aes(x = z1, y = n2, col = Test)) +  ggplot2::geom_line()  # check achieved Type I error for sufficient statistic design Power.ssrCP(x = xxZ, theta = 0) #>   theta delta     Power       en #> 1     0     0 0.0220804 95.11565  # compare designs using observed vs planned theta for conditional power xxtheta1 <- ssrCP(   x = x, z1 = z, overrun = overrun, beta = betastar, cpadj = cpadj,   maxinc = maxinflation, z2 = z2, theta = x$delta ) # combine data frames for the 2 designs y <- rbind(   data.frame(cbind(xx$dat, \"CP effect size\" = \"Obs. at IA\")),   data.frame(cbind(xxtheta1$dat, \"CP effect size\" = \"Alt. hypothesis\")) ) # plot stage 2 sample size by design ggplot2::ggplot(data = y, ggplot2::aes(x = z1, y = n2, col = CP.effect.size)) +  ggplot2::geom_line()  # compare power and expected sample size y1 <- Power.ssrCP(x = xx) y2 <- Power.ssrCP(x = xxtheta1) # combine data frames for the 2 designs y3 <- rbind(   data.frame(cbind(y1, \"CP effect size\" = \"Obs. at IA\")),   data.frame(cbind(y2, \"CP effect size\" = \"Alt. hypothesis\")) ) # plot expected sample size by design and effect size ggplot2::ggplot(data = y3, ggplot2::aes(x = delta, y = en, col = CP.effect.size)) +  ggplot2::geom_line() + ggplot2::xlab(expression(delta)) +  ggplot2::ylab(\"Expected sample size\")  # plot power by design and effect size ggplot2::ggplot(data = y3, ggplot2::aes(x = delta, y = Power, col = CP.effect.size)) +  ggplot2::geom_line() +  ggplot2::xlab(expression(delta))"},{"path":"https://keaven.github.io/gsDesign/reference/toBinomialExact.html","id":null,"dir":"Reference","previous_headings":"","what":"Translate survival design bounds to exact binomial bounds — toBinomialExact","title":"Translate survival design bounds to exact binomial bounds — toBinomialExact","text":"Translate survival design bounds exact binomial bounds","code":""},{"path":"https://keaven.github.io/gsDesign/reference/toBinomialExact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Translate survival design bounds to exact binomial bounds — toBinomialExact","text":"","code":"toBinomialExact(x)"},{"path":"https://keaven.github.io/gsDesign/reference/toBinomialExact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Translate survival design bounds to exact binomial bounds — toBinomialExact","text":"x object class gsSurv; .e., object generated gsSurv() function.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/toBinomialExact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Translate survival design bounds to exact binomial bounds — toBinomialExact","text":"object class gsBinomialExact.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/toBinomialExact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Translate survival design bounds to exact binomial bounds — toBinomialExact","text":"","code":"# The following code derives the group sequential design using the method # of Lachin and Foulkes  x <- gsSurv(   k = 3,                 # 3 analyses   test.type = 4,         # Non-binding futility bound 1 (no futility bound) and 4 are allowable   alpha = .025,          # 1-sided Type I error   beta = .1,             # Type II error (1 - power)   timing = c(0.45, 0.7), # Proportion of final planned events at interims   sfu = sfHSD,           # Efficacy spending function   sfupar = -4,           # Parameter for efficacy spending function   sfl = sfLDOF,          # Futility spending function; not needed for test.type = 1   sflpar = 0,            # Parameter for futility spending function   lambdaC = .001,        # Exponential failure rate   hr = 0.3,              # Assumed proportional hazard ratio (1 - vaccine efficacy = 1 - VE)   hr0 = 0.7,             # Null hypothesis VE   eta = 5e-04,           # Exponential dropout rate   gamma = 10,            # Piecewise exponential enrollment rates   R = 16,                # Time period durations for enrollment rates in gamma   T = 24,                # Planned trial duration   minfup = 8,            # Planned minimum follow-up   ratio = 3              # Randomization ratio (experimental:control) ) # Convert bounds to exact binomial bounds toBinomialExact(x) #>              Bounds #>   Analysis   N   a   b #>          1  31  12  22 #>          2  48  23  30 #>          3  69  38  39 #>  #> Boundary crossing probabilities and expected sample size assume #> any cross stops the trial #>  #> Upper boundary #>           Analysis #>    Theta      1      2      3  Total E{N} #>   0.6774 0.4328 0.3960 0.1523 0.9811 44.1 #>   0.4737 0.0068 0.0206 0.0578 0.0851 52.2 #>  #> Lower boundary #>           Analysis #>    Theta      1      2      3  Total #>   0.6774 0.0008 0.0030 0.0151 0.0189 #>   0.4737 0.2167 0.3767 0.3215 0.9149"},{"path":"https://keaven.github.io/gsDesign/reference/toInteger.html","id":null,"dir":"Reference","previous_headings":"","what":"Translate group sequential design to integer events (survival designs)\nor sample size (other designs) — toInteger","title":"Translate group sequential design to integer events (survival designs)\nor sample size (other designs) — toInteger","text":"Translate group sequential design integer events (survival designs) sample size (designs)","code":""},{"path":"https://keaven.github.io/gsDesign/reference/toInteger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Translate group sequential design to integer events (survival designs)\nor sample size (other designs) — toInteger","text":"","code":"toInteger(x, ratio = 0, roundUpFinal = TRUE)"},{"path":"https://keaven.github.io/gsDesign/reference/toInteger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Translate group sequential design to integer events (survival designs)\nor sample size (other designs) — toInteger","text":"x object class gsDesign. ratio Integer indicating randomization ratio; used time--event outcome; see details. roundUpFinal Final value returned n.rounded TRUE; otherwise, just rounded.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/toInteger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Translate group sequential design to integer events (survival designs)\nor sample size (other designs) — toInteger","text":"object class gsDesign integer vector n..","code":""},{"path":"https://keaven.github.io/gsDesign/reference/toInteger.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Translate group sequential design to integer events (survival designs)\nor sample size (other designs) — toInteger","text":"Note ratio 0, rounding n.done nearest integer. input x class gsSurv (time--event outcome), ratio taken input x rather value provided ratio argument. cases gsSurv class, rounding final.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/toInteger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Translate group sequential design to integer events (survival designs)\nor sample size (other designs) — toInteger","text":"","code":"# The following code derives the group sequential design using the method # of Lachin and Foulkes  x <- gsSurv(   k = 3,                 # 3 analyses   test.type = 4,         # Non-binding futility bound 1 (no futility bound) and 4 are allowable   alpha = .025,          # 1-sided Type I error   beta = .1,             # Type II error (1 - power)   timing = c(0.45, 0.7), # Proportion of final planned events at interims   sfu = sfHSD,           # Efficacy spending function   sfupar = -4,           # Parameter for efficacy spending function   sfl = sfLDOF,          # Futility spending function; not needed for test.type = 1   sflpar = 0,            # Parameter for futility spending function   lambdaC = .001,        # Exponential failure rate   hr = 0.3,              # Assumed proportional hazard ratio (1 - vaccine efficacy = 1 - VE)   hr0 = 0.7,             # Null hypothesis VE   eta = 5e-04,           # Exponential dropout rate   gamma = 10,            # Piecewise exponential enrollment rates   R = 16,                # Time period durations for enrollment rates in gamma   T = 24,                # Planned trial duration   minfup = 8,            # Planned minimum follow-up   ratio = 3              # Randomization ratio (experimental:control) ) # Convert bounds to exact binomial bounds toInteger(x, ratio = 3) #> Time to event group sequential design with HR= 0.3  #> Non-inferiority design with null HR= 0.7  #> Randomization (Exp/Control):  ratio= 3  #> Asymmetric two-sided group sequential design with #> 90 % power and 2.5 % Type I Error. #> Upper bound spending computations assume #> trial continues if lower bound is crossed. #>  #>                ----Lower bounds----  ----Upper bounds----- #>   Analysis N   Z   Nominal p Spend+  Z   Nominal p Spend++ #>          1 31 0.07    0.5277 0.0141 2.83    0.0023  0.0023 #>          2 48 1.11    0.8673 0.0345 2.52    0.0059  0.0047 #>          3 69 2.00    0.9774 0.0514 2.00    0.0226  0.0179 #>      Total                   0.1000                 0.0250  #> + lower bound beta spending (under H1): #>  Lan-DeMets O'Brien-Fleming approximation spending function with none = 1. #> ++ alpha spending: #>  Hwang-Shih-DeCani spending function with gamma = -4. #>  #> Boundary crossing probabilities and expected sample size #> assume any cross stops the trial #>  #> Upper boundary (power or Type I Error) #>           Analysis #>    Theta      1      2      3  Total E{N} #>   0.0000 0.0023 0.0047 0.0159 0.0230 41.5 #>   0.4065 0.2863 0.3402 0.2762 0.9027 49.7 #>  #> Lower boundary (futility or Type II Error) #>           Analysis #>    Theta      1      2      3  Total #>   0.0000 0.5277 0.3439 0.1054 0.9770 #>   0.4065 0.0141 0.0345 0.0487 0.0973 #>              T        n   Events HR futility HR efficacy #> IA 1  15.22419 8624.502 30.99999       0.680       0.217 #> IA 2  19.23447 9064.000 48.00004       0.483       0.302 #> Final 24.19069 9064.000 69.00000       0.401       0.401 #> Accrual rates: #>      Stratum 1 #> 0-16     566.5 #> Control event rates (H1): #>       Stratum 1 #> 0-Inf         0 #> Censoring rates: #>       Stratum 1 #> 0-Inf         0"},{"path":"https://keaven.github.io/gsDesign/reference/varBinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Testing, Confidence Intervals, Sample Size and Power for Comparing Two\nBinomial Rates — ciBinomial","title":"Testing, Confidence Intervals, Sample Size and Power for Comparing Two\nBinomial Rates — ciBinomial","text":"Support provided sample size estimation, power, testing, confidence intervals simulation fixed sample size trials (, group sequential adaptive) two arms binary outcomes.  superiority non-inferiority trials considered. routines default comparisons risk-difference, options base computations risk-ratio odds-ratio also included. nBinomial() computes sample size power using method Farrington Manning (1990) trial test difference two binomial event rates.  routine can used test superiority non-inferiority. design tests superiority nBinomial() consistent method Fleiss, Tytun, Ury (without continuity correction) test differences event rates. routine consistent Hmisc package routines bsamsize bpower superiority designs. Vector arguments allow computing sample sizes multiple scenarios comparative purposes. testBinomial() computes Z- Chi-square-statistic compares two binomial event rates using method Miettinen Nurminen (1980). can used superiority non-inferiority testing. Vector arguments allow easy incorporation simulation routines fixed, group sequential adaptive designs. ciBinomial() computes confidence intervals 1) difference two rates, 2) risk-ratio two rates 3) odds-ratio two rates. procedure provides inference consistent testBinomial() confidence intervals produced inverting testing procedures testBinomial(). Type error alpha input ciBinomial always interpreted 2-sided. simBinomial() performs simulations estimate power Miettinen Nurminen (1985) test comparing two binomial rates superiority non-inferiority.  noted documentation bpower.sim() HMisc package, using testBinomial() can see formulas without continuity correction quite accurate.  fact, Type error continuity-corrected test significantly lower (Gordon Watson, 1996) nominal rate.  Thus, default continuity corrections performed. varBinomial computes blinded estimates variance estimate 1) event rate differences, 2) logarithm risk ratio, 3) logarithm odds ratio. intended blinded sample size re-estimation comparative trials binary outcome. Testing 2-sided Chi-square statistic used 1-sided Z-statistic used. Thus, 2 options produce substantially different results, general. non-inferiority, 1-sided testing appropriate. may wish round sample sizes using ceiling(). Farrington Manning (1990) begin event rates p1 p2 alternative hypothesis difference rates null hypothesis, delta0. values, actual rates null hypothesis computed, labeled p10 p20 outtype=3. rates p1 p2 used compute variance Z-test comparing rates alternative hypothesis, p10 p20 used null hypothesis. computational method also used estimate variances varBinomial() based overall event rate observed input treatment difference specified delta0. Sample size scale=\"Difference\" produces error p1-p2=delta0.  Normally, alternative hypothesis consideration p1-p2-delta0$>0$. However, alternative can p1-p2-delta0$<0$.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/varBinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Testing, Confidence Intervals, Sample Size and Power for Comparing Two\nBinomial Rates — ciBinomial","text":"","code":"ciBinomial(x1, x2, n1, n2, alpha = 0.05, adj = 0, scale = \"Difference\")  nBinomial(   p1,   p2,   alpha = 0.025,   beta = 0.1,   delta0 = 0,   ratio = 1,   sided = 1,   outtype = 1,   scale = \"Difference\",   n = NULL )  simBinomial(   p1,   p2,   n1,   n2,   delta0 = 0,   nsim = 10000,   chisq = 0,   adj = 0,   scale = \"Difference\" )  testBinomial(   x1,   x2,   n1,   n2,   delta0 = 0,   chisq = 0,   adj = 0,   scale = \"Difference\",   tol = 1e-11 )  varBinomial(x, n, delta0 = 0, ratio = 1, scale = \"Difference\")"},{"path":"https://keaven.github.io/gsDesign/reference/varBinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Testing, Confidence Intervals, Sample Size and Power for Comparing Two\nBinomial Rates — ciBinomial","text":"x1 Number “successes” control group x2 Number “successes” experimental group n1 Number observations control group n2 Number observations experimental group alpha type error; see sided distinguish 1- 2-sided tests adj adj=1, standard variance continuity correction used Miettinen Nurminen test statistic includes factor \\(n / (n - 1)\\) \\(n\\) total sample size. adj 1, factor applied. default adj=0 since nominal Type error generally conservative adj=1 (Gordon Watson, 1996). scale “Difference”, “RR”, “”; see scale parameter documentation Details.  scalar argument. p1 event rate group 1 alternative hypothesis p2 event rate group 2 alternative hypothesis beta type II error delta0 value 0 (default) always represents difference treatment groups null hypothesis. delta0 interpreted differently depending value parameter scale.  scale=\"Difference\" (default), delta0 difference event rates null hypothesis (p10 - p20). scale=\"RR\", delta0 logarithm relative risk event rates (p10 / p20) null hypothesis. scale=\"LNOR\", delta0 difference natural logarithm odds-ratio null hypothesis log(p10 / (1 - p10)) - log(p20 / (1 - p20)). ratio sample size ratio group 2 divided group 1 sided 2 2-sided test, 1 1-sided test outtype nBinomial ; 1 (default) returns total sample size; 2 returns data frame sample size group (n1, n2; n input NULL, power returned Power; 3 returns data frame total sample size (n), sample size group (n1, n2), Type error (alpha), 1 2 (sided, input), Type II error (beta), power (Power), null alternate hypothesis standard deviations (sigma0, sigma1), input event rates (p1, p2), null hypothesis difference treatment group means (delta0) null hypothesis event rates (p10, p20). n power computed nBinomial(), input total trial sample size n; may vector. also sample size varBinomial, case argument must scalar. nsim number simulations performed simBinomial() chisq indicator whether chi-square (opposed Z) statistic computed. delta0=0 (default), difference event rates divided standard error null hypothesis used. Otherwise, Miettinen Nurminen chi-square statistic 2 x 2 table used. tol Default probably used; used deal rounding issue interim calculations x Number “successes” combined control experimental groups.","code":""},{"path":"https://keaven.github.io/gsDesign/reference/varBinomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Testing, Confidence Intervals, Sample Size and Power for Comparing Two\nBinomial Rates — ciBinomial","text":"testBinomial() simBinomial() return vector either Chi-square Z test statistics.  may compared appropriate cutoff point (e.g., qnorm(.975) normal qchisq(.95,1) chi-square). ciBinomial() returns data frame 1 row confidence interval; variable names lower upper. varBinomial() returns vector (blinded) variance estimates difference event rates (scale=\"Difference\"), logarithm odds-ratio (scale=\"\") logarithm risk-ratio (scale=\"RR\"). default outtype=1, nBinomial() returns vector total sample sizes returned.  outtype=2, nBinomial() returns data frame containing two vectors n1 n2 containing sample sizes groups 1 2, respectively; n input, option also returns power third vector, Power. outtype=3, nBinomial() returns data frame following columns: n vector total samples size required event rate comparison specified n1 vector sample sizes group 1 event rate comparison specified n2 vector sample sizes group 2 event rate comparison specified alpha input sided input beta input; n input, computed Power n=NULL input, 1-beta; otherwise, power computed sample size input sigma0 vector containing standard deviation treatment effect difference null hypothesis times sqrt(n) scale=\"Difference\" scale=\"\"; scale=\"RR\", standard deviation time sqrt(n) numerator Farrington-Manning test statistic x1-exp(delta0)*x2. sigma1 vector containing values sigma0, case estimated alternative hypothesis. p1 input p2 input p10 group 1 event rate used null hypothesis p20 group 2 event rate used null hypothesis","code":""},{"path":"https://keaven.github.io/gsDesign/reference/varBinomial.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Testing, Confidence Intervals, Sample Size and Power for Comparing Two\nBinomial Rates — ciBinomial","text":"Farrington, CP Manning, G (1990), Test statistics sample size formulae comparative binomial trials null hypothesis non-zero risk difference non-unity relative risk. Statistics Medicine; 9: 1447-1454. Fleiss, JL, Tytun, Ury (1980), simple approximation calculating sample sizes comparing independent proportions. Biometrics;36:343-346. Gordon, Watson R (1985), myth continuity-corrected sample size formulae. Biometrics; 52: 71-76. Miettinen, O Nurminen, M (1985), Comparative analysis two rates. Statistics Medicine; 4 : 213-226.","code":""},{"path":[]},{"path":"https://keaven.github.io/gsDesign/reference/varBinomial.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Testing, Confidence Intervals, Sample Size and Power for Comparing Two\nBinomial Rates — ciBinomial","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://keaven.github.io/gsDesign/reference/varBinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Testing, Confidence Intervals, Sample Size and Power for Comparing Two\nBinomial Rates — ciBinomial","text":"","code":"# Compute z-test test statistic comparing 39/500 to 13/500 # use continuity correction in variance x <- testBinomial(x1 = 39, x2 = 13, n1 = 500, n2 = 500, adj = 1) x #> [1] 3.701266 pnorm(x, lower.tail = FALSE) #> [1] 0.0001072634  # Compute with unadjusted variance x0 <- testBinomial(x1 = 39, x2 = 23, n1 = 500, n2 = 500) x0 #> [1] 2.098083 pnorm(x0, lower.tail = FALSE) #> [1] 0.0179489  # Perform 50k simulations to test validity of the above # asymptotic p-values # (you may want to perform more to reduce standard error of estimate) sum(as.double(x0) <=   simBinomial(p1 = .078, p2 = .078, n1 = 500, n2 = 500, nsim = 10000)) / 10000 #> [1] 0.0166 sum(as.double(x0) <=   simBinomial(p1 = .052, p2 = .052, n1 = 500, n2 = 500, nsim = 10000)) / 10000 #> [1] 0.0187  # Perform a non-inferiority test to see if p2=400 / 500 is within 5% of # p1=410 / 500 use a z-statistic with unadjusted variance x <- testBinomial(x1 = 410, x2 = 400, n1 = 500, n2 = 500, delta0 = -.05) x #> [1] 2.807617 pnorm(x, lower.tail = FALSE) #> [1] 0.002495478  # since chi-square tests equivalence (a 2-sided test) rather than # non-inferiority (a 1-sided test), # the result is quite different pchisq(testBinomial(   x1 = 410, x2 = 400, n1 = 500, n2 = 500, delta0 = -.05,   chisq = 1, adj = 1 ), 1, lower.tail = FALSE) #> [1] 0.005012758  # now simulate the z-statistic witthout continuity corrected variance sum(qnorm(.975) <=   simBinomial(p1 = .8, p2 = .8, n1 = 500, n2 = 500, nsim = 100000)) / 100000 #> [1] 0.02429  # compute a sample size to show non-inferiority # with 5% margin, 90% power nBinomial(p1 = .2, p2 = .2, delta0 = .05, alpha = .025, sided = 1, beta = .1) #> [1] 2697.607  # assuming a slight advantage in the experimental group lowers # sample size requirement nBinomial(p1 = .2, p2 = .19, delta0 = .05, alpha = .025, sided = 1, beta = .1) #> [1] 4131.9  # compute a sample size for comparing 15% vs 10% event rates # with 1 to 2 randomization nBinomial(p1 = .15, p2 = .1, beta = .2, ratio = 2, alpha = .05) #> [1] 1191.041  # now look at total sample size using 1-1 randomization n <- nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05) n #> [1] 1079.853 # check if inputing sample size returns the desired power nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, n = n) #> [1] 0.8  # re-do with alternate output types nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, outtype = 2) #>         n1       n2 #> 1 539.9264 539.9264 nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, outtype = 3) #>          n       n1       n2 alpha sided beta Power    sigma0    sigma1   p1 #> 1 1079.853 539.9264 539.9264  0.05     1  0.2   0.8 0.6614378 0.6595453 0.15 #>    p2 delta0   p10   p20 #> 1 0.1      0 0.125 0.125  # look at power plot under different control event rate and # relative risk reductions library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union library(ggplot2) p1 <- seq(.075, .2, .000625) len <- length(p1) p2 <- c(p1 * .75, p1 * 2/3, p1 * .6, p1 * .5) Reduction <- c(rep(\"25 percent\", len), rep(\"33 percent\", len),                 rep(\"40 percent\", len), rep(\"50 percent\", len)) df <- tibble(p1 = rep(p1, 4), p2, Reduction) %>%    mutate(`Sample size` = nBinomial(p1, p2, beta = .2, alpha = .025, sided = 1)) ggplot(df, aes(x = p1, y = `Sample size`, col = Reduction)) +    geom_line() +    xlab(\"Control group event rate\") +   ylim(0,6000) +   ggtitle(\"Binomial sample size computation for 80 pct power\")   # compute blinded estimate of treatment effect difference x1 <- rbinom(n = 1, size = 100, p = .2) x2 <- rbinom(n = 1, size = 200, p = .1) # blinded estimate of risk difference variance varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0) #> [1] 0.002083333 # blinded estimate of log-risk-ratio variance varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0, scale = \"RR\") #> [1] 0.075 # blinded estimate of log-odds-ratio variance varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0, scale = \"OR\") #> [1] 0.108"},{"path":"https://keaven.github.io/gsDesign/reference/xtable.html","id":null,"dir":"Reference","previous_headings":"","what":"xtable — xtable","title":"xtable — xtable","text":"xtable","code":""},{"path":"https://keaven.github.io/gsDesign/reference/xtable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"xtable — xtable","text":"object class \"xtable\"","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-350-july-2023","dir":"Changelog","previous_headings":"","what":"gsDesign 3.5.0 (July, 2023)","title":"gsDesign 3.5.0 (July, 2023)","text":"sfPower() now allows wider parameter range (0, 15]. toInteger() function added convert gsDesign gsSurv classes integer sample size event counts. toBinomialExact() function added convert time--event bounds exact binomial low event rate studies. Added “Gentle Introduction Group Sequential Design” vignette introduction asymptotics group sequential design. as_table() as_gt() methods gsBinomialExact objects added, described new “Binomial SPRT” vignette. plot.ssrCP(), hat syntax mathematical expression revised, resolving labeling issues. ggplot2::qplot() usage replaced due deprecation ggplot2 3.4.0. Link update gsDesign manual documentation, now directly pointing gsDesign technical manual bookdown project. Introduced new hex sticker logo.","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-340-october-2022","dir":"Changelog","previous_headings":"","what":"gsDesign 3.4.0 (October, 2022)","title":"gsDesign 3.4.0 (October, 2022)","text":"CRAN release: 2022-10-12 Removed restriction gsCP() interim test statistic zi (#63). Removed gMCP dependency. Updated vignettes linked vignettes gMCPLite (#69). Added deprecation warning hGraph() suggested using gMCPLite::hGraph() instead (#70). Moved ggplot2 Depends Imports (#56).","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-330-may-2022","dir":"Changelog","previous_headings":"","what":"gsDesign 3.3.0 (May, 2022)","title":"gsDesign 3.3.0 (May, 2022)","text":"CRAN release: 2022-05-27 Demonstrate cure model calendar-based analysis timing time--event endpoint design Vaccine efficacy design using spending bounds exact binomial boundary crossing probabilities Minor fix labeling print.gsProbability Fixed error sfStep Updates reduce R CMD check minor issues","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-322-january-2022","dir":"Changelog","previous_headings":"","what":"gsDesign 3.2.2 (January, 2022)","title":"gsDesign 3.2.2 (January, 2022)","text":"CRAN release: 2022-02-02 Use inherits() instead () determine object instance class, appropriate Correctly close graphics device unit tests avoid plot output file found issues Minor fixes hGraph() multiplicity graphs Minor fix nBinomial() odds-ratio scale specified resolve user issue Minor changes vignettes","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-321-july-2021","dir":"Changelog","previous_headings":"","what":"gsDesign 3.2.1 (July, 2021)","title":"gsDesign 3.2.1 (July, 2021)","text":"CRAN release: 2021-07-12 Changed gt package usage vignette due deprecated gt function Replied minor comments CRAN reviewer (functionality impact) Minor update DESCRIPTION citing Jennison Turnbull reference","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-320-january-2021","dir":"Changelog","previous_headings":"","what":"gsDesign 3.2.0 (January, 2021)","title":"gsDesign 3.2.0 (January, 2021)","text":"CRAN release: 2021-03-13 Substantially updated unit testing increase code coverage 80% Updated error checking messages print function check fails Removed dependencies plyr packages Updated github actions","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-311-may-2020","dir":"Changelog","previous_headings":"","what":"gsDesign 3.1.1 (May, 2020)","title":"gsDesign 3.1.1 (May, 2020)","text":"CRAN release: 2020-05-07 Vignettes updated Added hGraph() support ggplot2 versions multiplicity graphs Eliminated unnecessary check sequentialPValue Targeted release CRAN Removed dependencies reshape2, plyr Updated continuous integration Updated license","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-310-april-2019","dir":"Changelog","previous_headings":"","what":"gsDesign 3.1.0 (April, 2019)","title":"gsDesign 3.1.0 (April, 2019)","text":"Addition pkgdown web site Updated unit testing RUnit testthat Converted roxygen2 generation help files Converted vignettes R Markdown Added Travis-CI Appveyor support Added sequentialPValue function Backwards compatible addition spending time capabilities gsDesign gsSurv","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-30-5-january-2018","dir":"Changelog","previous_headings":"","what":"gsDesign 3.0-5 (January, 2018)","title":"gsDesign 3.0-5 (January, 2018)","text":"Registered C routines Fixed “gsbound” Replaced “array” “rep” calls avoid R CMD check warnings","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-30-4-september-2017","dir":"Changelog","previous_headings":"","what":"gsDesign 3.0-4 (September, 2017)","title":"gsDesign 3.0-4 (September, 2017)","text":"First Github-based release Cleaned documentation nBinomial1Sample() Updated documentation code (including one default value argument) nBinomial1Sample() improve error handling clarity Updated sfLDOF() generalize rho parameter; still backwards compatible Lan-DeMets O’Brien-Fleming","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-30-3","dir":"Changelog","previous_headings":"","what":"gsDesign 3.0-3","title":"gsDesign 3.0-3","text":"Introduced spending time separate concept information time enable concepts calendar-based spending functions. user function changed gsDesign() function change addition parameters usTime lsTime; default behavior backwards compatible.","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-30-2-february-2016","dir":"Changelog","previous_headings":"","what":"gsDesign 3.0-2 (February, 2016)","title":"gsDesign 3.0-2 (February, 2016)","text":"Simplified conditional power section gsDesignManual.pdf doc directory Corrected basic calculation gsCP() Eliminated deprecated ggplot2 function opts()","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-30-1-january-2016","dir":"Changelog","previous_headings":"","what":"gsDesign 3.0-1 (January, 2016)","title":"gsDesign 3.0-1 (January, 2016)","text":"CRAN release: 2016-02-01 changes comply R standards (NAMESPACE - importFrom statements - DESCRIPTION - adding plyr imports) ensuring appropriate references. Deleted link documentation longer exists (gsBinomialExact.Rd). Last planned RForge-based release; moving Github.","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-30-0-december-2015","dir":"Changelog","previous_headings":"","what":"gsDesign 3.0-0 (December, 2015)","title":"gsDesign 3.0-0 (December, 2015)","text":"Updated xtable extension meet R standards extensions. Fixed xtable.gsSurv print.gsSurv work 1-sided designs Update calls ggplot replace show_guide (deprecated) show.legend arguments used ggplot2::geom_text calls; user impact Minor typo fixed sfLogistic help file Cleaned “imports” “depends” effort R “good citizen” Registered S3 methods NAMESPACE","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-29-4","dir":"Changelog","previous_headings":"","what":"gsDesign 2.9-4","title":"gsDesign 2.9-4","text":"Minor edit package description comply R standards","code":""},{"path":"https://keaven.github.io/gsDesign/news/index.html","id":"gsdesign-29-3-november-2014","dir":"Changelog","previous_headings":"","what":"gsDesign 2.9-3 (November, 2014)","title":"gsDesign 2.9-3 (November, 2014)","text":"CRAN release: 2014-11-10 Added sfTrimmed likely preferred spending function approach skipping early interim efficacy analyses; also can adjust bound final analysis performed less maximum planned information. Updated help(sfTrimmed) demonstrate capabilities. Added sfGapped, primarily intended eliminate futility analyses later study; see help(sfGapped) example Added summary.spendfn() provide textual summary spending functions; simplified print function gsDesign objects Added sfStep() can used set interim spend exact amount information unknown; example can misused provided help file Fixed rounding gsBoundSummary, xtable.gsSurv summary.gsDesign consistent gsSurv objects","code":""}]
